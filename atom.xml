<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>AprilNAVI&#39;s Blog | You are the best</title>
  
  
  <link href="https://aprilnavi.github.io/atom.xml" rel="self"/>
  
  <link href="https://aprilnavi.github.io/"/>
  <updated>2022-03-14T16:19:27.211Z</updated>
  <id>https://aprilnavi.github.io/</id>
  
  <author>
    <name>AprilNAVI</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>游戏引擎架构精要（才怪）④</title>
    <link href="https://aprilnavi.github.io/2022/03/15/2022-03-14-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A3/"/>
    <id>https://aprilnavi.github.io/2022/03/15/2022-03-14-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A3/</id>
    <published>2022-03-14T16:17:58.000Z</published>
    <updated>2022-03-14T16:19:27.211Z</updated>
    
    <content type="html"><![CDATA[<p>《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。</p><p>但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，</p><p>以及n个自己给自己找的理由，让这个阅读计划一直搁置。</p><p>但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多</p><p>再加上自己有意往引擎方向发展，阅读这本书就提上了日程。</p><span id="more"></span><p>今天进104官网看，发现引擎架构理所当然成为了这门课的官方教科书</p><p>这本书确实聊的蛮浅，但本人毕竟也才疏学浅看完这本书也需要些精力</p><p>今天晚上104就开课了，感觉自己进度好慢什么都跟不上</p><p>虽然是有点急了但是我菜的离谱也是当务之急，赶紧多肝吧</p><p>今天保底把第六章搞完，有机会的话肝肝第七章</p><hr><h1 id="资源及文件系统"><a href="#资源及文件系统" class="headerlink" title="资源及文件系统"></a>资源及文件系统</h1><p>游戏引擎必须有载入和管理多种媒体的能力，包括texture，mesh，animation，sound，collision，physics，scene</p><p>这涉及到如何同步或者异步IO（串流载入）的问题，涉及到如何跨平台编写文件系统，</p><p>涉及到如何管理runtime的资产占用的内存，涉及到怎么保存交叉引用的复合对象</p><p>（今天就只记得看了这么多了，真的很摸鱼）</p><hr><h2 id="6-1-文件系统"><a href="#6-1-文件系统" class="headerlink" title="6.1 文件系统"></a>6.1 文件系统</h2><h3 id="6-1-1-文件名和路径"><a href="#6-1-1-文件名和路径" class="headerlink" title="6.1.1 文件名和路径"></a>6.1.1 文件名和路径</h3><p>路径是描述了文件系统层次中文件或目录位置的字符串</p><p>在windows上（不讨论其他平台了），路径是一般是c:\Windows\System32这样的</p><p>路径分为绝对路径和相对路径，（有机会可以提提在UE里面导资产的事情）</p><p>在运行时寻找资产是十分费时的，最好在运气前就搜寻完所有的资产</p><p>若想开发跨平台的游戏引擎，则需要实现一个轻量化的路径处理API而非直接使用平台API</p><hr><h3 id="6-1-2-文件I-O"><a href="#6-1-2-文件I-O" class="headerlink" title="6.1.2 文件I/O"></a>6.1.2 文件I/O</h3><p>一般会建议引擎将文件IO的API封装成自己的API，</p><p>好处是可以保证所有平台上都有相同的表现，可以降低维护量同时也能满足拓展的需求</p><p>我们一般会<strong>推荐使用异步文件IO API</strong>，因为如果使用同步的IO API</p><p>那么这意味着在所有数据读取完之前程序会进入<strong>阻塞</strong>，这明显是十分蛋疼的</p><p>我们希望游戏都<strong>有串流（背后加载数据，主程序继续持续运行）</strong>的功能</p><p>说起来圣莫尼卡的《战神》就把这一块玩的很好，全程基本不会黑屏读图</p><p>为了支持串流就必须使用异步的IO API，具体伪代码详见原书p278</p><p>多数异步IO库允许主程序在请求发出一段时间后，等待IO完成才继续允许</p><p>如果需要在等待IO时做些有限的工作，则这种方式十分适用。</p><p>有些IO库允许程序员取得某些异步操作的时间估计，并设置时限</p><p>以及超出时限的安排（取消请求，通知程序，继续尝试）</p><hr><h2 id="6-2-资源管理器"><a href="#6-2-资源管理器" class="headerlink" title="6.2 资源管理器"></a>6.2 资源管理器</h2><p>游戏资源必须被妥善处理，包括离线时将资产转化为引擎适用资产的离线工具</p><p>还有在runtime时载入，卸下，以及操作资源的工具。</p><h3 id="6-2-1-离线资源管理以及工具链"><a href="#6-2-1-离线资源管理以及工具链" class="headerlink" title="6.2.1 离线资源管理以及工具链"></a>6.2.1 离线资源管理以及工具链</h3><p>资产的版本控制这方面因为没有和别人协同开发过</p><p>因此更不了解如何做好一个版本控制了，这对自己搓的玩具来说也不算大事，略过</p><p>对于大部分资产来说，游戏引擎不会使用原来的格式（就好像虚幻的uasset）</p><p>每个资产会流经资产调节管道（asset Conditioning Pipeline）</p><p>此时需要一些<strong>元数据（metadata，我悟了什么是元数据）</strong>来描述如何处理资产</p><p><strong>元数据就是描述数据的数据，例如要压缩位图使用哪一种压缩方式</strong></p><p>为了管理这些metadata以及资产，我们需要某种数据库。</p><p>数据库（也可以说是资产编辑器了）一般满足如下功能：</p><p>能处理多个资产，创建，删除，查看，修改，移动（磁盘上的位置）</p><p>交叉引用，维持交叉引用完整性，保存历史版本，多种搜索方式</p><hr><p>UE4的unreal editor就是个很棒的例子，editor几乎负责一切事物</p><p>包括元数据管理，资产创建，关卡布局，</p><p>可以在创建资产时直接看到资产在游戏世界的样子（所见即所得）</p><p>还可以在Editor中直接运行游戏，以便观察其如何在游戏中运作</p><p>同时UE的引用完整性做的也相当好（读的知识越多越感觉ue做的叼）</p><p>顽皮狗和ogre的离线资产管理方案这里就不做总结了</p><hr><p>资产调节管道也称（resource conditioning pipeline，名字不重要）</p><p>每个资产管道的始端都是原生格式的源资产，通常会经过三个处理阶段到达引擎</p><ol><li><p><strong>导出器（expoter）</strong>将原生格式的资产中的数据导出为中间格式供后续管道使用</p></li><li><p><strong>编译器（compiler）</strong>将第一阶段的数据进行小改动，例如重新压缩纹理，并非所有资产都需要重新编译</p></li><li><p><strong>链接器（linker）</strong>将多个文件结合成一个包再一起导入引擎，类比cpp的链接过程</p></li></ol><hr><h3 id="6-2-2-运行时资产管理"><a href="#6-2-2-运行时资产管理" class="headerlink" title="6.2.2 运行时资产管理"></a>6.2.2 运行时资产管理</h3><p>runtime管理的许多责任和功能都和其主要功能（载入资源到内存）有关：</p><p>确保任何时候同一份资源只有一份副本，管理资源生命周期（需要时载入不需要时卸载）</p><p>处理符合资源（多个资源组成的资源），维护引用完整性，管理资源载入后的内存</p><p>载入资源后初始化资源，提供较为统一的api，尽可能支持异步</p><p>资源文件及目录组织，一般是树状的不太关心（没啥好写的）</p><hr><p>游戏中所有资源必须有某种<strong>全局唯一标识符（GUID）</strong>常见的GUID就是资源的文件系统路径</p><p>这能很直观的反应他们硬盘上的物理路径且GUID因此不会重复</p><p>为了保证在任何时间载入内存的都只有一份副本</p><p>大部分资源管理器会使用某种形式的资源注册表记录已载入的资源</p><p>以键值对的集合（键为GUID值为指针）的方法则非常经典</p><p>资源被载入内存时限以其GUID为键，加载资源注册表字典，卸载资源时删除记录</p><p>游戏请求资源时就会用GUID寻找资源注册表，找得到就传指针</p><p>找不到就自动载入一个新的资源或者返回错误码</p><p>在runtime载入资源会对游戏的帧率造成非常大的影响，甚至是停顿</p><p>因此引擎可以采用串流（异步加载）或者是在游戏进行时完全禁止加载</p><hr><p>每个资产对生命周期有不同的要求：</p><ul><li>有些资产在游戏开始时必须被载入，驻留在内存一直到整个游戏结束，或者说其生命周期是无限的。典型例子有角色网格，材质，纹理以及核心动画，HUD，以及其他全程可以听到看到的资源</li><li>有些资产的生命周期则对应某个关卡，在玩家离开关卡时资源才被弃置（就好像ue的level资产，假设我们这里所说的关卡是一个实体而非逻辑概念的话）</li><li>有些资产的生命周期短于一个关卡的时间，例如过场动画，一小段BGM</li><li>有些资产的生命周期如很难定义，例如一些音乐和音效，因为每字节只短暂停留在内存中，这类资源通常以特定大小区块为单位载入。</li></ul><hr><p>在何时载入资源是已知的好解决的，但我们应该在何时卸载资源归还内存呢</p><p>许多资源依然会在之后的关卡继续共享，我们当然不希望将某些资源卸载后马上又加载他们</p><p>一个很好的方案就是使用引用计数（提到引用计数你应该想起智能指针类）</p><p>载入新的关卡时先遍历这些关卡所需的资源，并将其引用计数加1</p><p>然后再遍历即将卸载的资源将其引用计数减一，引用计数跌到0的就应该卸载掉。</p><hr><p>载入资源是不可避免的问题是考虑资源加载到哪一块内存，之前所述的内存分配系统通常与资源管理系统有很大的关系</p><p>要么利用已有的内存分配器设计系统资源，要么就设计内存分配器以配合资源管理所需。</p><p><strong>基于堆</strong>：若目标平台为PC，则由于操作系统支持高级的虚拟内存分配，这个方法还算勉强可以接受</p><p>但如果游戏运行在一个物理内存有限的游戏机上，只配上了最基础的虚拟内存管理器（可能还没有）</p><p>那么内存碎片就会是一个较为严重的问题，可以回顾之前所说的定期整理内存碎片的方案。</p><p><strong>基于栈：</strong>因为栈的内存分配是连续的，因此不会有内存碎片的问题。若能确保游戏是线性以及以关卡为中心</p><p>且一次内存足够容纳一整个关卡，那么就可以用这个方法。我们甚至可以用堆载入资源</p><p>标记栈的堆顶位置，每次完成关卡后都重新将栈顶指针重新指回到开始标记的位置，这样就可以迅速的释放关卡的所有资源</p><p>而且永远不会导致内存碎片</p><p><strong>基于池：</strong>在支持串流（异步加载）的游戏引擎中，一个常见分配技巧是将数据转化为同等大小的区块（chunk）。</p><p>因为chunk大小一致，因此就可以使用池分配器。但与此同时就得考虑分块的空间浪费问题</p><p>同时也要避免大型数据结构的使用，取而代之使用小于单个组块的数据结构</p><hr><p>游戏的复合资源通常包含着大量交叉引用：A引用B，B引用CD，ABCD必须同时在内存才能运行</p><p>要完整的载入复合资源，就得载入其依赖的所有资源。在Cpp中交叉引用一般以指针实现。</p><p>一个好的方式是使用GUID做交叉引用，资源管理器维护一个全局资源查找表</p><p>每次将资源对象载入内存后，都要把其指针以GUID为键加入查找表中。</p><p>当所有资源对象都载入内存后，扫描一次所有对象，将其交叉引用资源对象的GUID通过查找表换成指针</p><hr><p>有的资源在载入后还需要进行初始化，例如定义mesh的顶点和索引值，这些数据在渲染前得传送到缓存</p><p>而初始化的步骤又只能在runtime进行，包括建立顶点和索引缓冲，锁定缓冲读入缓冲以及解锁缓冲</p><p>在Cpp中许多开发者更喜欢把载入后初始化和卸载置于Init（）Destory（）这样的虚函数中</p><hr><p>肝到了0点18分，没想到这一章节感觉东西不多但是居然肝了有3k字，太难以置信了</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。&lt;/p&gt;
&lt;p&gt;但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，&lt;/p&gt;
&lt;p&gt;以及n个自己给自己找的理由，让这个阅读计划一直搁置。&lt;/p&gt;
&lt;p&gt;但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多&lt;/p&gt;
&lt;p&gt;再加上自己有意往引擎方向发展，阅读这本书就提上了日程。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>第四周学习日志</title>
    <link href="https://aprilnavi.github.io/2022/03/14/2022-03-14-%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/"/>
    <id>https://aprilnavi.github.io/2022/03/14/2022-03-14-%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/</id>
    <published>2022-03-14T09:17:58.000Z</published>
    <updated>2022-03-14T09:09:10.480Z</updated>
    
    <content type="html"><![CDATA[<p>这周恰逢games104开课，最近又流出了很多tx裁员的消息</p><p>压力大起来了，看来得再支棱一点了</p><span id="more"></span><hr><h1 id="Monday"><a href="#Monday" class="headerlink" title="Monday"></a>Monday</h1><p>上周周末过的挺一般的（不好不坏又好又坏）</p><p>不知为什么的就很不淡定，玩游戏的负罪感也变得比之前强了</p><p>大概周五晚上产出了一篇写PCF的博客之后就再也没动过书了</p><p>好多书没看时间根本不够用，有好多想玩的时间也不够用</p><p>再加上裁员内卷的恐慌情绪以及各路小道消息一直蔓延</p><p>一直节奏不错的我也有点乱了阵脚，一晚上都没有睡好觉</p><p>以至于今天早上抱了本书来看，结果闷头睡了一早上</p><p>十一点tx那边把我资料打回来了让我重新提交搞得我也有点怕怕的</p><hr><p>中午饱饱的睡了一觉之后压力没那么大了</p><p>但是下午一边摸鱼一边看书效率真的挺堪忧的</p><p>一想到自己UE引擎渲染三修，晚上又开104的课要听</p><p>瞬间就觉得压力好大，一堆想学一堆在学一堆没时间学</p><p>今天下午看引擎架构关于资源管理的那一章节就看了两个多小时</p><p>确实是感觉深度没有很深，看着也不痛不痒的感觉没学到什么</p><p>更大原因应该还是自己动手能力不足没法直接跟着敲一个出来</p><p>不过既然看了还是好好产出吧。</p><p>晚上争取八点前吧引擎架构的第六章和第七章搞完然后去看104！</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;这周恰逢games104开课，最近又流出了很多tx裁员的消息&lt;/p&gt;
&lt;p&gt;压力大起来了，看来得再支棱一点了&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Games202 Lecture3 (Shadow 1)</title>
    <link href="https://aprilnavi.github.io/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/"/>
    <id>https://aprilnavi.github.io/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/</id>
    <published>2022-03-11T02:06:58.000Z</published>
    <updated>2022-03-11T18:20:34.026Z</updated>
    
    <content type="html"><![CDATA[<p>在做opengl的时候做到了shadowmapping，效果做出来了但其实并不能算吃的很透</p><p>刚巧想起之前在202已结搭建好了框架环境，可以成功把202娘跑起来</p><p>所以会跟着202好好的把课听一遍</p><p>这次开坑的任务：</p><p>总结202课上精要内容，加入自己理解作为输出</p><p>在作业1的框架上完成shadowmapping的硬阴影</p><p>开始吧 Let ‘s go!</p><span id="more"></span><hr><h1 id="Recap-Shadow-Mapping"><a href="#Recap-Shadow-Mapping" class="headerlink" title="Recap Shadow Mapping"></a>Recap Shadow Mapping</h1><p>做两次光栅化（pass）</p><p>第一次从<strong>光的视角（light space）</strong>做一次pass，得到光看到的更近的更浅的深度值</p><p>将其渲染到一个texture上记录下来，作为ShadowMap</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220311104355661.png" alt="image-20220311104355661"></p><p>第二次从<strong>观察视角（camera）</strong>做一次pass，得到物体更远的深度值</p><p>取一阶段的ShadowMap深度进行比较</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220311104321858.png" alt="image-20220311104321858"></p><p>若第二次的深度值小于第一次的深度值，则生成硬阴影</p><hr><p>优势：不需要场景的几何信息，一旦shadowmap已经生成，shadowmap就能作为场景的几何表示</p><p>缺陷：会发生自遮挡和比较严重的走样（锯齿）</p><hr><p>备注：生成z值时用的矩阵如果是用正交的，第二个阶段也要拿正交的去比</p><p>同理用透视生成的z也一样，两者只要对应上都能生成正确结果</p><p>但大佬提醒，平行光用正交投影，点光源和聚光灯用透视。</p><hr><h2 id="self-occlusion"><a href="#self-occlusion" class="headerlink" title="self-occlusion"></a>self-occlusion</h2><p>如果没有在做深度对比的时候进行bias（偏移）出来的图大概率是像这样的：</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/QQ%E5%9B%BE%E7%89%8720220311110853.jpg" alt="(QQ图片20220311110853.jpg"></p><p>原因是这样的：</p><p>我们在第一阶段用一个像素来记录深度值，但此时如果光对于平面来说是斜照的</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220311111336669.png" alt="image-20220311111336669"></p><p>那一块区域就都只能取小红线这个深度值（即小红线就是像素记录的深度值）</p><p>当从上往下垂直照射（光线和平面法线重合）的时候，自遮挡的现象最不明显</p><p>为了尽量缩小影响bias带来的计算偏差</p><p>因此我们会根据光照和法线的夹角来计算一个bias在比较深度的时候使用：</p><pre><code>float bias = max(0.05 * (1.0 - dot(fs_in.Normal, lightDir)), 0.005);</code></pre><p>这样做也会带来一些问题，例如我们看上去物体就像浮在表面上一样</p><p>阴影并不是贴合着物体的轮廓的，我们称这种现象为悬浮(Peter Panning)</p><p>（这个概念在Learnopengl Shadowmapping有不错的解释：[阴影映射 - LearnOpenGL CN (learnopengl-cn.github.io)](<a href="https://learnopengl-cn.github.io/05">https://learnopengl-cn.github.io/05</a> Advanced Lighting/03 Shadows/01 Shadow Mapping/#_6)）</p><hr><p>RTR doesn’t trust in complexity（实时渲染不相信复杂度）就像电子竞技不相信眼泪哈哈哈</p><hr><p>晚上玩了下原神观察了下阴影，听大佬说人物的阴影用的CSM（Cascaded Shadow Mapping 级联阴影映射）</p><p>即给不同位置的shadowmap不同的分辨率，降低开销同时也能提升细节</p><p>动态阴影基本上都是用各种改进的Shadowmap做的，还有就是光追阴影</p><p>因此Shadowmap需要解决改进的就是锯齿问题</p><hr><h1 id="The-Math-Behind-Shadow-Map"><a href="#The-Math-Behind-Shadow-Map" class="headerlink" title="The Math Behind Shadow Map"></a>The Math Behind Shadow Map</h1><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220311230849772.png" alt="image-20220311230849772"></p><p>将两个函数乘积再积分近似等于积分再乘积（分母相当于做归一化）</p><p>当g(x)的support（支撑集）很小,或者g(x)的函数曲线足够光滑（smooth）</p><hr><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312000423444.png" alt="image-20220312000423444"></p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312001718439.png" alt="image-20220312001718439"></p><p>左边是visibility，右边是纯Shader的结果</p><p>对于点光源和方向光源来说，相当于是Small Support满足了第一条件</p><p>所以是可以近似认为，可以用约等式将shader和visibility的部分拆开分别计算再叠加</p><p>对于面光源来说，面光源内的radiance认为是相等各处不变的，即L是smooth的，也可以满足第一条件</p><p>而对于shading point来说diffuse的表面我们认为变化是比较小的</p><p>而glossy的表面（被打磨的铜镜之类的材质效果，是较为模糊的镜面）是较为剧变的，结果就比较不准确</p><hr><h1 id="Percentage-Closer-Soft-Shadow-PCSS"><a href="#Percentage-Closer-Soft-Shadow-PCSS" class="headerlink" title="Percentage Closer Soft Shadow (PCSS)"></a>Percentage Closer Soft Shadow (PCSS)</h1><p>对于硬阴影来说，阴影在边界上没有从无到有的过渡，看上去很不自然</p><p>在生活中，光源基本上都是理想的面光源，看到的阴影都更倾向于软阴影，有一个良好的过渡。</p><p>PCSS是用来生成软阴影的技术，建立在PCF（percentage Closer Filter）之上</p><p>PCF是起初用于解决阴影边界的抗锯齿而非计算软阴影。</p><p><strong>PCF不是对最后生成的结果的锯齿做模糊</strong>，而是在做阴影的判断时做的Filter</p><p>同样是因为不能先得到一个走样的结果，然后再做一个模糊（和做反走样的概念是一样的）</p><p><strong>PCF同样不是对生成的ShadowMap做了模糊</strong>，因为对Shadowmap本身就是记录非0即1的结果来表示阴影</p><p>做平均然后和模糊了的深度做测试是没有意义的</p><p>PCF的做法是在投影到light space找对应像素时，不单单只找那一个像素，而是找周围一圈的像素做一个平均（Filter）</p><p>![image-20220312005309957]image-20220312005309957.png)</p><hr><p>借用learnOpenGL的对此的解释：（个人感觉很到位而且给出了具体的代码演示）</p><p>核心思想是从深度贴图中多次采样，每一次采样的纹理坐标都稍有不同。</p><p>每个独立的样本可能在也可能不再阴影中。所有的次生结果接着结合在一起，进行平均化，我们就得到了柔和阴影。</p><pre><code>float shadow = 0.0;vec2 texelSize = 1.0 / textureSize(shadowMap, 0);for(int x = -1; x &lt;= 1; ++x)&#123;    for(int y = -1; y &lt;= 1; ++y)    &#123;        float pcfDepth = texture(shadowMap, projCoords.xy + vec2(x, y) * texelSize).r;         shadow += currentDepth - bias &gt; pcfDepth ? 1.0 : 0.0;            &#125;    &#125;shadow /= 9.0;</code></pre><p>这个textureSize返回一个给定采样器纹理的0级mipmap的vec2类型的宽和高。</p><p>用1除以它返回一个单独纹理像素的大小，我们用以对纹理坐标进行偏移，确保每个新样本，来自不同的深度值。</p><p>这里我们采样得到9个值，它们在投影坐标的x和y值的周围，为阴影阻挡进行测试，并最终通过样本的总数目将结果平均化。</p><p>使用更多的样本，更改texelSize变量，就可以增加阴影的柔和程度。</p><p>效果可行，但对于一个shading point要做更多次的计算，所以会变得很慢</p><hr><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312010426704.png" alt="image-20220312010426704"></p><p>课程中的对比图</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312005843526.png" alt="image-20220312005843526"></p><p>这是自己手搓的3x3的卷积，Filter越大则阴影越软，因此软阴影就是因此计算而来的</p><p>而一般来说，离物体越近的地方阴影就越硬越明显，因此就有了Percentage Closer Soft Shadow的概念</p><p>即根据阴影与遮挡物的距离给定不同大小的filter size</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312020418634.png" alt="image-20220312020418634"></p><p>这张图很好的说明了Light面越大则软阴影的区域就越大（图中相似三角形的关系）</p><p>我们可以想象，若遮挡物Blocker的离接收物Receiver越近，相似三角形就会更小</p><p>这就很好的解释了为什么有“离物体越近的地方阴影就越硬”的这个现象</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312021607801.png" alt="image-20220312021607801"></p><p>恰巧笔者最近也在玩消光，有机会的话去游戏里好好观察一番</p><hr><p>打异度之刃2去咯  2022/3/12 2:20</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在做opengl的时候做到了shadowmapping，效果做出来了但其实并不能算吃的很透&lt;/p&gt;
&lt;p&gt;刚巧想起之前在202已结搭建好了框架环境，可以成功把202娘跑起来&lt;/p&gt;
&lt;p&gt;所以会跟着202好好的把课听一遍&lt;/p&gt;
&lt;p&gt;这次开坑的任务：&lt;/p&gt;
&lt;p&gt;总结202课上精要内容，加入自己理解作为输出&lt;/p&gt;
&lt;p&gt;在作业1的框架上完成shadowmapping的硬阴影&lt;/p&gt;
&lt;p&gt;开始吧 Let ‘s go!&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>游戏引擎架构精要（才怪）③</title>
    <link href="https://aprilnavi.github.io/2022/03/08/2022-03-08-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A2/"/>
    <id>https://aprilnavi.github.io/2022/03/08/2022-03-08-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A2/</id>
    <published>2022-03-08T09:17:58.000Z</published>
    <updated>2022-03-09T10:05:00.150Z</updated>
    
    <content type="html"><![CDATA[<p>《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。</p><p>但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，</p><p>以及n个自己给自己找的理由，让这个阅读计划一直搁置。</p><p>但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多</p><p>再加上自己有意往引擎方向发展，阅读这本书就提上了日程。</p><span id="more"></span><p>今天把第五章的东西看完，看的内容不多但是感觉有收获，</p><p>书上讲的东西很干货，特别是谈及链表那个地方确实给了人很大的启发</p><hr><h1 id="第五章"><a href="#第五章" class="headerlink" title="第五章"></a>第五章</h1><h2 id="5-3-容器"><a href="#5-3-容器" class="headerlink" title="5.3 容器"></a>5.3 容器</h2><p>这个章节讲了一些基本上常用的数据结构，比较详细的分析了他们适用的场景</p><p>并且为我们自己亲自编写他们也提供了很不错的方案，是我觉得很有用很精华的内容</p><hr><h3 id="5-3-2-迭代器"><a href="#5-3-2-迭代器" class="headerlink" title="5.3.2 迭代器"></a>5.3.2 迭代器</h3><p>问题c++的迭代器在我第一次学习的时候，我不知道他和直接i++的区别是什么</p><p>书中所说，迭代器像是数组索引或指针，可以移至下一个元素（我也知道）</p><p>但是！迭代器通常是容器类的<strong>友元</strong>，因此可以高效迭代访问容器，不向外面暴露容器类的实现细节</p><p>其次，迭代器简化了迭代过程，无论数据结构多复杂，我都可以<code> iterator++</code></p><p>这个又涉及到前置递增++i和后置递增i++的问题</p><p>原文：在深度流水线CPU上，前置递增必须完成递增才能使用这个值，会引起<strong>流水线停顿</strong></p><p>在for循环里面前置和后置没有区别，<strong>当用到值的时候建议使用后置递增</strong></p><p>在使用类类型的时候，由于前置和后置可能是自定义的运算符重载</p><p>而后置递增需要对对象进行拷贝，会造成性能消耗，因此<strong>在类类型尽量使用前置递增</strong></p><hr><h3 id="5-3-3-算法复杂度"><a href="#5-3-3-算法复杂度" class="headerlink" title="5.3.3 算法复杂度"></a>5.3.3 算法复杂度</h3><p>这个大家面试的时候应该都刷烂了，但是书里边对于复杂度的常见解释</p><p>写的不错所以还是可以记一下的：</p><p>若算法的运行时间和容器中的元素数目无关的话，称算法为O（1）；</p><p>若算法循环访问容器里面的元素，每个元素当访问一次，则算法为O（n）；</p><p>若算法有两层循环，每层循环访问每个元素一次，则算法为O（n2）（自动联想上标）；</p><p>若算法使用分治法（二分查找），每次都能消去余下元素的一半，则算法为O（logn）；</p><p>若算法执行一个子算法n次，且子算法为O（logn），则整个算法为O（nlogn）</p><p>最长预见的数量级O（1），O（logn）,O（n）,O（nlogn）,O（n2）</p><p>同时也应该考虑容器的内存布局和使用特性</p><p>数组的内存连续，更加缓存友好，且除了元素不需要额外的内存开销（对比链表需要存指向下一元素的指针）</p><p>若插入以及移除元素的速度很重要，则应该使用链表</p><hr><h3 id="5-3-4-自建容器"><a href="#5-3-4-自建容器" class="headerlink" title="5.3.4 自建容器"></a>5.3.4 自建容器</h3><p>这里对于是否使用自建的数据结构提供了讨论，使用自建容器有以下好处：</p><ul><li>可以自己控制如何分配内存，自由的进行优化</li><li>可自行提供第三方库没有的功能（stl中只能搜索单个最有关元素，而不能搜索n个）</li><li>不需要第三方库支持则可以消除第三方团队的外部依赖</li><li>可全权控制多线程或多核系统的保护机制</li></ul><hr><p>常见第三方：</p><p><strong>STL：</strong></p><p>优势：功能丰富，多平台的壮健表现，几乎所有c++编译器自带stl</p><p>缺点：难学，对于特定问题速度不如自建容器快，对比自建容器会占用更多内存</p><p>会进行许多动态分配，要控制stl的内存占用量</p><p>STL适合pc游戏引擎，因为对比游戏主机内存受限，缺乏高级CPU和虚拟内存</p><p>现代pc拥有高级虚拟内存系统，通常也能忽略物理内存不足的可能性</p><p><strong>Boost：</strong></p><p>优势：文档写得好，功能比stl更多，能有效处理智能指针</p><p>缺点：核心类是模板，可能会生成较大的lib，不适合小项目</p><p>不保证向后兼容，Boost团队也不提供保障。</p><hr><p>数组和动态数组不加赘述，没什么好说的</p><hr><p>链表这块讲的很不错：</p><p>外露式链表：</p><pre><code>template&lt;typename ELEMENT&gt;struct Link&#123;   Link&lt;ELEMENT&gt;* Prev;   Link&lt;ELEMENT&gt;* Next;   ELEMENT* Elem;&#125;</code></pre><p>节点数据结构和元素数据结构完全分离，每个节点含指针指向元素。</p><p>外露式链表的特点在于，一个元素可以置于多个链表中，只需要节点指向该元素</p><p>但分配节点时必须进行动态分配，许多时候会使用池分配器。</p><hr><p>侵入式链表：</p><pre><code>template&lt;typename ELEMENT&gt;struct Link&#123;   Link&lt;ELEMENT&gt;* Prev;   Link&lt;ELEMENT&gt;* Next;&#125;class SomeElement:public Link&lt;SomeElement&gt;&#123;   //其他成员&#125;</code></pre><p>使用侵入式链表的好处是，分配元素时无须再动态分配节点（已经获得了节点）</p><p>但每个元素不能置于多个列表中，（元素只有一个节点数据），因此侵入式链表不如外露式有弹性</p><hr><p>循环链表的结构一般会包含头尾指针：</p><pre><code>template&lt;typename ELEMENT&gt;struct Link&#123;   Link&lt;ELEMENT&gt;* Tail;   Link&lt;ELEMENT&gt;* Head;      //相关操作成员函数&#125;</code></pre><p>用Link类来管理头尾指针有些好处:</p><pre><code>template&lt;typename ELEMENT&gt;struct Link&#123;   Link&lt;ELEMENT&gt; Root; //包含了头尾指针         //相关操作成员函数&#125;</code></pre><p>这样一来最后节点的next和第一个节点的pre都是指向root的</p><p>这样设计能简化插入和移除的逻辑，我们先看看独立头尾指针移除元素的代码：</p><pre><code>void LinkList::remove(Link&lt;ELEMENT&gt;&amp; link)&#123;  if(link.next)link.next.pre=link.pre;  else this.Tail=link.pre  //移除链表末元素    if(link.pre)link.pre.pre=link.next;  else this.Head=link.next//移除链表首元素    link.pre=link.next=nullptr;&#125;</code></pre><p>在这个设计中首节点的pre和末节点的next必为空指针，若列表只有一个节点，则两个指针都会是空指针</p><p>不能单凭一个指针得知他是否属于一个链表</p><p>若使用root的设计：</p><pre><code>void LinkList::remove(Link&lt;ELEMENT&gt;&amp; link)&#123;  ASSERT(link.next);  ASSERT(link.pre);    link.next.pre=link.pre;  link.pre.pre=link.next;    link.pre=link.next=nullptr;&#125;</code></pre><p>最后节点的next和第一个节点的pre都是指向root的</p><p>因此若首节点的pre和末节点的next为空指针，则他不属于这个链表</p><hr><p>字典，散列表（哈希表）</p><p>笔者不可能去手写哈希函数所以感觉没什么好说的哈哈哈</p><p>感觉还是乖乖std::吧</p><hr><h2 id="5-4-字符串"><a href="#5-4-字符串" class="headerlink" title="5.4 字符串"></a>5.4 字符串</h2><p>问了问魔方的引擎前辈</p><p>那边好像基本上都是在改ue的，说在游戏引擎里面处理这个不多</p><p>而且ue内部的字符串管理也还行</p><p>那我就选择性忽略这章吧</p><hr><h2 id="5-5-引擎配置"><a href="#5-5-引擎配置" class="headerlink" title="5.5 引擎配置"></a>5.5 引擎配置</h2><p>5.5这章感觉也没有提供什么对我比较有启发的东西</p><p>讲到ini，xml还有注册表什么的感觉算是短期之内比较接触不到的东西</p><p>如果具体想做的话应该很快能找到不错的解决方案</p><hr><p>今天就到这吧 赶紧shadowmapping去了</p><p>2022.3.9 17:35</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。&lt;/p&gt;
&lt;p&gt;但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，&lt;/p&gt;
&lt;p&gt;以及n个自己给自己找的理由，让这个阅读计划一直搁置。&lt;/p&gt;
&lt;p&gt;但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多&lt;/p&gt;
&lt;p&gt;再加上自己有意往引擎方向发展，阅读这本书就提上了日程。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>第三周学习日志</title>
    <link href="https://aprilnavi.github.io/2022/03/07/2022-03-07-%E7%AC%AC%E4%B8%89%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/"/>
    <id>https://aprilnavi.github.io/2022/03/07/2022-03-07-%E7%AC%AC%E4%B8%89%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/</id>
    <published>2022-03-07T10:31:58.000Z</published>
    <updated>2022-03-11T18:25:28.859Z</updated>
    
    <content type="html"><![CDATA[<p>第三周的学习日志哒</p><span id="more"></span><h1 id="Monday"><a href="#Monday" class="headerlink" title="Monday"></a>Monday</h1><p>上午的状态很不错，整个人都神采奕奕的</p><p>把光照改进成了bling phong，加了gamma校正和点光源的衰减</p><p>做起来的效果不错，而且一整个上午的效率也很高，明天可以开始做Shadow mapping</p><p>上午上课发生了一点小插曲，我在上PS课的时候用着自己电脑在写shader</p><p>老师过来问我在干什么我说在写着色器，老师说我是毕业想去做游戏吗</p><p>我说已经进tx了（实则转正没一撇），然后老师就以整层楼都听得见的声音直接大喊了一声</p><p>（说起来这个offer真的给了我很多，信心，实力，虚荣，人脉，好的坏的都有）</p><p>然后老师坏笑的说：如果我挂掉你会怎么样呢，我：球球放过</p><p>然后老师就推了一个后辈的v给我，叫我好好带带，带不动就挂我（晕）</p><p>然后稍微看了下大二上在跟着unity教程做demo，看着是还不错，但是不知道基础怎么样</p><p>稍微了解了下挺多行情也术语也不了解（还好不算太离谱的卷王）</p><p>其实挺好的，游戏有在做，后端也有在搞，不需要版号掐死就死路一条</p><hr><p>下午补考完以后基本上是做大牢</p><p>补考本身是并不能算顺利但也并不是完全寄，只能说期望能过吧</p><p>四点就来图书馆想着写一两个小时博客，结果摸鱼边码字字码了不少但是还没写完</p><p>最后因为版号的事情人也焦虑的不行，只能说游戏行业真的太难了</p><p>之后的日子会很难熬吧，但我早已经斩断后路了，毕竟重现前辈所期望的世界是我的U咩呢</p><hr><p>希望七点二十之前可以把UE打开吧，博客写到这样就算了</p><hr><h1 id="Tuesday"><a href="#Tuesday" class="headerlink" title="Tuesday"></a>Tuesday</h1><p>昨天晚上因为一些琐事没有睡好，大概是三点多才睡着</p><p>早上一下睡到了五十分才醒，一醒来就往教室跑，除开很困之外人的精神面貌还不错（好像也不好）</p><p>但起码好在我是个精神独立的人，不会因为失去什么就停止前进</p><p>身体感觉到了明显的劳累感，不过我知道这是因为我把作息调成了不熬夜的作息导致的（好事）</p><p>早上做shadowmapping只做了一半，感觉好难，最后还是跟着源码粘上去才出了效果</p><p>希望明天花多点时间能够把shadowmapping搞明白。</p><hr><p>中午下课把电脑开开心心放图书馆</p><p>然后下午下课过来发现电脑给人挪走了，一天的好心情直接急急急</p><p>希望晚上抽雷神的时候运气可以好点吧</p><hr><p>九条五命，西风长枪两把，和璞鸢一把，毕业心海一只</p><p>水群时间一大把，博客都没有肝完呜呜呜呜</p><p>晚上看了一小时光追课全程发呆，什么都听不懂属实小emo</p><p>好在心情还是不错的，但不得不说萌萌真的很厉害我真的很敬佩她</p><p>我还零基础的时候她就在拿MiniGame打比赛，gameplay做的很好</p><p>我们现在联系的少了，我记得拿到了魔方的oc告诉她的时候她反应不大</p><p>（看来是不稀罕了呜呜呜）她确实没有让我失望，</p><p>晚上直接列式问光追里面的积分和采样算的结果如何（tql）而且她真的是很谦虚的人</p><p>如果我的成长速度是5那她估计是15，但我也会好好加油的</p><hr><h1 id="Wednesday"><a href="#Wednesday" class="headerlink" title="Wednesday"></a>Wednesday</h1><hr><p>早上睡到了八九点，一早上都没怎么肝，就想着东奔西跑给图书馆占位置了</p><p>os课下半节直接逃了，回宿舍打原神去了笑死</p><p>一中午没睡下午精神也不是很好</p><hr><p>说是学习日志到现在根本也还没进状态吧</p><p>不过倒是和鸡哥聊了很多转正的事情，对转正更有信心了</p><p>在居居的群了钓了一下午鱼心情蛮好的还</p><p>虽然最后也是什么都没做哈哈哈哈</p><hr><p>今天的任务定个小目标吧</p><ol><li><p>补完昨天的博客</p></li><li><p>搞完昨天没搞完的shadowmapping（这也算是早上没搞完的）</p></li><li><p>gameplay做完一个模块吧</p></li></ol><p>今日事今日毕冲冲冲！ </p><hr><h1 id="Thursday"><a href="#Thursday" class="headerlink" title="Thursday"></a>Thursday</h1><p>搞了一整个晚上的shadow map</p><p>rtr到了但是翻了几页就劝退了</p><h1 id="Friday"><a href="#Friday" class="headerlink" title="Friday"></a>Friday</h1><p>单单是重新把框架搞好</p><p>调试shadowmap什么的就做了一早上</p><p>回来一边摸鱼一边学习把202第一章关于shadow的整理归纳好了</p><p>写完博客已经是2点钟了</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;第三周的学习日志哒&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>年糕老师的ue4小课堂（第二期）</title>
    <link href="https://aprilnavi.github.io/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/"/>
    <id>https://aprilnavi.github.io/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/</id>
    <published>2022-03-07T10:31:58.000Z</published>
    <updated>2022-03-07T10:59:08.634Z</updated>
    
    <content type="html"><![CDATA[<p>在ue方面笔者完全是个萌新，糕糕前辈在我进入某大佬群时主动加了我的好友（现在想来感动的能哭出声）</p><p>在我学习ue时不吝赐教，为我提供了许多资料，语气也十分的和蔼温柔</p><p>每次遇到什么问题发消息几乎都是秒回，解答了我的许多疑惑（我哭死）</p><p>这篇博客会做成一个对话的专栏形式，会记录一些前期学习遇到的疑问</p><p>不会有固定的大纲，记录的风格是诙谐轻松的（顺利的话会一直写下去？）</p><p>最重要的是这些遇到并得到解答的问题我不希望今天获取然后明天就失忆了</p><p>这些知识对初学者应该是很有帮助的（确信），所以我很乐意记录这样一个快乐的过程</p><span id="more"></span><hr><p>这次笔者会记录在学校学习的第二周和糕糕前辈发生的有趣的对话</p><hr><h2 id="第一幕-3-1"><a href="#第一幕-3-1" class="headerlink" title="第一幕 3.1"></a>第一幕 3.1</h2><p>四月：糕糕你之前发我的那个有关assert的文章还在吗，哦对了说起来断言算是c++的机制还是算是ue的机制呢</p><p>糕糕：是ue的机制，你也可以自己写，不过就不叫断言了。你知道断言为什么叫断言吗。</p><p>四月：会引发一个中断！（确信）</p><p>糕糕：没错，断言的意思差不多就类似中断的文字版。</p><hr><h2 id="第二幕-3-2"><a href="#第二幕-3-2" class="headerlink" title="第二幕 3.2"></a>第二幕 3.2</h2><p>四月：糕糕，元数据metadata是什么</p><p>糕糕：元数据是用来描述数据的数据，<a href="https://www.ruanyifeng.com/blog/2007/03/metadata.html">https://www.ruanyifeng.com/blog/2007/03/metadata.html</a></p><p>四月：这样，那ue的元数据是什么，文件大小时间那些的吗</p><p>糕糕：UE的UProperty有Meta标签，不过可以自己加，只能editor识别。或者说这个所谓的描述其实没有固定添加的地方</p><p>只是看你的程序对他处不处理。</p><p>四月：噢噢正是这样所以UE editor能把这些当成资产来使用，这就是元数据</p><hr><h2 id="第三幕-3-2"><a href="#第三幕-3-2" class="headerlink" title="第三幕 3.2"></a>第三幕 3.2</h2><p><strong>四月：</strong>自带的FPS模板写了一堆前向声明诶</p><p><img src="/images/loading.jpg" data-original="/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/_4VZ%25%5D%25DHR%5B7%60RTAIZ79GOR.png" alt="img"></p><p><strong>糕糕：</strong>C++ 必须写这个，必须能不用#include就不用</p><p><strong>四月：</strong>噢噢原来是这样，我之前都是都是#include</p><p><strong>糕糕：</strong>#include的话 其中某个头文件改了，链式增加编译数量，而且会有重叠引用的问题</p><p><strong>四月：</strong>之前demo就遇到过，就武器类引用了我的角色，角色类也引用我的武器，然后乱糟糟的，可能哪边不小心改错了就过不去编译。</p><p><strong>糕糕：</strong>还有这个前置声明，我推荐在头文件里写在要用的地方，而不是写在最上面，方便复制片段代码</p><p>还有个事，struct不能前置声明</p><p><strong>四月：</strong>所以class和struct的区别又多了一个，那我怎么天天看到它们只有一个public一个private的区别</p><p>糕糕：其实是UE里不能这样</p><p><strong>四月：</strong>可恶啊</p><p><strong>糕糕：</strong>因为UE的struct只能放到栈里构造，而class只能在堆里构造，UE的uclass 创建变量的时候只能用 指针，ustruct只识别非指针</p><p>所以ustruct，在头文件里构造这个类的时候就要明确要多少内存，所以就得在这里include进来了。</p><p>而class在构造这个类的时候是用的指针，固定大小的，所以可以前置声明。</p><p><strong>四月：</strong>呜呜呜糕糕真是好老师</p><p><strong>糕糕：</strong>所以可恶的C++，现在我学ts就完全好多了</p><hr><h2 id="第四幕-3-2"><a href="#第四幕-3-2" class="headerlink" title="第四幕 3.2"></a>第四幕 3.2</h2><p>四月：UgameplayStatic::里面有什么常用的api吗</p><p>糕糕：看源码，基本上都是常用Api吧。但实际项目中，最好自己写个类似的库</p><p>四月：我自己实现一遍吗</p><p>糕糕：嗯嗯，因为他get出来的是UE原来的类型，要cast一下</p><p><img src="/images/loading.jpg" data-original="/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/T39@HAUYOY4%7BNE%7D(QPL)RKU.png" alt="img"></p><p>比如最常用的这个，正经项目你肯定会自己写个Gamemode吧，你每次都要cast一下</p><p>直接对自己的gamemode写个static get自己的实例算了 反正是单例。</p><p>四月：避免cast是为什么呢，性能开销太大了吗</p><p>糕糕：嗯，损耗很大。</p><p><img src="/images/loading.jpg" data-original="/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/%E5%8D%95%E4%BE%8B.png" alt="img"></p><p>写个单例大概像这样的</p><p>四月：单例不是考虑到线程安全会有什么懒汉式还有其他的吗</p><p>糕糕：Gamemode的生命周期不用自己管理，所以我们只用存他的指针返回他的指针就是了</p><p>四月：所以引擎会帮我们解决对吗</p><p>糕糕：嗯嗯对的，这样只有第一次有cast损耗，后面放tick里也没啥问题了</p><hr><h2 id="小插曲"><a href="#小插曲" class="headerlink" title="小插曲"></a>小插曲</h2><p>四月：我想玩那个车车游戏</p><p>糕糕：base.apk</p><p>四月：这车真的很难开，为什么你漂移还能炸对手</p><p>糕糕：游戏开发者一般是技术最好的吧，其实一般来说是策划，但这移动算法都是我写的</p><p>四月：里面的按钮居然都点不了！只有广告是可以点的，老板估计很开心</p><p>糕糕：说起来 你想去大厂的话，一定要想办法转正或者毕业就直接去大厂，不然工作几年之后很难的</p><p>我这边的tx基本上只招资深的<img src="/images/loading.jpg" data-original="/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/2FFS%7B6G@M3$ZUWUK%25SWE0H.gif" alt="img">普通的和高级的基本上都是从实习生就在Tx的</p><p>四月：我当然知道啦，所以转正我特别重视，毕竟现在版号不发了，是游戏圈的紧要关头，可能没转正成功我就回家了。</p><p>我打算死磕tx了，毕业拿转正offer之前都不算高枕无忧。</p><hr><p>笔者写这些的时候，又听到了一些所谓“小道消息”，说春招的hc被卡了很多，即使自己不需要春招已经上岸</p><p>但还是感觉到了不小的压力，也为整个中国游戏行业的未来狠狠的捏了一把汗。</p><p>再说下去要emo了，这样可不行，人还是得开开心心的，毕竟我又是月亮又是太阳！</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在ue方面笔者完全是个萌新，糕糕前辈在我进入某大佬群时主动加了我的好友（现在想来感动的能哭出声）&lt;/p&gt;
&lt;p&gt;在我学习ue时不吝赐教，为我提供了许多资料，语气也十分的和蔼温柔&lt;/p&gt;
&lt;p&gt;每次遇到什么问题发消息几乎都是秒回，解答了我的许多疑惑（我哭死）&lt;/p&gt;
&lt;p&gt;这篇博客会做成一个对话的专栏形式，会记录一些前期学习遇到的疑问&lt;/p&gt;
&lt;p&gt;不会有固定的大纲，记录的风格是诙谐轻松的（顺利的话会一直写下去？）&lt;/p&gt;
&lt;p&gt;最重要的是这些遇到并得到解答的问题我不希望今天获取然后明天就失忆了&lt;/p&gt;
&lt;p&gt;这些知识对初学者应该是很有帮助的（确信），所以我很乐意记录这样一个快乐的过程&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>年糕老师的ue4小课堂（第一期）</title>
    <link href="https://aprilnavi.github.io/2022/03/07/2022-03-04-%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%B8%80%E6%9C%9F%EF%BC%89/"/>
    <id>https://aprilnavi.github.io/2022/03/07/2022-03-04-%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%B8%80%E6%9C%9F%EF%BC%89/</id>
    <published>2022-03-07T09:31:58.000Z</published>
    <updated>2022-03-07T09:02:02.104Z</updated>
    
    <content type="html"><![CDATA[<p>在ue方面笔者完全是个萌新，糕糕前辈在我进入某大佬群时主动加了我的好友（现在想来感动的能哭出声）</p><p>在我学习ue时不吝赐教，为我提供了许多资料，语气也十分的和蔼温柔</p><p>每次遇到什么问题发消息几乎都是秒回，解答了我的许多疑惑（我哭死）</p><p>这篇博客会做成一个对话的专栏形式，会记录一些前期学习遇到的疑问</p><p>不会有固定的大纲，记录的风格是诙谐轻松的（顺利的话会一直写下去？）</p><p>最重要的是这些遇到并得到解答的问题我不希望今天获取然后明天就失忆了</p><p>这些知识对初学者应该是很有帮助的（确信），所以我很乐意记录这样一个快乐的过程</p><span id="more"></span><hr><p>让我们有请今天的嘉宾，糕糕老师！</p><p><strong>糕糕：</strong>大家好，我是一个工作不到两年的菜鸡（看来糕糕老师确实很谦虚呢）</p><hr><h2 id="第一幕-2-23"><a href="#第一幕-2-23" class="headerlink" title="第一幕 2.23"></a>第一幕 2.23</h2><p>某天晚上我新建了个了第三人称模板，想找个项目做做重温一下act的感觉，在搞动画蓝图的时候有了以下一幕：</p><p><strong>四月：</strong>那个人向哪里走就向哪里转向的，是在哪里设置的？</p><p><strong>糕糕 ：</strong>MovementComponent 还是 Character的默认属性那里忘记了</p><p><strong>四月：</strong>我还是开中文吧，感觉用英文很多东西反应不过来</p><p><strong>糕糕：</strong>建议是开中文语言，节点的名字和变量的名字英文</p><p><img src="/images/loading.jpg" data-original="/2022/03/07/2022-03-04-%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%B8%80%E6%9C%9F%EF%BC%89/(S9NBOMCU)3C7$7ZNKGC%7D5O-16463936762971.png" alt="img"></p><p><img src="/images/loading.jpg" data-original="/2022/03/07/2022-03-04-%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%B8%80%E6%9C%9F%EF%BC%89/QQ%E5%9B%BE%E7%89%8720220304193559.png" alt="img"></p><p><strong>糕糕：</strong>嗯对是这样</p><p><strong>四月：</strong>奇怪了，我在blendspace里面看都是正常的，有很多个方向的移动，连上去之后，怎么跑怎么动都是一个样子</p><p><img src="/images/loading.jpg" data-original="/2022/03/07/2022-03-04-%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%B8%80%E6%9C%9F%EF%BC%89/image-20220304194659446.png" alt="image-20220304194659446"></p><p><strong>糕糕：</strong>白色那里选场景里的Character，这可是蓝图调试基础</p><p><strong>四月：</strong>呜呜呜基础</p><p><strong>糕糕：</strong>没事，我也是自学才看到这个功能的</p><p><strong>四月：</strong>算了我把速度打印到屏幕吧，这样方便一点</p><p><strong>四月：</strong>我草，破案了，他的速度只有正值，我是傻逼啊</p><p><strong>糕糕：</strong>哈哈哈哈哈哈哈，这个就是做项目的好处了，能学到解决问题的思路，所以即使之后做的不是这个类型的游戏之类的也能做</p><p><strong>四月：</strong>他这个自带模板有大病啊，怪不得要设置成自动旋转，速度怎么可能会没有负值啊，然后blendspace只做了前进的</p><p><strong>糕糕：</strong>速度一般都是0～动画的实际速度，看设计的。</p><hr><p>次日：</p><p><strong>四月：</strong>完了，我是怎么说出昨天晚上那些话的，正常来说速度怎么可能有负值呢</p><p><strong>糕糕：</strong>所以我没多想</p><p>![image-20220304200942589]image-20220304200942589.png)</p><p><strong>四月：</strong>这样，感觉好缺编程经验，断言，调试，句柄，宏这些我都没学过，怎么恶补</p><p><strong>糕糕：</strong>你是想刚毕业就有10年经验吗</p><p><strong>四月：</strong>啊可是这个难道不是毕业生标配吗，我怎么感觉别人都会（事实上这个傻逼在过度焦虑）</p><p><strong>四月：</strong>哈哈哈哈哈哈哈哈哈，你这一说我就放心了</p><p><strong>糕糕：</strong>嗯 我的意思就是，这些其实都是在做项目过程中学的，所以没有恶补的方法</p><p><strong>四月 ：</strong>噢噢这样，之前精力基本上都在看理论，怪不得都不知道这些，实操少了</p><hr><p>由此可见，gameplay的实操本身就是最好的学习资料</p><hr><h2 id="第二幕-2-25"><a href="#第二幕-2-25" class="headerlink" title="第二幕 2.25"></a>第二幕 2.25</h2><p>这篇特别长但我觉得特别有营养，是经典</p><p>有天下午在图书馆看大象无形（确实是真的看不懂），看到一半回忆起当时面试被问到的问题</p><p><strong>四月：</strong>gamemode和gamestate的区别是什么，关卡蓝图又是什么</p><p><strong>糕糕：</strong>终于到这里了</p><p><strong>四月：</strong>没有，还没到这里，是我在读书的时候想起了面试官问我的问题。</p><p><strong>糕糕：</strong>这些东西都是属于Gameplay框架里的一部分，Gameplay框架的定义，它是一个“房间制多人联机回合计分对战游戏框架”，所以你做单机游戏的时候，实际上是用不到的。</p><p><strong>四月：</strong>所以做单机游戏的时候 ，是不是我把规则写gamemode和gamestate都可以</p><p><strong>糕糕：</strong>是这样，但是你一旦做多人游戏，这俩的网络同步状态，以目前游戏用得比较多的UE联机方式，DS服务器架构下，<br>一个游戏房间里拥有一个中央服务端只处理服务器逻辑不处理渲染，而所有玩家都是客户端。在这种架构下，服务端跑了一个UWorld，客户端也跑了一个UWorld，但是只有服务端的UWorld是真实的，其他所有的都是复制品。</p><p><strong>四月：</strong>所以说客户端是对服务端的拙劣模仿，有看到这样的形容</p><p><strong>糕糕：</strong>对的，然后 Gamemode Gamestate都是继承actor的，Gamemode仅在服务端上生成，不复制到客户端，Gamestate在所有端均生成，以服务端为准，其他为复制品</p><p><strong>四月：</strong>噢噢原来是这样，那关卡蓝图呢</p><p><strong>糕糕：</strong>关卡蓝图纯本地，一般不使用关卡蓝图，关卡蓝图不是Actor哦</p><p><strong>四月：</strong>原来是这样</p><p><strong>糕糕：</strong>Gamemode是UE的Gameplay框架的一部分，所以 Gamemode 的设置里的这些东西也是</p><p><strong>糕糕：</strong>先不看Pawn，先看PlayerController，只在拥有的客户端上生成，服务端拥有所有客户端的 PlayerController，所以，玩家在自己的PlayerController，修改了值啊，执行了什么事件啊之类的，只有服务器知道，其他客户端是不知道的，所以又来了个PlayerState</p><p><strong>四月：</strong>啊这</p><p><strong>糕糕：</strong><a href="https://docs.unrealengine.com/4.27/zh-CN/InteractiveExperiences/Framework/">https://docs.unrealengine.com/4.27/zh-CN/InteractiveExperiences/Framework/</a></p><p>你的问题文档都有，只是“计分多人游戏框架”这件事是我自己总结的，网上没有的，你先理解了这个定义，用这个定义去理解他的框架应该会更容易些，不然容易误解某些功能233。</p><p><strong>四月：</strong>虚幻引擎真的好难学啊</p><p><strong>糕糕：</strong>成也Gameplay框架败也Gameplay框架，成在，你作为没有经验的，不是架构师，理解它用它，就能出游戏了；</p><p>成在，你作为没有经验的，不是架构师，理解它用它，就能出游戏了。</p><p><strong>四月：</strong>我该怎么做呜呜呜呜</p><p><strong>糕糕：</strong>开整！现在就用它整个多人联机fps</p><p><strong>糕糕：</strong>Gamemode用来写当前游戏模式的服务器要执行的事件，比如LOL，假如在10分钟出大龙，这件事就是写Gamemode里的。</p><p>而游戏已经进行了10分钟，大龙已经被击杀了多少次，是在Gamestate里面。</p><p><strong>四月：</strong>gamemode是写事件，state是记录信息条件，这样吗</p><p><strong>糕糕：</strong>这样，大龙例子不是很好，那就红buff吧。红BUFF有个特点，你没视野的时候被打死，你不知道红BUFF没了。没错，他的生成和存在状态就是存Gamemode里的。</p><p><strong>四月：</strong>所有野怪都这样</p><p><strong>糕糕：</strong>因为Gamemode不在客户端同步，你可以设置只在客户端有视野的时候，Gamemode才把对应状态通过RPC发过去</p><p><strong>四月：</strong>那gamestate还是记信息嘛，每个客户端一份，然后服务端的是真的，其他都是复制品</p><p><strong>糕糕：</strong>嗯，gamestate记全场客户端人尽皆知的事，游戏持续时间……大逃杀的话，剩余人数。但如果是LOL的话，</p><p>玩家杀人数可以记到gamestate，但是补刀数 装备在 playerstate，可以理解吗</p><p><strong>四月：</strong>不太理解诶，补刀数不是和杀人数战绩按理说不是一样的吗</p><p><strong>糕糕：</strong>不一样的哦，你观察下打野英雄，不露脸不显示补刀数的，防止你知道打野英雄的发育情况了</p><p><strong>四月：</strong>噢噢，所以补刀并不是全场客户端人尽皆知的事情，所以就并不是记录在Gametate而是在Playerstate里面。这样我就明白了</p><hr><p>这个专栏感觉还是很生动的，打算以一星期一次的频率更新一次（前提是有提问）</p><p>这一期太长了剩下就放到下一期来吧！2022.3.7</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在ue方面笔者完全是个萌新，糕糕前辈在我进入某大佬群时主动加了我的好友（现在想来感动的能哭出声）&lt;/p&gt;
&lt;p&gt;在我学习ue时不吝赐教，为我提供了许多资料，语气也十分的和蔼温柔&lt;/p&gt;
&lt;p&gt;每次遇到什么问题发消息几乎都是秒回，解答了我的许多疑惑（我哭死）&lt;/p&gt;
&lt;p&gt;这篇博客会做成一个对话的专栏形式，会记录一些前期学习遇到的疑问&lt;/p&gt;
&lt;p&gt;不会有固定的大纲，记录的风格是诙谐轻松的（顺利的话会一直写下去？）&lt;/p&gt;
&lt;p&gt;最重要的是这些遇到并得到解答的问题我不希望今天获取然后明天就失忆了&lt;/p&gt;
&lt;p&gt;这些知识对初学者应该是很有帮助的（确信），所以我很乐意记录这样一个快乐的过程&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>主流抗锯齿方案对比</title>
    <link href="https://aprilnavi.github.io/2022/03/04/%E4%B8%BB%E6%B5%81%E6%8A%97%E9%94%AF%E9%BD%BF%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94/"/>
    <id>https://aprilnavi.github.io/2022/03/04/%E4%B8%BB%E6%B5%81%E6%8A%97%E9%94%AF%E9%BD%BF%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94/</id>
    <published>2022-03-04T11:00:58.000Z</published>
    <updated>2022-03-04T11:01:59.010Z</updated>
    
    <content type="html"><![CDATA[<p>感觉这个坑对于经常玩游戏的玩家应该还算有一点吸引力</p><p>因为笔者最近在研究opengl的时候做到了离屏msaa的部分</p><p>觉得如果能自己好好学习一下抗锯齿的几种类型并简要的介绍一下</p><p>想必对自己学习历程一定会有很大的帮助</p><span id="more"></span><p>我们不会在这里阐述锯齿产生的原因，详见games101 P6的那节，同时我们假设读者都了解熟悉光栅化的过程</p><p>我们也不会拿源码出来讲解抗锯齿的实际使用</p><p>（PS：确实除了msaa其他都没做过，可能会把opengl做离屏msaa那一章拿出来讲解一下）</p><p>本篇内容当然还是以网上的内容摘要总结为主（其实就是写给自己复习用的）</p><p>我们会尽量从原理和优缺点分析这些抗锯齿方案。</p><h1 id="MSAA，SSAA"><a href="#MSAA，SSAA" class="headerlink" title="MSAA，SSAA"></a>MSAA，SSAA</h1><p><strong>MSAA（MultiSampling Anti-Aliasing）（多重采样反走样）</strong></p><p><strong>SSAA（Super-Sampling Anti-Aliasing）（超级采样反走样）</strong></p><p>从名字我们就能很容易看出两种抗锯齿采取的办法是在增加了采样的次数</p><p>msaa和ssaa我认为是相似的，虽然他们只在对子像素点处理方式上有着细微区别</p><p>但所耗费的开销差别的巨大的，这也因此让ssaa直接就退出了历史舞台，因此我们会细嗦MSAA</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>他们的具体做法都是在一个像素内增加子像素点，ssaa会对每个子像素点都进行一次单独的着色计算</p><p>在最后将子像素点的颜色合并到对应的像素点。SSAA是最直接也是效果最好的抗锯齿方法。</p><p>像素本身就是计算机图像的最小不可分最小的单位，所以会将整个纹理拉大到更高倍数的缓存上进行采样</p><p>以常见的SSAAx4为例，在面对一张需要以1920x1080（1080P）像素渲染的画面时</p><p>SSAA会首先渲染一张尺寸为3840x2160（4K）像素的缓存，再在这种长宽都乘以2的画面上进行采样</p><p>采样的精度和效果当然是最理想的，但是也可以想象，这种对于硬件资源的消耗非常大，成本也非常高。</p><hr><p>MSAA出于性能考虑，同一个像素上的多个子像素点，不会每个都进行一次像素着色计算</p><p>而是共享像素中心点的像素计算结果。</p><p>对于每个像素点，如果上面对应的子像素点至少有一个通过了覆盖测试，就会进行<strong>一次</strong>采样</p><p>计算的插值采样位置是像素的中心位置。一次采样的结果，会用于多个次像素采样点中。</p><p>计算完成后，每个通过覆盖测试的次像素点还需要进行 <strong>depth-stencil test/深度-模板测试</strong></p><p>这个测试和普通的单个像素的深度-模板测试是一样的，只是现在发生在次像素点而已。</p><p>当深度-模板测试通过后，在像素中心位置采样的结果值就会写入到对应的次像素点。</p><hr><p>使用MSAA是比较简单的，重要工作都是 GPU 来自动完成的，我们只需要使用即可。</p><p>在 OpengGL 中，使用 MSAA 只需要将 FrameBuffer 的格式设置成相应的 NxMSAA 格式</p><p>将 FrameBuffer 作为渲染输出，就是 MSAA的效果。</p><p>将 MSAA 格式贴图 Blit 到普通的格式，OpenGL 会自动完成 resolve 的工作。</p><p>我们使用 MSAA 时也要注意，要尽量避免过多地进行 resolve 操作</p><p>比如经常将 MSAA 格式贴图作为贴图输入，又作为 RenderTarget 来输出。这样会不断进行 resovle 操作，造成额外的性能消耗。</p><p>（草这说的好像就是我）</p><p>如果是使用现代的图形 API，则一般需要显式地调用 resolve，整个过程也更加可控。</p><p>（懂了opengl不算现代图形api）</p><hr><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：使用简单方便，效果好。</p><p>缺点：因为是在光栅化阶段做的抗锯齿，抗锯齿这部分是由硬件完成的，会额外消耗大量内存和带宽</p><p>对于延迟渲染来说，GBuffer 本身就已经很大了，如果再使用 MSAA，额外的带宽消耗极大。</p><p>因此延迟渲染一般不会使用 MSAA来作为实现抗锯齿手段。</p><p>而目前大部分 PC 端游戏都是基于延迟渲染管线的，包括Unity 的 HDRP ，所以 PC 游戏一般不会使用 MSAA。</p><p>（因为自己没做过延迟渲染，所以关于延迟渲染的部分是抄的网上的233333）</p><hr><h1 id="FXAA"><a href="#FXAA" class="headerlink" title="FXAA"></a>FXAA</h1><p><strong>FXAA（Fast Approximate Anti-Aliasing）（快速近似抗锯齿）</strong></p><p>它是传统MSAA（多重采样抗锯齿）效果的一种高性能近似值。运行于目标游戏渲染管线的后期处理阶段</p><p>它只是单纯的后期处理着色器，不依赖于任何GPU计算API。</p><p>正因为如此，FXAA技术对显卡没有特殊要求，完全兼容NVIDIA、AMD的不同显卡(MLAA仅支持A卡)和DX9、DX10、DX11。</p><h2 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h2><p>除了增加每个像素点的采样数，我们实现抗锯齿的另一种方式就是后处理。</p><p>考虑到大部分情况下，我们想要抗锯齿的部分，其实都只是在物体边缘或者高光变化的部分</p><p>我们通过后处理的方式，找出图像块之间的边缘，然后根据边缘信息对边缘两侧的图像进行混合处理，达到抗锯齿的效果。</p><p>这类基于后处理的抗锯齿方式也叫做<strong>形变抗锯齿/Morphological antialiasing</strong></p><p>但是任何事物都是辩证的，正如同其名，FXAA毕竟是一种“比较廉价”的抗锯齿技术</p><p>在大多数的游戏应用中，效果终究不及传统的MSAA，适用于性能不高的电脑配置。</p><p>具体的FXAA算法可以看这篇优质博客：</p><p><a href="https://zhuanlan.zhihu.com/p/431384101">主流抗锯齿方案详解（三）FXAA - 知乎 (zhihu.com)</a></p><p>（其实很多观点也是扒的人家和百度百科的，这位作者的文真的给了我很大的启发，有机会的话建议都好好读一遍）</p><h2 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：FXAA 的优点就是集成比较方便，只需要一个 Pass 来实现抗锯齿，</p><p>同时提供了quality和console两个版本，是目前手机上的最常用的抗锯齿方式。</p><p>缺点：FXAA在带来超快速运算的同时，也带来了精度和质量上的损失。</p><p>而且由于FXAA是基于后处理判断边界来实现的，因此没有次像素特性，在光照高频(颜色变化很快)的地方会不稳定。</p><p>单独看静态的场景没有问题，但是移动摄影机时，就会导致一些闪烁。</p><hr><h1 id="TAA"><a href="#TAA" class="headerlink" title="TAA"></a>TAA</h1><hr><h1 id="SMAA"><a href="#SMAA" class="headerlink" title="SMAA"></a>SMAA</h1><hr><h1 id="DLSS"><a href="#DLSS" class="headerlink" title="DLSS"></a>DLSS</h1><hr><p>很多很多内容都来自，谢谢这位作者，仅做自己学习记录之用，若有雷同，无意冒犯</p><p><a href="https://www.zhihu.com/column/c_1210266723531976704">实时渲染学习笔记 - 知乎 (zhihu.com)</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;感觉这个坑对于经常玩游戏的玩家应该还算有一点吸引力&lt;/p&gt;
&lt;p&gt;因为笔者最近在研究opengl的时候做到了离屏msaa的部分&lt;/p&gt;
&lt;p&gt;觉得如果能自己好好学习一下抗锯齿的几种类型并简要的介绍一下&lt;/p&gt;
&lt;p&gt;想必对自己学习历程一定会有很大的帮助&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>游戏引擎架构精要（才怪）②</title>
    <link href="https://aprilnavi.github.io/2022/03/03/2022-03-03-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A1/"/>
    <id>https://aprilnavi.github.io/2022/03/03/2022-03-03-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A1/</id>
    <published>2022-03-03T13:36:58.000Z</published>
    <updated>2022-03-03T14:25:58.451Z</updated>
    
    <content type="html"><![CDATA[<p>《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。</p><p>但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，</p><p>以及n个自己给自己找的理由，让这个阅读计划一直搁置。</p><p>但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多</p><p>再加上自己有意往引擎方向发展，阅读这本书就提上了日程。</p><span id="more"></span><hr><h1 id="第四章-三维数学"><a href="#第四章-三维数学" class="headerlink" title="第四章  三维数学"></a>第四章  三维数学</h1><p>第四章基本上是三维数学，包括了点，矢量，矩阵，坐标系，以及他们的运算</p><p>这些数学内容不着重描写，可以在之前计算机图形学的博客温习。</p><p>这一章会主要谈谈四元数的特点，和其他旋转表示方式的比较。</p><h2 id="4-4-四元数"><a href="#4-4-四元数" class="headerlink" title="4.4 四元数"></a>4.4 四元数</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>我们可以用3x3的矩阵来表示旋转，但旋转只有三个自由度（pitch,yaw,roll）,用9个float来表示旋转很显然是冗余的</p><p>四元数可以表达为</p><p><img src="/images/loading.jpg" data-original="/2022/03/03/2022-03-03-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A1/image-20220303222511659.png" alt="image-20220303222511659"></p><p>其中只有单位长度的四元数能表达三维函数（四元数算式太难打了不打了）</p><p>四元数可以理解成一个矢量一个标量，一个轴（矢量）和一个角度。</p><hr><h3 id="运算"><a href="#运算" class="headerlink" title="运算"></a>运算</h3><p>四元数进行加法是不能表达旋转的，因为这样就不符合单位长度了。</p><p>给定两个四元数p和q表达旋转P和旋转Q，则pq就表示P和Q的组合旋转。</p><p>四元数求逆写为q-1（自动脑补上标-1），逆四元数和原四元数的乘积为标量1</p><p>共轭四元数q*相当于原四元数的矢量部分取负号，在单位长度的情况下，共轭四元数和逆四元数相等（）</p><p>因此计算逆四元数比计算3x3逆矩阵快很多，可以利用这一特点优化引擎。</p><p>具体和矢量的旋转运算见原书p180，任何三维旋转都可以在3x3矩阵和四元数之间随意自由转换。</p><hr><h3 id="插值"><a href="#插值" class="headerlink" title="插值"></a>插值</h3><p>四元数对比矩阵和欧拉角最大的优越在于插值方便</p><p>四元数的插值有线性插值（LERP）和球面线性插值（SLERP）两种。</p><p>SLERP对比LERP有更准确的结果，但开销更大更加昂贵，使用哪种插值还有待商榷。</p><hr><h2 id="4-5-比较各种旋转方式"><a href="#4-5-比较各种旋转方式" class="headerlink" title="4.5 比较各种旋转方式"></a>4.5 比较各种旋转方式</h2><h3 id="欧拉角"><a href="#欧拉角" class="headerlink" title="欧拉角"></a>欧拉角</h3><p>欧拉角能表示旋转，由三个标量（pitch,yaw,roll）组成，会用一个三维矢量表示</p><p>优势：简单小巧（3个float），直观，便于理解，对于某个轴的插值只需要对对应的标量做插值</p><p>缺陷：对任意方向的旋转做不了插值；万向节死锁；领域没有通用的旋转次序，不能定义一个确定的旋转，旋转的先后次序对结果有影响；</p><hr><h3 id="3x3矩阵"><a href="#3x3矩阵" class="headerlink" title="3x3矩阵"></a>3x3矩阵</h3><p>3x3矩阵是有效表达旋转的方式，不受万向节死锁影响</p><p>优势：可以确切的独一无二的表达旋转，CPU和GPU有内建支持可以硬件加速运算，纯旋转的转置矩阵为逆矩阵</p><p>缺陷：旋转矩阵不够直观，不容易想象成对应的空间变换；旋转矩阵不容易插值；相对欧拉角（3个float）旋转矩阵需要9个float。</p><hr><h3 id="轴角"><a href="#轴角" class="headerlink" title="轴角"></a>轴角</h3><p>一个以单位矢量定义的旋转轴，再加上一个标量定义的旋转角</p><p>优势：直观，紧凑（4个float），确定了左右手就能确切表示旋转</p><p>缺陷：无法直接简单的进行插值，轴角形式的旋转也不能直接施加于矢量，必须转化为矩阵或四元数</p><hr><h3 id="四元数"><a href="#四元数" class="headerlink" title="四元数"></a>四元数</h3><p>形式与轴角相似，与轴角的区别是四元数的旋转轴矢量的长度为旋转角的一半的正弦，第四分量不是旋转角而是旋转半角的余弦。</p><p>优势：能串接旋转，可以轻易插值，只需要储存4个float，可以和矩阵自由转换，无所不能</p><p>缺陷：难学（确信）</p><hr><h1 id="第五章-游戏支持系统"><a href="#第五章-游戏支持系统" class="headerlink" title="第五章  游戏支持系统"></a>第五章  游戏支持系统</h1><h2 id="5-1-子系统的启动和终止"><a href="#5-1-子系统的启动和终止" class="headerlink" title="5.1 子系统的启动和终止"></a>5.1 子系统的启动和终止</h2><p>游戏引擎是一个复杂工程，必须按照各个系统的依赖关系进行加载和卸载。</p><hr><h3 id="c-的静态初始化（行不通哒）"><a href="#c-的静态初始化（行不通哒）" class="headerlink" title="c++的静态初始化（行不通哒）"></a>c++的静态初始化（行不通哒）</h3><p>游戏引擎大部分为c++编写，原生的启动是否可以作为启动用？</p><p>众所周知全局和静态对象是在main函数之前初始化的，我们无法预知他们构造的次序，因此是行不通的。</p><hr><h3 id="按需构建（还是行不通哒）"><a href="#按需构建（还是行不通哒）" class="headerlink" title="按需构建（还是行不通哒）"></a>按需构建（还是行不通哒）</h3><p>在c++中，类中声明的静态变量只会在第一次调用时构造，我们创建静态变量就能控制全局单例的构造次序。</p><p>但此方法无法控制析构次序，</p><hr><h3 id="在单例管理器中定义启动和终止函数（盘他）"><a href="#在单例管理器中定义启动和终止函数（盘他）" class="headerlink" title="在单例管理器中定义启动和终止函数（盘他）"></a>在单例管理器中定义启动和终止函数（盘他）</h3><p>放弃使用构造函数和析构函数，这两个函数让他们去摸鱼</p><p>我们自己定义并按所需的明确顺序调动各启动和终止函数。</p><pre><code>class RenderManager&#123;  public:   RenderManager()   &#123;      //摸鱼   &#125;   ~RenderManager()   &#123;      //摸鱼   &#125;      void startUP()   &#123;      //启动管理器   &#125;         void ShutDown()   &#123;      //终止管理器   &#125;&#125;.....class AnimationManager&#123;....&#125;//巴拉巴拉...RenderManager gRenderManager;AnimationManager gAnimationManager;//巴拉巴拉...int main()&#123;    gRenderManager.startUP();    gAnimationManager.startUP();        //运行游戏        gAnimationManager.ShutDown();    gRenderManager.ShutDown();       //以相反的次序终止各系统&#125;</code></pre><hr><h2 id="5-2-内存管理"><a href="#5-2-内存管理" class="headerlink" title="5.2 内存管理"></a>5.2 内存管理</h2><p>通过malloc和free或者new/delete来动态申请内存（堆分配），是非常慢的操作</p><p>原因是堆分配器是一个通用的设施，必须能处理任何大小的请求，需要大量管理开销（众所周知越通用的东西就越不高效越不强大）</p><p>在多数操作系统中，动态分配内存会使得从用户态切换到核心态（好耶刚刚学）</p><p>ue在内存方面是怎么处理的则在另一篇博客新坑有比较详细的说明</p><hr><h3 id="基于堆的分配器"><a href="#基于堆的分配器" class="headerlink" title="基于堆的分配器"></a>基于堆的分配器</h3><p>分配一大段连续内存，安排一个指向堆顶部的指针，用来标识已分配的和未分配的空间</p><p>进行分配时，只需要把指针往上移动请求所需的字节数即可。释放空间时，记得以进行分配时相反的次序进行释放</p><p>可以编写一个函数，把堆顶指针回滚到上一次标记的位置，即释放回滚点之后到堆顶的所有内存</p><p>伪代码可以在原书p220查看</p><hr><h3 id="双端堆分配器"><a href="#双端堆分配器" class="headerlink" title="双端堆分配器"></a>双端堆分配器</h3><p>将一块内存给两个分配器使用，一个从底端向上分配，另一个从顶端向下分配。</p><p>这个方案很实用，因为允许权衡两个堆栈的使用，因此能更有效的运用内存。</p><hr><h3 id="池分配器"><a href="#池分配器" class="headerlink" title="池分配器"></a>池分配器</h3><p>在分配大量同等大小的小块内存时（矩阵，迭代器，可渲染的网格实例），池分配器则是不二之选。</p><p>做法是预先分配一大块内存，大小刚好是元素分配内存大小的倍数。</p><p>例如4x4矩阵池就是16个元素乘以每个元素4字节（32位float）或8字节（64位double）。</p><p>（ps：原书的意思应该是这个池本身是一个4x4矩阵的形状，用来存放16个元素，而非储存一个4x4矩阵）</p><p>收到分配请求时只需要取出元素，释放则只需要回收回池中，分配和释放都是O(1)的操作。</p><hr><h3 id="含对齐功能的分配器"><a href="#含对齐功能的分配器" class="headerlink" title="含对齐功能的分配器"></a>含对齐功能的分配器</h3><p>所有内存分配器都传回对齐的内存块（具体实现伪代码在原书p223有详解）</p><p>对齐的内存块能让CPU更加高效的读写。</p><hr><h3 id="单帧和双缓冲内存分配器"><a href="#单帧和双缓冲内存分配器" class="headerlink" title="单帧和双缓冲内存分配器"></a>单帧和双缓冲内存分配器</h3><p>几乎引擎都会在游戏循环中分配一些临时用的数据，要么在这次循环中丢弃，要么在下一次迭代丢弃。</p><p><strong>单帧分配器</strong>的做法是先预留一块内存，并以前文所述的基于堆的分配器分配，在每一帧开始时将顶端指针重新定向到内存块的底端地址。</p><p>益处是分配的这块内存永远会在循环中重置，不需要我们手动释放，也极其高效</p><p>但我们必须注意决不能将指向单帧内存块的指针跨帧使用（nullptr警告）</p><p><strong>双缓冲分配器</strong>允许在第i帧分配的内存块用于i+1帧，实现则是简历两个相同尺寸的单帧堆分配器，每帧交替使用</p><p>在缓存非同步处理的结果时，这类分配器极其有用。双缓冲模式在渲染里因为可以解决画面撕裂的问题得到了广泛应用</p><p>我们在当帧完成前将结果写入缓存，在下一帧时缓冲处于不活跃状态，我们依然可以安心使用数据。</p><hr><p>今天看到内存管理的部分就没怎么看了，原因是和糕糕老师聊ue的内存管理这部分聊了很多有意思的东西，一不注意时间就过去了。</p><p>不过感觉今天收获还是不少滴，吸收的也还可以，日后想动手自己实现一个内存管理方案了。2022/3/3</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。&lt;/p&gt;
&lt;p&gt;但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，&lt;/p&gt;
&lt;p&gt;以及n个自己给自己找的理由，让这个阅读计划一直搁置。&lt;/p&gt;
&lt;p&gt;但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多&lt;/p&gt;
&lt;p&gt;再加上自己有意往引擎方向发展，阅读这本书就提上了日程。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>游戏引擎架构精要（才怪）①</title>
    <link href="https://aprilnavi.github.io/2022/03/01/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A0/"/>
    <id>https://aprilnavi.github.io/2022/03/01/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A0/</id>
    <published>2022-03-01T13:36:58.000Z</published>
    <updated>2022-03-03T13:04:20.103Z</updated>
    
    <content type="html"><![CDATA[<p>《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。</p><p>但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，</p><p>以及n个自己给自己找的理由，让这个阅读计划一直搁置。</p><p>但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多</p><p>再加上自己有意往引擎方向发展，阅读这本书就提上了日程。</p><span id="more"></span><p>既然它这么厚，那囫囵吞枣看完就忘肯定都是不行的，所以还是写点东西记一下吧</p><p>之前有粗读一下这本书，书的内容是复杂，综合，全面的，每个章节都涵盖了大量的内容</p><p>以目前的能力没法很好的概括提及，没有像之前记录《游戏编程模式》那样有固定的写作框架</p><p>所以这篇博客的形式可能还是更倾向读书笔记而非对他人有意义的知识总结</p><p>所以现在这些废话基本上是写给自己看的hhh</p><hr><h1 id="第一章-基础"><a href="#第一章-基础" class="headerlink" title="第一章  基础"></a>第一章  基础</h1><p>导论，游戏介绍，不同游戏类型所使用的引擎差异，游戏引擎概述，没什么好说的，工具及资产管道，略</p><p><img src="/images/loading.jpg" data-original="/2022/03/01/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A0/VDMX@PP27ZW40Z1U9O%257XC.png" alt="img"></p><p>第一章里面感觉这张图既经典又重要，丢一篇米忽悠大佬的文</p><p><a href="https://zhuanlan.zhihu.com/p/356028087">从零手写游戏引擎2：引擎架构概述 - 知乎 (zhihu.com)</a></p><p>大佬评价这本书游戏开发领域尤其是客户端开发必看书籍，也是一本偏入门和科普性质的书籍。</p><p>看来这个入门还是让我蛮吃力的hhh。</p><hr><h1 id="第二章-专业工具"><a href="#第二章-专业工具" class="headerlink" title="第二章  专业工具"></a>第二章  专业工具</h1><h2 id="2-1-版本控制"><a href="#2-1-版本控制" class="headerlink" title="2.1 版本控制"></a>2.1 版本控制</h2><p>git，会用就行，命令行要用再查，略</p><h2 id="2-2-visual-studio常见功能"><a href="#2-2-visual-studio常见功能" class="headerlink" title="2.2 visual studio常见功能"></a>2.2 visual studio常见功能</h2><h3 id="生成配置"><a href="#生成配置" class="headerlink" title="生成配置"></a>生成配置</h3><p><img src="/images/loading.jpg" data-original="/2022/03/01/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A0/image-20220301203453167.png" alt="image-20220301203453167"></p><p>可以在生成配置里面设定不同的预处理器，编译器，链接器属性</p><p><strong>预处理器设置</strong>处理#include文件的展开，以及处理#define宏的定义和替换</p><p><strong>编译器设置</strong>控制产生的对象文件是否包含调试信息，是最常见的编译选项之一，也可以控制是否展开内联函数。</p><p><strong>链接器设置</strong>指定将哪些外部库链接到可执行文件，以及搜索路径</p><p>一般项目自带”调试（debug）“和”发布（release）“配置。</p><h3 id="常规属性页设置"><a href="#常规属性页设置" class="headerlink" title="常规属性页设置"></a>常规属性页设置</h3><p>随便打开一个项目的属性就能进入常规属性设置页面，里面有输出目录，中间目录各种目录的说明。</p><h3 id="调试代码"><a href="#调试代码" class="headerlink" title="调试代码"></a>调试代码</h3><p>我一直觉得调试代码是很重要的功能，希望可以借着记录要点和操作慢慢理解增进</p><ul><li><p>一个解决方案可能包含多个项目，记得正确设置启动项目。</p></li><li><p>断点（breakpoint）是代码调试的基本所需，能让代码停下观察此刻的运行状态。</p></li><li><p>F5 开始调试，F10 逐过程运行（不进入函数调用），F11 逐语句运行（进入函数调用）</p></li></ul><p><img src="/images/loading.jpg" data-original="/2022/03/01/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A0/image-20220301210551736.png" alt="image-20220301210551736"></p><p><img src="/images/loading.jpg" data-original="/2022/03/01/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A0/image-20220301210657028.png" alt="image-20220301210657028"></p><p>运行中可以如图所示调出许多窗口用于观察变量或者变量地址，函数堆栈情况。</p><p>其中监视窗口是个很有意思的功能，有机会可以多多尝试。</p><p>数据断点也是个很有用的功能，可以在指定地址或者被写入时引发一个中断</p><p>（vs2022没有找到条件断点，但找到了函数断点）</p><p><img src="/images/loading.jpg" data-original="/2022/03/01/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A0/image-20220301211906610.png" alt="image-20220301211906610"></p><h2 id="2-3-剖析工具"><a href="#2-3-剖析工具" class="headerlink" title="2.3 剖析工具"></a>2.3 剖析工具</h2><p>剖析器（profiler）可以度量代码的执行时间，并能告知每个函数所花的时间。</p><ul><li>统计式剖析器：几乎不影响目标代码的执行速度，原理是周期为CPU的程序计数器寄存器进行采样。</li><li>测控式剖析器：提供最详细最精确的计时数据，代码几乎跑不动。</li></ul><hr><h1 id="第三章-游戏软件工程基础"><a href="#第三章-游戏软件工程基础" class="headerlink" title="第三章  游戏软件工程基础"></a>第三章  游戏软件工程基础</h1><p>3.1说的是cpp的语法以及cpp11的一些特性</p><p>3.2则聊了聊一些比较深的东西，例如多态和虚函数表，拷贝和移动语义，内存布局</p><p>这些内容早在背八股文的时候都记牢了也理解了，没有什么有意思的内容</p><h2 id="3-3-捕捉和错误处理"><a href="#3-3-捕捉和错误处理" class="headerlink" title="3.3 捕捉和错误处理"></a>3.3 捕捉和错误处理</h2><p>错误分为用户错误和程序员错误，用户错误指用户做了不正确的事情引发的错误</p><p>例如无效键入，尝试打开不存在的文件，我们这里只讨论程序员错误。</p><p>程序员错误的处理应该以立即中止程序并提供调试信息为原则。</p><ul><li><p>错误返回码：当函数执行错误时返回一个不可能的值，最好可以返回一个枚举值。缺点是堆栈里的函数观察到错误时，其他函数都要添加代码。</p></li><li><p>异常：可以检测错误函数，并把相关错误储存于某对象，缺点是异常处理会有一些额外的开销，一个函数使用了异常整个程序都得使用异常。</p></li><li><p>断言：当表达式为假时，暂停程序打印错误信息。断言可以用宏实现，UE引擎则自带断言功能。</p></li></ul><p>3.4说的是流水线，缓存以及优化，这些涉及到硬件架构的内容目前对我来说太硬核了，往后稍稍。</p><hr><p>今天就到这里吧，第四章基本上都是三维数学相关的内容，里面矢量，矩阵，坐标系那些的内容也是基本上滚瓜烂熟了</p><p>第四章中比较感兴趣的是四元数，奈何今天看到的时候没看明白233333</p><p>2022.3.1 ——21：32</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。&lt;/p&gt;
&lt;p&gt;但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，&lt;/p&gt;
&lt;p&gt;以及n个自己给自己找的理由，让这个阅读计划一直搁置。&lt;/p&gt;
&lt;p&gt;但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多&lt;/p&gt;
&lt;p&gt;再加上自己有意往引擎方向发展，阅读这本书就提上了日程。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>第二周学习日志（log for touching fish）</title>
    <link href="https://aprilnavi.github.io/2022/02/28/%E7%AC%AC%E4%BA%8C%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/"/>
    <id>https://aprilnavi.github.io/2022/02/28/%E7%AC%AC%E4%BA%8C%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/</id>
    <published>2022-02-28T04:31:47.000Z</published>
    <updated>2022-03-04T12:03:40.236Z</updated>
    
    <content type="html"><![CDATA[<p>开学啦开学啦</p><span id="more"></span><h2 id="Monday"><a href="#Monday" class="headerlink" title="Monday"></a>Monday</h2><p>早上算是效率还不错的，虽然其实做了并没有特别多的事情</p><p>我想想好像成功导入了imgui的库跑起来了，找了个光酱的obj渲了出来</p><p>虽然具体怎么运行还需要再研究研究，但明天不打算花时间了，周末有时间再看看吧</p><p>这样想想其实并没有做什么事，但好在人的精神很好，心情也不错，</p><p>初学渲染的时候总是这样充满精神的，这样让我觉得正反馈很强。</p><hr><p>下午去图书馆看了引擎架构，一边聊天一边摸鱼看书，心情还是不错的</p><p>目前为止有些计算机硬件的东西看不明白但感觉应该对我目前不太重要</p><p>有些关于vs调试的知识感觉对我确实不错，之后可能会出篇博客记录一下</p><p>下午看到3.7要补考软测了，爷tx实习都拿了还要补考真是醉了555</p><hr><p>晚上开始有点迷茫了吧，得失心还是太重了。</p><p>每当学习一段时间如果没能感到进步或者有学到知识</p><p>不免就会觉得浪费了时间而感到焦虑。</p><p>而迄今为止依然没有找到学习虚幻4的好办法</p><p>国内没有一个系统的教科书的教程供高效学习，同时自己的实操能力也很差</p><p>可能更偏向传统的一步一步带着走的教程而非开源资源教学</p><p>再加上自己也想好好的研究下UE引擎的源码还有其他方面的东西</p><p>不免觉得自己的脑子犹如石沉大海，感觉这方面就算手搓了个demo也还是个新手</p><p>要学的东西太多了||同学比我厉害看的书比我多||转正要做MiniGame但我gameplay半桶水</p><p>但好在每当我开始写作，心情就会好起来。待会再去肝会xb2吧，反正其他人不也都在老头环23333。</p><hr><h2 id="Tuesday"><a href="#Tuesday" class="headerlink" title="Tuesday"></a>Tuesday</h2><p>虽然昨天两点才睡，但早上精神依旧很好</p><p>第一节课改geometry给hikari酱做了一个法线可视化，就像毛毛人一样</p><p>也印证了assimp的法线导入是没问题的，有机会把之前项目改改重新做吧</p><p>随后是做instancing章节做到一半，后边会渲出一个实时旋转的行星带场景</p><p>还是挺让人期待的，明天上午没课就做这个吧（熬夜打xb睡很晚也有可能）</p><p>第二节课猛看os，感觉os基本上掌握就只是时间问题</p><hr><p>中午打原神打到忘记午睡了，下午第一节课看了会os就趴桌上睡了</p><p>醒来看了线程进程，摸了会鱼玩手机和ieg的前辈姐姐聊了聊时间就过了</p><p>后边去图书馆遇到了班里的很多老熟人，这两天听身边同学耳闻也基本上开始面试找工作了</p><p>发现班里努力的人还是不少的（虽然总是那几个），不过大三下了这是理所当然的</p><p>总是觉得能拿到魔方offer然后兴趣驱动学习的自己真幸运</p><p>还是要一步一步脚踏实地的来，走好每一步路珍惜这个机会</p><p>下午看引擎架构基本上看在了三维数学上，就看了一个多小时六七十页的样子</p><p>五点想着回宿舍记录一下博客吧，接着就凹了两个小时的分。</p><p>不得不说写作真的是正反馈很强的事情，单单看着那堆字就成就感爆棚</p><p>每当学习遇到瓶颈心态失衡的时候，如果不想开摆直接打游戏的话，</p><p>记录一下近期学习的近况也记录一下心情，确实是个很不错的主意</p><p>希望今晚的学习历程一切顺利吧。</p><hr><h2 id="Wednesday"><a href="#Wednesday" class="headerlink" title="Wednesday"></a>Wednesday</h2><p>我的天，昨天忘记记了，写这个已经是周四了</p><p>说起来这周要补考我到现在还没复习也没打印准考证呜呜呜（闲话到此为止！）</p><p>说起来早上没课，感觉想摆一摆，于是就打了一早上深渊，</p><p>打到十一点糕糕老师叫我去A然后我又A到了快亮点</p><p>想了想必须喝杯咖啡赶紧做事了</p><hr><p>这样想想也没有做多少事情</p><p>下午我则是把玩了instancing渲染把玩了很久</p><p>只要是同一个相同的物体在场景里面渲染</p><p>使用instancing渲染就可以用同一个shader减少draw call的次数</p><p>最后渲染了100w个小行星，GPU直接跑满电脑狂转hhh</p><p>接着就是和糕糕老师一边聊ue的一些特性一边做gameplay</p><p>一开始看ue的api感觉是懵的，因为很久没有接触了（别骂了）</p><p>后边感觉手感恢复了很多，做了个黑洞吸东西的功能</p><p>没怎么想就直接做出来了，算是没那么坐牢了</p><hr><p>但是昨天实在太摸鱼了，被刚刚下班的引擎的前辈训斥了</p><p>“刚刚下班就看见你在高强度水群，别水了我都替你着急！”</p><p>呜呜呜瞬间感觉弱小又愧疚，虽然绝对而言我就业可能压力不大</p><p>但在腾讯的23届里面实力我绝对是垫底的，因此确实很珍惜实习生的机会</p><p>因为版号原因，接下来hc会更少的吧，想进大厂基本上也就只有校招这个机会了</p><p>所以感觉压力还是挺大的，昨天做到了十二点才下，做完也没打游戏直接就下了</p><p>希望2022年能有不错的提升，我看那些大我一届的前辈不是在搞神经渲染就是在手写引擎</p><p>一个个全都爆杀我，不过我相信自己的潜力是无穷的！</p><p>（相信的心就是你的魔法）</p><hr><h2 id="Thursday"><a href="#Thursday" class="headerlink" title="Thursday"></a>Thursday</h2><p>对不起我忘记写了完全想不起来了</p><h2 id="Friday"><a href="#Friday" class="headerlink" title="Friday"></a>Friday</h2><p>上午带电脑去教室边摸鱼边做，最后还好是成功把离屏msaa做出来了（摸鱼指打原神）</p><p>（是真的做出来了哦，不是碰巧结果和我做的相似哦）</p><p>中午和糕糕前辈A到了两点，玩了会ns开摆睡到四点半，背电脑到图书馆就是五点了</p><p>于是一直效率爆棚的肝博客肝到了现在（世末歌者是真的好听我超）</p><p>不得不说听歌抖腿效率码字的效率是真的高啊</p><p>写了一篇学习抗锯齿方案的博客，现在在写平时请教年糕前辈的记录</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;开学啦开学啦&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>如何用OpenGL复现Phong模型</title>
    <link href="https://aprilnavi.github.io/2022/01/23/%E5%A6%82%E4%BD%95%E7%94%A8OpenGL%E5%A4%8D%E7%8E%B0phong%E6%A8%A1%E5%9E%8B/"/>
    <id>https://aprilnavi.github.io/2022/01/23/%E5%A6%82%E4%BD%95%E7%94%A8OpenGL%E5%A4%8D%E7%8E%B0phong%E6%A8%A1%E5%9E%8B/</id>
    <published>2022-01-23T11:36:58.000Z</published>
    <updated>2022-01-24T15:25:23.473Z</updated>
    
    <content type="html"><![CDATA[<p>写这篇博客的时候我还在我老家的床上，给自己放了两三天的假，决定写点东西。</p><p>在经历了visual studio的链接失败和着色器编译失败之后</p><p>深感自己力量渺小，无法棒打vs设计师（胡言乱语）</p><p>再加上之前学的有些快而不扎实，复制源码跑动了看一遍就粗略带过（有时甚至跑不动）</p><p>所以写这篇救命博客来挽救一下自己岌岌可危的大脑。</p><span id="more"></span><p><img src="/images/loading.jpg" data-original="/2022/01/23/%E5%A6%82%E4%BD%95%E7%94%A8OpenGL%E5%A4%8D%E7%8E%B0phong%E6%A8%A1%E5%9E%8B/QQ%E5%9B%BE%E7%89%8720220123213125.png" alt="QQ图片20220123213125.png"></p><hr><p>首先先祝贺自己拿到了魔方的暑期实习，已经踏上正轨了但还需努力，毕竟能不能转正，还得看今后发展的如何。但我其实更想从事引擎方面的工作。</p><hr><p>OpenGL的教程是鼎鼎大名的learnOpenGL，中文站做了很棒的翻译工作，强烈安利。</p><p>代码中涉及到封装的函数，类，因为并不重要所以就不予展示。</p><p>更多的是自己温习一个完整OGL渲染程序的不同模块。</p><p>首先让我打开vs找找我的源码，哦对这样可能废话有点多</p><p>但我喜欢这样诙谐的语气记录自己想法，毕竟最后看到这个博客的可能只有我一个人</p><p>总而言之，让我们先看看如何创建一个窗口吧。</p><hr><h2 id="创建窗口部分"><a href="#创建窗口部分" class="headerlink" title="创建窗口部分"></a>创建窗口部分</h2><p>先丢源码，使用的是我们的<strong>寄了废物库</strong>和<strong>glad库</strong>，glad库能让我们更方便的在运行时确定函数地址</p><p>这些代码可以让我们创建一个窗口</p><pre><code class="c++">#include &lt;glad/glad.h&gt;#include &lt;GLFW/glfw3.h&gt;#include &lt;iostream&gt;int main()&#123;    glfwInit();//初始化    glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3);//主版本号    glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3);//副版本号    glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE);//核心渲染模式#ifdef __APPLE__    glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE);#endif    // glfw window creation    // --------------------    GLFWwindow* window = glfwCreateWindow(SCR_WIDTH, SCR_HEIGHT, &quot;Render Window&quot;, NULL, NULL);//new一个窗口对象    if (window == NULL)    &#123;        std::cout &lt;&lt; &quot;Failed to create GLFW window&quot; &lt;&lt; std::endl;        glfwTerminate();        return -1;    &#125;    glfwMakeContextCurrent(window);    glfwSetFramebufferSizeCallback(window, framebuffer_size_callback);//绑定窗口回调函数    glfwSetCursorPosCallback(window, mouse_callback);//绑定鼠标移动视野的函数    glfwSetScrollCallback(window, scroll_callback);//绑定滚轮回调函数    // tell GLFW to capture our mouse    glfwSetInputMode(window, GLFW_CURSOR, GLFW_CURSOR_DISABLED);//捕获鼠标    // glad: load all OpenGL function pointers    // ---------------------------------------    if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress))        //给GLAD传入了用来加载系统相关的OpenGL函数指针地址的函数    &#123;        std::cout &lt;&lt; &quot;Failed to initialize GLAD&quot; &lt;&lt; std::endl;        return -1;    &#125;        ....        //渲染循环    while(!glfwWindowShouldClose(window)) &#123;    ....             processInput(window);//处理输入逻辑    glClearColor(0.1f, 0.1f, 0.1f, 1.0f);//设置清除缓冲的颜色    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);用这个颜色来清除缓冲，顺便也清除深处缓冲            ....               glfwSwapBuffers(window);//交换帧缓冲    glfwPollEvents();//检查并处理各个事件 &#125;        glfwTerminate();    return 0;&#125;</code></pre><p>通过这些代码，应该可以直接创建出一个渲染窗口。</p><hr><p>突然间有点不知道怎么组织复述各个模块了哈哈</p><hr><h2 id="顶点数据"><a href="#顶点数据" class="headerlink" title="顶点数据"></a>顶点数据</h2><p>这里涉及到VAO，VBO，EBO（这里没用到）的概念</p><p>详细了解这三个的概念可以看<a href="https://blog.csdn.net/qq_32974399/article/details/103956589">详解Opengl中VBO和VAO_代码乐的博客-CSDN博客_opengl vao</a></p><p>一言蔽之，vbo<strong>存数据</strong>，vao<strong>存配置信息</strong>，一般先绑vao，然后再把其他东西往上绑</p><p>vao也会把存入的vbo记上，用的时候用vao就行，东西都设置完了最后解绑vao。</p><pre><code class="c++">    float vertices[] = &#123;        // positions          // normals           // texture coords        -0.5f, -0.5f, -0.5f,  0.0f,  0.0f, -1.0f,  0.0f,  0.0f,         0.5f, -0.5f, -0.5f,  0.0f,  0.0f, -1.0f,  1.0f,  0.0f,         0.5f,  0.5f, -0.5f,  0.0f,  0.0f, -1.0f,  1.0f,  1.0f,         0.5f,  0.5f, -0.5f,  0.0f,  0.0f, -1.0f,  1.0f,  1.0f,        -0.5f,  0.5f, -0.5f,  0.0f,  0.0f, -1.0f,  0.0f,  1.0f,        -0.5f, -0.5f, -0.5f,  0.0f,  0.0f, -1.0f,  0.0f,  0.0f,        -0.5f, -0.5f,  0.5f,  0.0f,  0.0f,  1.0f,  0.0f,  0.0f,         0.5f, -0.5f,  0.5f,  0.0f,  0.0f,  1.0f,  1.0f,  0.0f,         0.5f,  0.5f,  0.5f,  0.0f,  0.0f,  1.0f,  1.0f,  1.0f,         0.5f,  0.5f,  0.5f,  0.0f,  0.0f,  1.0f,  1.0f,  1.0f,        -0.5f,  0.5f,  0.5f,  0.0f,  0.0f,  1.0f,  0.0f,  1.0f,        -0.5f, -0.5f,  0.5f,  0.0f,  0.0f,  1.0f,  0.0f,  0.0f,        -0.5f,  0.5f,  0.5f, -1.0f,  0.0f,  0.0f,  1.0f,  0.0f,        -0.5f,  0.5f, -0.5f, -1.0f,  0.0f,  0.0f,  1.0f,  1.0f,        -0.5f, -0.5f, -0.5f, -1.0f,  0.0f,  0.0f,  0.0f,  1.0f,        -0.5f, -0.5f, -0.5f, -1.0f,  0.0f,  0.0f,  0.0f,  1.0f,        -0.5f, -0.5f,  0.5f, -1.0f,  0.0f,  0.0f,  0.0f,  0.0f,        -0.5f,  0.5f,  0.5f, -1.0f,  0.0f,  0.0f,  1.0f,  0.0f,         0.5f,  0.5f,  0.5f,  1.0f,  0.0f,  0.0f,  1.0f,  0.0f,         0.5f,  0.5f, -0.5f,  1.0f,  0.0f,  0.0f,  1.0f,  1.0f,         0.5f, -0.5f, -0.5f,  1.0f,  0.0f,  0.0f,  0.0f,  1.0f,         0.5f, -0.5f, -0.5f,  1.0f,  0.0f,  0.0f,  0.0f,  1.0f,         0.5f, -0.5f,  0.5f,  1.0f,  0.0f,  0.0f,  0.0f,  0.0f,         0.5f,  0.5f,  0.5f,  1.0f,  0.0f,  0.0f,  1.0f,  0.0f,        -0.5f, -0.5f, -0.5f,  0.0f, -1.0f,  0.0f,  0.0f,  1.0f,         0.5f, -0.5f, -0.5f,  0.0f, -1.0f,  0.0f,  1.0f,  1.0f,         0.5f, -0.5f,  0.5f,  0.0f, -1.0f,  0.0f,  1.0f,  0.0f,         0.5f, -0.5f,  0.5f,  0.0f, -1.0f,  0.0f,  1.0f,  0.0f,        -0.5f, -0.5f,  0.5f,  0.0f, -1.0f,  0.0f,  0.0f,  0.0f,        -0.5f, -0.5f, -0.5f,  0.0f, -1.0f,  0.0f,  0.0f,  1.0f,        -0.5f,  0.5f, -0.5f,  0.0f,  1.0f,  0.0f,  0.0f,  1.0f,         0.5f,  0.5f, -0.5f,  0.0f,  1.0f,  0.0f,  1.0f,  1.0f,         0.5f,  0.5f,  0.5f,  0.0f,  1.0f,  0.0f,  1.0f,  0.0f,         0.5f,  0.5f,  0.5f,  0.0f,  1.0f,  0.0f,  1.0f,  0.0f,        -0.5f,  0.5f,  0.5f,  0.0f,  1.0f,  0.0f,  0.0f,  0.0f,        -0.5f,  0.5f, -0.5f,  0.0f,  1.0f,  0.0f,  0.0f,  1.0f    &#125;;//顶点数据，可以不看，但得写出来知道是做什么的    unsigned int VBO, cubeVAO;//生成这俩ID，其中的这个vao是用来管理我们渲染的箱子的    glGenVertexArrays(1, &amp;cubeVAO);//用这个ID生成顶点数组，反正vao就用的这玩意    glGenBuffers(1, &amp;VBO);//用这个ID生成缓冲，是缓冲哦，vbo用这种缓冲，待会其他缓冲也得用这个    glBindBuffer(GL_ARRAY_BUFFER, VBO);//把这份缓冲绑定到显存的那部分真正的缓冲上    glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);//往显存上开始写入顶点数据    glBindVertexArray(cubeVAO);//先把vao绑上，之后配置的各种数据vao都会记录下来    glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)0);    glEnableVertexAttribArray(0);    glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(3 * sizeof(float)));    glEnableVertexAttribArray(1);    glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(6 * sizeof(float)));    glEnableVertexAttribArray(2);//指定着色器怎么解析顶点数据，在下文细说    unsigned int lightCubeVAO;//这是另一个vao哦，这个vao用来管理我们的光源    glGenVertexArrays(1, &amp;lightCubeVAO);//一样的用ID生成    glBindVertexArray(lightCubeVAO);//一样的绑定vao    glBindBuffer(GL_ARRAY_BUFFER, VBO);//一样的绑定缓存，之前把顶点数据写入过一次这次就不写了    // note that we update the lamp&#39;s position attribute&#39;s stride to reflect the updated buffer data    glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)0);    glEnableVertexAttribArray(0);//指定着色器怎么解析顶点数据....    while (!glfwWindowShouldClose(window))    &#123;        ...        lightingShader.use();        //使用被渲染的箱子的着色器程序        ...        //渲染箱子        glBindVertexArray(cubeVAO);//使用这套vao来渲染，vao里面包括了设置好的vbo和配置信息        glDrawArrays(GL_TRIANGLES, 0, 36);//画36个顶点，以画三角形的方式        ...                //使用光源的着色器程序        lightCubeShader.use();        ...        //渲染光源        glBindVertexArray(lightCubeVAO);//同上，不过这个是光源        glDrawArrays(GL_TRIANGLES, 0, 36);                ...    &#125;....    //渲染完成后删除这些数据释放资源    glDeleteVertexArrays(1, &amp;cubeVAO);    glDeleteVertexArrays(1, &amp;lightCubeVAO);    glDeleteBuffers(1, &amp;VBO);</code></pre><p>glGenBuffers和glGenVertexArrays的作用有点像我们new一份空间，然后就用我们指定的指针来管理这份空间一样。</p><p>然后我们再把这份生成的缓存绑定到显存的缓存上，往这份缓存写数据就是往显存写数据。</p><p>VertexArrays就直接绑着就完事了，不用管他，他会自动记录我们做过的事情。</p><hr><p>你应该记得我们的顶点数据一行有八个数据，他们有的是顶点，有的是法线，有的是纹理坐标。</p><p>接着我们是怎么指定着色器来解析数据的呢，还记得这些代码吧</p><pre><code>    glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)0);    glEnableVertexAttribArray(0);    glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(3 * sizeof(float)));    glEnableVertexAttribArray(1);    glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(6 * sizeof(float)));    glEnableVertexAttribArray(2);</code></pre><p>接着让我们看看我们的顶点着色器是怎么导入数据的吧。</p><pre><code>#version 330 corelayout (location = 0) in vec3 aPos;layout (location = 1) in vec3 aNormal;layout (location = 2) in vec2 aTexCoords;</code></pre><p>我们指定了三个不同的位置来导入我们的顶点数据</p><p><code>glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)0);</code></p><p>所做的就是指定顶点着色器的0号位置，3个值，浮点数，一份顶点数据有8个值，我们从偏移量0的开始算</p><p><code>    glEnableVertexAttribArray(0);</code>启用0号顶点数据</p><p>然后我们两个vao分别是所渲染箱子和光源的数据，他们都用的同一套顶点数据（都是正方体）</p><p>但第二个vao只要顶点数据就够了。我们对于两个vao使用不同的shader程序来渲染。</p><hr><h2 id="导入纹理"><a href="#导入纹理" class="headerlink" title="导入纹理"></a>导入纹理</h2><p>导入纹理这块我们用了一个函数来封装，包括怎么从文件读取，设置什么样的环绕方式和过滤方式。</p><p>stb_image.h是一个非常流行的单头文件图像加载库，它能够加载大部分流行的文件格式，并且能够很简单得整合到工程之中。</p><pre><code class="c++">#define STB_IMAGE_IMPLEMENTATION//没加这个宏直接把我害死，编译就一个劲链接错误#include &quot;stb_image.h&quot; //这个头文件glEnable(GL_DEPTH_TEST);//既然提到纹理就记得开启深度测试，要不然会很哈人unsigned int diffuseMap = loadTexture(&quot;container2.png&quot;);unsigned int loadTexture(char const* path)&#123;    unsigned int textureID; //定义一个纹理的ID    glGenTextures(1, &amp;textureID);//生成一个纹理数据，就像上边顶点数据一样    int width, height, nrComponents;//长，宽，颜色通道个数    unsigned char* data = stbi_load(path, &amp;width, &amp;height, &amp;nrComponents, 0);    if (data)    &#123;        GLenum format;//根据颜色通道个数选择纹理格式        if (nrComponents == 1)            format = GL_RED;        else if (nrComponents == 3)            format = GL_RGB;        else if (nrComponents == 4)            format = GL_RGBA;        glBindTexture(GL_TEXTURE_2D, textureID);//在显存上绑定纹理        glTexImage2D(GL_TEXTURE_2D, 0, format, width, height, 0, format, GL_UNSIGNED_BYTE, data);        //第一个参数指定了纹理目标(Target)。设置为GL_TEXTURE_2D意味着会生成与当前绑定的纹理对象在同一个目标上的纹理（任何绑定到GL_TEXTURE_1D和GL_TEXTURE_3D的纹理不会受到影响）。        //第二个参数为纹理指定多级渐远纹理的级别，如果你希望单独手动设置每个多级渐远纹理的级别的话。这里我们填0，也就是基本级别。        //第三个参数告诉OpenGL我们希望把纹理储存为何种格式。        //第四个和第五个参数设置最终的纹理的宽度和高度。我们之前加载图像的时候储存了它们，所以我们使用对应的变量。        //下个参数应该总是被设为0（历史遗留的问题）。        //第七第八个参数定义了源图的格式和数据类型。我们使用RGB值加载这个图像，并把它们储存为char(byte)数组，我们将会传入对应值。最后一个参数是真正的图像数据。        glGenerateMipmap(GL_TEXTURE_2D);//自动生成mipmap        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);        //对于横轴和纵轴采取GL_REPEAT的环绕方式                glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);        //设置过滤方式，这里我们都设为线性滤波        //一个常见的错误是，将放大过滤的选项设置为mipmap选项之一。这样没有任何效果，因为mipmap主要是使用在纹理被缩小的情况下的        stbi_image_free(data);//设置完这块纹理后我们就释放这部分数据    &#125;    else    &#123;        std::cout &lt;&lt; &quot;Texture failed to load at path: &quot; &lt;&lt; path &lt;&lt; std::endl;        stbi_image_free(data);    &#125;    return textureID;//最后我们返回一个纹理ID供我们使用&#125;    while (!glfwWindowShouldClose(window))    &#123;        ...                    lightingShader.use();        glActiveTexture(GL_TEXTURE0);        glBindTexture(GL_TEXTURE_2D, diffuseMap);        //记得在调用glDrawElements之前绑定纹理了，它会自动把纹理赋值给片段着色器的采样器：                    ...    &#125;</code></pre><p>前边部分注释写在代码里没什么好说的，让我们看看片元着色器的导入</p><pre><code>#version 330 coreout vec4 FragColor;struct Material &#123;    sampler2D diffuse;    vec3 specular;        float shininess;&#125;; ...uniform Material material;...int main&#123;   ...&#125;</code></pre><p>你可能会奇怪为什么<code>sampler2D</code>变量是个uniform，我们却不用glUniform给它赋值。</p><p>使用glUniform，我们可以给纹理采样器分配一个位置值,一个纹理的位置值通常称为一个纹理单元(Texture Unit)。</p><p>一个纹理的默认纹理单元是0，它是默认的激活纹理单元。</p><p>只要我们首先激活对应的纹理单元，不用glUniform我们也能用<code>glBindTexture(GL_TEXTURE_2D, texture);</code>将纹理传入着色器</p><p>如果有两个纹理的话，就是这样：</p><p>(这时我们就得手动设置着色器的哪个texture对应源程序代码段的哪个texture)</p><pre><code>glActiveTexture(GL_TEXTURE0);glBindTexture(GL_TEXTURE_2D, texture1);glActiveTexture(GL_TEXTURE1);glBindTexture(GL_TEXTURE_2D, texture2);...ourShader.use(); // 不要忘记在设置uniform变量之前激活着色器程序！glUniform1i(glGetUniformLocation(ourShader.ID, &quot;texture1&quot;), 0); // 手动设置ourShader.setInt(&quot;texture2&quot;, 1); // 或者使用着色器类设置while(...) &#123;    [...]&#125;</code></pre><pre><code>#version 330 core...uniform sampler2D texture1;uniform sampler2D texture2;</code></pre><p>因为OpenGL要求y轴<code>0.0</code>坐标是在图片的底部的，但是图片的y轴<code>0.0</code>坐标通常在顶部。</p><p>所以我们还能使用<code>stbi_set_flip_vertically_on_load(true);</code>翻转图片。</p><h2 id="MVP变换"><a href="#MVP变换" class="headerlink" title="MVP变换"></a>MVP变换</h2><p>还记得顶点着色器的职责吧，我们把三维的顶点数据转化成他们在屏幕上的坐标。</p><p>所以MVP变换一般由顶点着色器做运算。</p><p>我们的思路是用glm生成矩阵，然后用uniform传入着色器</p><pre><code>#include &lt;glm/glm.hpp&gt;#include &lt;glm/gtc/matrix_transform.hpp&gt;#include &lt;glm/gtc/type_ptr.hpp&gt;...int main&#123;        // view/projection transformations        glm::mat4 projection = glm::perspective(glm::radians(camera.Zoom), (float)SCR_WIDTH /     (float)SCR_HEIGHT, 0.1f, 100.0f);//透视投影矩阵        glm::mat4 view = camera.GetViewMatrix();//视点变换        lightingShader.setMat4(&quot;projection&quot;, projection);        lightingShader.setMat4(&quot;view&quot;, view);        // world transformation        glm::mat4 model = glm::mat4(1.0f);//模型变换矩阵        lightingShader.setMat4(&quot;model&quot;, model);&#125;</code></pre><p>我们这里只展示了被渲染箱子的着色部分，不过这样就够了。</p><p>实际上我们渲染的另一个物体是个亮方块，他虽然是扮演了光源但实际上并没有起到太阳的作用</p><p>光线的数据依然是我们手动导入的，其他很多值都是我们规定的，</p><p>但把他以白色渲染出来可以更加直观的观察到光照是如何影响物体的</p><p>让我们复习一下mvp变换做的事情吧（肯定会有人说哎呀烦死了）</p><p><strong>模型变换（model）</strong>把顶点的坐标从局部坐标系转换到世界坐标。</p><p><strong>视点变换（view）</strong>世界坐标 &gt;&gt;&gt; 观察空间</p><p><strong>投影变换（projection）</strong>观察空间&gt;&gt;&gt;剪裁空间</p><p>观察空间经常被人们称之OpenGL的摄像机(Camera)，所以我们这里用camera类生成view矩阵，但不深究</p><p>来模拟摄像机的效果，利用wasd和鼠标可以随意遨游在我们构建的世界。</p><p>做完投影变换就直接到剪裁空间了，OpenGL然后对<strong>裁剪坐标</strong>执行<strong>透视除法</strong>从而将它们变换到<strong>标准化设备坐标</strong></p><p>在顶点着色器则里边是这样的</p><pre><code class="c++">#version 330 corelayout (location = 0) in vec3 aPos;...uniform mat4 model;uniform mat4 view;uniform mat4 projection;...    void main()&#123;    FragPos = vec3(model * vec4(aPos, 1.0));    ...    gl_Position = projection * view * vec4(FragPos, 1.0);&#125;</code></pre><p>如果不讨论怎么法线和纹理的计算，顶点着色器所做的内容就是将传入的顶点数据进行mvp变换</p><p>ps：我们这里还需要输出世界坐标系的顶点坐标进行后续运算，所以将计算分开了。</p><hr><h2 id="phong模型计算（着色器详解）"><a href="#phong模型计算（着色器详解）" class="headerlink" title="phong模型计算（着色器详解）"></a>phong模型计算（着色器详解）</h2><p>重点介绍一下渲染循环中phong模型中的几个分量。</p><p>lightingShader是我们箱子的着色器程序，或许他叫box shader会更合适些</p><pre><code>    while (!glfwWindowShouldClose(window))    &#123;    ...        lightingShader.use();        lightingShader.setVec3(&quot;light.position&quot;, lightPos);        lightingShader.setVec3(&quot;viewPos&quot;, camera.Position);                // light properties        lightingShader.setVec3(&quot;light.ambient&quot;, 0.2f, 0.2f, 0.2f);        lightingShader.setVec3(&quot;light.diffuse&quot;, 0.5f, 0.5f, 0.5f);        lightingShader.setVec3(&quot;light.specular&quot;, 1.0f, 1.0f, 1.0f);                // material properties        lightingShader.setVec3(&quot;material.specular&quot;, 0.5f, 0.5f, 0.5f);        lightingShader.setFloat(&quot;material.shininess&quot;, 64.0f);        &#125;</code></pre><p>如果对冯模型有了解的话（下次我自己看的时候估计会觉得是废话23333）</p><p>会知道在shader里面的计算是把<strong>环境光（ambient）漫反射（diffuse）高光（specular）</strong>的贡献相加</p><p>三个部分的计算便是由由我们传入的uniform值来参与的。</p><p>还记得片元着色器的职责是决定一个片元的颜色吧，这次我们展示一个完整的片元着色器：</p><pre><code>#version 330 coreout vec4 FragColor;struct Material &#123;    sampler2D diffuse;    vec3 specular;        float shininess;&#125;; struct Light &#123;    vec3 position;    vec3 ambient;    vec3 diffuse;    vec3 specular;&#125;;in vec3 FragPos;  in vec3 Normal;  in vec2 TexCoords;  uniform vec3 viewPos;uniform Material material;uniform Light light;void main()&#123;    // ambient    vec3 ambient = light.ambient * texture(material.diffuse, TexCoords).rgb;          // diffuse     vec3 norm = normalize(Normal);    vec3 lightDir = normalize(light.position - FragPos);    float diff = max(dot(norm, lightDir), 0.0);    vec3 diffuse = light.diffuse * diff * texture(material.diffuse, TexCoords).rgb;          // specular    vec3 viewDir = normalize(viewPos - FragPos);    vec3 reflectDir = reflect(-lightDir, norm);      float spec = pow(max(dot(viewDir, reflectDir), 0.0), material.shininess);    vec3 specular = light.specular * (spec * material.specular);              vec3 result = ambient + diffuse + specular;    FragColor = vec4(result, 1.0);&#125; </code></pre><p>环境光部分，我们这里就暂且认为环境光是我们的物体颜色，毕竟我们现在也做不出什么全局光照。</p><p>所以这里我们直接拿纹理和微弱的光照分量相乘就行</p><hr><p>漫反射光照能对物体产生显著的视觉影响，或者说物体呈现出什么样子就是漫反射决定的。</p><p>计算漫反射需要<strong>法线</strong>和<strong>入射光线</strong>，入射光线是我们由上阶段的顶点着色器输出的顶点坐标（世界坐标系）和光照计算而来的</p><p>这里的法线则是很有意思的地方，本身我们渲染的并不是一个箱子的模型，而是一个个手填的顶点</p><p>不存在什么表面更不存在什么法线，所以法线我们也是手填的（233333）</p><p>最后乘上<strong>漫反射系数</strong>，这决定了这部分的贡献是如何的。</p><p>所以尽管计算部分是参照了<strong>兰伯特光照模型</strong>，但我们在背光处也能看到物体的纹理，这便是由不真实的法线造成的。</p><hr><p>高光部分会复杂些，需要<strong>观察向量，反射方向，光泽度。</strong></p><p>观察方向由我们填入的camera.position和顶点计算得出。</p><p>反射方向的计算是一个耗时的计算，若改成计算半程向量（half vector）便能加速此部分的计算，也能得到不错的效果（布林冯）</p><hr><p>光泽度则影响高光亮点的大小。在公式里面扮演指数的部分，光泽度越高亮点就越小。</p><p>最后我们会乘上<strong>高光反射系数</strong>，这里填的（1.0,1.0,1.0），因为我们理所当然觉得高光很明显。</p><p>如此一来便完成了phong模型的着色部分的计算，我们便能渲出我们可爱的小箱箱了。</p><hr><p>完成这篇水博客之后感觉精神好了很多，不像之前那样一看到vs就烦躁了，学习的欲望也重新被激起了</p><p>今天没什么干劲了，明天再努力吧.jpg</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;写这篇博客的时候我还在我老家的床上，给自己放了两三天的假，决定写点东西。&lt;/p&gt;
&lt;p&gt;在经历了visual studio的链接失败和着色器编译失败之后&lt;/p&gt;
&lt;p&gt;深感自己力量渺小，无法棒打vs设计师（胡言乱语）&lt;/p&gt;
&lt;p&gt;再加上之前学的有些快而不扎实，复制源码跑动了看一遍就粗略带过（有时甚至跑不动）&lt;/p&gt;
&lt;p&gt;所以写这篇救命博客来挽救一下自己岌岌可危的大脑。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>温故知新UE4（网络同步）</title>
    <link href="https://aprilnavi.github.io/2021/12/21/2021-12-21-%E6%B8%A9%E6%95%85%E7%9F%A5%E6%96%B0UE4%EF%BC%88%E7%BD%91%E7%BB%9C%E5%90%8C%E6%AD%A5%EF%BC%89/"/>
    <id>https://aprilnavi.github.io/2021/12/21/2021-12-21-%E6%B8%A9%E6%95%85%E7%9F%A5%E6%96%B0UE4%EF%BC%88%E7%BD%91%E7%BB%9C%E5%90%8C%E6%AD%A5%EF%BC%89/</id>
    <published>2021-12-21T07:06:58.000Z</published>
    <updated>2021-12-22T09:31:15.480Z</updated>
    
    <content type="html"><![CDATA[<p>在开发完ue的demo后，回头总结了一些心得，趁着闲暇就记录下来。</p><span id="more"></span><p>这一篇看上去一点也不ue4，等熟了ue4的网络同步再来补相关部分。</p><h2 id="TCP三四次握手"><a href="#TCP三四次握手" class="headerlink" title="TCP三四次握手"></a>TCP三四次握手</h2><h3 id="创建连接（三次握手）"><a href="#创建连接（三次握手）" class="headerlink" title="创建连接（三次握手）"></a>创建连接（三次握手）</h3><p>第一次：客户端尝试连接服务器，向服务器发送syn包（seq＝x）。客户端进入SYN_SEND状态。</p><p>第二次：服务器接收客户端的syn包，同时向客户端发送一个SYN包（seq=y，ack＝x+1），同时发送一个ACK，即发送的是ACK+SYN，服务器进入SYN_RECV状态</p><p>第三次：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK（seq=x+1，ack＝y+1），客户端和服务器进入Establish，TCP连接建立完成。</p><hr><h3 id="释放连接（四次握手）"><a href="#释放连接（四次握手）" class="headerlink" title="释放连接（四次握手）"></a>释放连接（四次握手）</h3><p>第一次：客户端进程发出连接释放报文FIN，并停止发送数据。客户端进入FIN_WAIT1状态。</p><p>第二次：服务器收到连接释放报文，发出确认报文ACK（ack=u+1，seq=v），服务器进入CLOSE_WAIT状态。此时客户端不接受数据，但若服务器发送数据，客户端依然要接受。客户端收到服务器的确认请求，进入FIN_WAIT2状态。</p><p>第三次：服务器将最后的数据发送完，向客户端发送释放连接报文FIN（ack＝u+1，seq=w），服务器进入LAST_ACK状态。</p><p>第四次：客户端收到服务器的连接释放报文，必须发出确认报文ACK（ack=w+1，seq=u+1），客户端进入TIME_WAIT状态，等待2xMSL（最长报文寿命时间），进入CLOSED，服务器收到ACK立即进入CLOSED。</p><h3 id="一些之外的思考"><a href="#一些之外的思考" class="headerlink" title="一些之外的思考"></a>一些之外的思考</h3><p><strong>为什么建立连接是三次握手，释放连接是四次握手？</strong></p><p>因为建立连接时服务器收到客户端的SYN时，可以同时发送一个ACK加SYN。释放连接时由于不知道是否还要继续传输文件，SOCKET没有立即关闭，所以只能发送一个ACK。</p><p><strong>为什么TIME_WAIT状态需要经过2MSL才能进入CLOSE？</strong></p><p>我们得假设网络是不可靠的。TIME_WAIT用来重发可能丢失的ACK。当服务器没有收到ACK时，会一直重复发送FIN，所以服务端不能关闭，得确保在2MSL内没有收到FIN才能进入CLOSED。其中2MSL是一个发送和一个回复所需的最大时间。</p><p><strong>为什么两次握手不能完成TCP连接创建？</strong></p><p>若只有两次连接，在服务器传回给客户端的应答丢失的情况下，客户端不知道服务器是否准备好，会认为连接未建立而忽略服务器发来的任何分组，只等待ACK。而服务器会重复发送同样的分组，从而造成死锁。</p><hr><h2 id="TCP和UDP的区别"><a href="#TCP和UDP的区别" class="headerlink" title="TCP和UDP的区别"></a>TCP和UDP的区别</h2><ul><li>TCP面向连接，UDP无连接</li><li>TCP面向字节流，UDP面向报文</li><li>TCP提供可靠性（按序发送，有序到达，超时重传），UDP只尽力而为，不保证任何事。</li><li>TCP首部20字节，所需资源多，而UDP只占用8字节</li><li>TCP有流量控制和拥塞控制，而UDP没有（拥塞不会影响发送端的发送速率）</li><li>TCP只支持点对点，而UDP可以一对一，一对多，多对多。</li></ul><h2 id="网络同步"><a href="#网络同步" class="headerlink" title="网络同步"></a>网络同步</h2><p><strong>RPC</strong></p><p>即远程过程调用，本地调用远程提供的函数。因为不是一个内存空间，需要网络来表达调用的语义和数据，而不能直接调用。</p><p>带来的问题：<strong>Call ID映射</strong>（让服务器知道我调用是哪个函数），<strong>序列化与反序列化</strong>（参数需要通过一种标准化的格式来传输，将对象转换为一系列字节流），<strong>网络传输</strong></p><p><strong>属性同步</strong></p><p>对象A的属性更改了，其他端的对应属性也要更改。一般是服务器更改同步到其他客户端。</p><hr><h3 id="帧同步"><a href="#帧同步" class="headerlink" title="帧同步"></a>帧同步</h3><p>帧同步只同步操作，大部分逻辑在客户端上运行，服务器主要用于验证和广播，逻辑易实现，数据量少，可重播，一致性好。一个玩家卡了所有人都卡。</p><h3 id="状态同步"><a href="#状态同步" class="headerlink" title="状态同步"></a>状态同步</h3><p>同步游戏的各种状态。客户端上传操作到服务器，服务器收到后运算结果，把各个状态广播给各个客户端，客户端根据状态展现不同的内容。</p><p>状态同步是一种不严谨的同步，对延迟的要求并不高。</p><h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><p>帧同步客户端一致性全程一致，状态同步中途可能有变化。</p><p>延迟方面帧同步要求搞，状态同步要求低。</p><p>流量方面，帧同步的流量与操作数量成正比，而状态同步与物体数量成正比。</p><p>服务器的任务上来看，帧同步服务器做的是同步操作，而状态同步的服务器则需要接受输入，进行全局仿真，状态的复制。</p><p>客户端的任务上来看，帧同步客户端做的是全局仿真，而状态同步客户端则是做局部游戏世界的展示。</p><p>断线重连，状态同步更容易，帧同步要从头开始运行（王者荣耀）。</p><p>开发效率上来看，帧同步的开发效率很高，接近单机开发。状态同步需要前后台联合开发。</p><p>安全性来看，帧同步安全性低。而状态同步在服务器端安全性高，但客户端有作弊可能。</p><h3 id="修复延迟"><a href="#修复延迟" class="headerlink" title="修复延迟"></a>修复延迟</h3><p>插值，预测，缓存，延迟补偿</p><hr><h2 id="UE4网络同步架构"><a href="#UE4网络同步架构" class="headerlink" title="UE4网络同步架构"></a>UE4网络同步架构</h2><p>以CS模型为基础，做了面向对象风格的封装，网络代码和游戏逻辑完全分离，网络同步支持可视化编程，使用UDP协议通信。</p><p><strong>为什么使用纯UDP？</strong>‘</p><p>TCP的可靠性无法定制，且游戏中许多数据不要求可靠。</p><p>TCP与UDP都是基于IP协议，底层会互相干扰，混用也会增加设计复杂度。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在开发完ue的demo后，回头总结了一些心得，趁着闲暇就记录下来。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>温故知新UE4（游戏模式）</title>
    <link href="https://aprilnavi.github.io/2021/12/20/2021-12-21%20%E6%B8%A9%E6%95%85%E7%9F%A5%E6%96%B0UE4%EF%BC%88%E6%B8%B8%E6%88%8F%E6%A8%A1%E5%BC%8F%EF%BC%89/"/>
    <id>https://aprilnavi.github.io/2021/12/20/2021-12-21%20%E6%B8%A9%E6%95%85%E7%9F%A5%E6%96%B0UE4%EF%BC%88%E6%B8%B8%E6%88%8F%E6%A8%A1%E5%BC%8F%EF%BC%89/</id>
    <published>2021-12-20T04:31:47.000Z</published>
    <updated>2021-12-21T10:19:27.565Z</updated>
    
    <content type="html"><![CDATA[<p>在开发完ue的demo后，回头总结了一些心得，趁着闲暇就记录下来。</p><span id="more"></span><ul><li>万事万物皆继承自UObject(CG，Reflection，Metadata，Serialization，Editable)</li><li>从Actor开始具有一些生命特征(Spawn，Destory，Tick，Replication(网络复制))</li><li>Pawn可以被Controller控制，有Movement，Input等基本响应接口，State来记录玩家状态。Actor正是通过各种Component组合成Pawn。Pawn是可控生命体的基础。</li><li>Character是一个特殊的Pawn，默认自带Collision，Skeletal Mesh，Movement移动组件</li></ul><hr><ul><li>构造函数的初始化在Begin之前，因此组件以及其他数据的初始化，若需要场景其他数据，则初始化得放在Begin里面。</li><li>Gamemode记录了初始的默认Pawn，HUD，Playercontroller等信息。当gamemode满足不了关卡配置时，会在关卡蓝图做一些逻辑配置。Gamemode更适合用来制定规则和检测规则。</li></ul><hr><ul><li>据大佬所说，开发游戏用的最多的设计模式是单例（懒汉式，线程安全），观察者，工厂模式</li><li>物理和AI是固定步长更新。</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;在开发完ue的demo后，回头总结了一些心得，趁着闲暇就记录下来。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>编程规范准则</title>
    <link href="https://aprilnavi.github.io/2021/10/28/%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83%E5%87%86%E5%88%99/"/>
    <id>https://aprilnavi.github.io/2021/10/28/%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83%E5%87%86%E5%88%99/</id>
    <published>2021-10-28T07:06:58.000Z</published>
    <updated>2021-11-20T05:10:37.649Z</updated>
    
    <content type="html"><![CDATA[<p>一个庞大系统应该由许多短小的结构组成，我们在让代码能工作的前提下还应该考虑代码的条理性</p><p>因此我们需要一些编程规范来帮助我们编写和重构代码。</p><span id="more"></span><hr><h2 id="1-命名应该是有意义的（我认为最重要的）"><a href="#1-命名应该是有意义的（我认为最重要的）" class="headerlink" title="1.命名应该是有意义的（我认为最重要的）"></a>1.命名应该是有意义的（我认为最重要的）</h2><p><strong>我认为有关明命名的准则是最重要的，先不谈代码架构问题，倘若命名是没有意义的甚至是重复的</strong></p><p><strong>在工作和交流中就会起到混淆视听降低可读性的严重后果。</strong></p><p>应该花时间为我们的函数，变量，类，参数取个好名字。</p><p>名字应该名副其实的表达这个数据的用途。类名，变量名使用名词短语，而函数名则尽量使用动词短语。</p><p>命名时还应当注意：区分应该有意义（避免使用a1，a2，a3）；避免误导（不使用关键词例如list，否则会以为这个数据是list类型的）</p><p>每个词对应一个信息（用来表示两数相加的函数和将某数据放入容器的方法不能都叫add）</p><hr><h2 id="2-注释并不是尽然好的"><a href="#2-注释并不是尽然好的" class="headerlink" title="2.注释并不是尽然好的"></a>2.注释并不是尽然好的</h2><p><strong>这表示简洁的易读的代码的重要性，代码并不是能跑得动就行的，花时间重构代码很有价值</strong></p><p>注释的用法是弥补我们在尝试表达代码意图时所遭遇的失败</p><p>应尽量用可读性更好的代码来表达而非使用注释</p><p>值得写的好注释有：<strong>代码规范中所要求的法律信息；将某些晦涩的参数或返回值的意图解释清楚（如果可以的话最好还是用函数名来表达）</strong></p><hr><h2 id="3-函数应该尽量简洁短小"><a href="#3-函数应该尽量简洁短小" class="headerlink" title="3.函数应该尽量简洁短小"></a>3.函数应该尽量简洁短小</h2><p>在初步编写时没人能一次性写出好的函数，但我们可以慢慢改进重构精简它们。</p><p><strong>每个函数都应该短小，且一目了然，每个函数都只做一件事，并且每个函数都将你带到下个函数。</strong></p><p><strong>确保函数只做一件事，得确保函数内的语句都是同一抽象层级的。</strong></p><p><strong>函数的参数应该尽可能的少，多使用无参，或者单参数函数，少用双参数函数，避免用三个及以上的参数，这样会大大降低可读性。</strong></p><p><strong>可以通过将参数封装为类来减少函数的参数数量。</strong></p><p><strong>尽可能避免在不同函数中重用相同的代码段</strong></p><hr><h2 id="4-将数据进行良好的封装"><a href="#4-将数据进行良好的封装" class="headerlink" title="4.将数据进行良好的封装"></a>4.将数据进行良好的封装</h2><p><strong>封装是面向对象设计的三大特性之一</strong></p><p>从编程开始时，老师就教导我们尽量将数据设为私有private，将必要的函数和数据再设为公开public。</p><p>一方面能保护一些数据，只暴露所需的接口，接口之内皆为黑盒。</p><p>一方面能减少模块间的相互干扰，相互依赖，能极大减少代码的耦合度。</p><p>对于面向对象编程而言，代码难以添加新函数，因为可能需要修改所有的类，与此相对却更方便添加新的数据类型。</p><p>我认为在如今的编程环境中，这种情况可能更居多，所以面向对象是很出众的。</p><hr><h2 id="5-类应该短小精炼"><a href="#5-类应该短小精炼" class="headerlink" title="5.类应该短小精炼"></a>5.类应该短小精炼</h2><p>我认为若有能力将上述的问题处理好，说明已经有初步的重构代码的能力了</p><p>编写一个短小精悍的类虽然同样很重要但此时就是个小case啦。</p><p><strong>首先我们类的命名应该是精准的，确定性了指明这个类该做什么事情</strong></p><p><strong>我们根据类的职责来确定类的成员和类的长度。</strong></p><p><strong>其次类应该具有尽量强的内聚性，应该只具有少量的实体，类中方法尽量围绕这个实体做数据操作。</strong></p><p>内聚性高就表明这个类能自成一体，类中实体和函数能相互依赖，结合成一个逻辑实体。</p><hr><h2 id="6-多使用异常处理机制来进行错误处理"><a href="#6-多使用异常处理机制来进行错误处理" class="headerlink" title="6.多使用异常处理机制来进行错误处理"></a>6.多使用异常处理机制来进行错误处理</h2><p>曾经限于语言不支持异常，先辈们采用返回错误码的方式来汇报错误。</p><p>异常处理机制就可以让我们捕获并处理这些错误，然后我们可以让程序沿着一条不会出错的路径继续执行。</p><p>它的优越之处在于抛出异常不会影响代码的逻辑性，也不必催促调用者立即检查错误。</p><p><strong>一般我们先编写强行抛出异常的语句，以便来往处理器中添加行为。</strong></p><p><strong>其次我们根据我们的期待往try语句块中再填入我们所需测试的语句。</strong></p><p><strong>编写异常语句时，可以将错误处理语句隔离看待，独立于主要逻辑之外</strong></p><p>这样我们能单独处理它并极大提升代码的可维护性。</p><p>其中要注意的是，我们应该尽量减少返回值为null，而改为返回特例对象和抛出异常。</p><hr><h2 id="7-设计架构应一步步迭代"><a href="#7-设计架构应一步步迭代" class="headerlink" title="7.设计架构应一步步迭代"></a>7.设计架构应一步步迭代</h2><p>我们不该在代码能工作后就止步于此。</p><p>优秀的架构意味着我们做出一个改动时，整个程序会期待它而不是畏惧它的副作用。</p><p>由于良好的组织性，后续的人处理代码时不必花大量时间修改和理解代码。</p><p>良好的测试来为我们消除破坏代码的恐惧，接着我们将进行代码重构来迭进我们的代码。</p><p>重构过程中我们遵循：<strong>运行所有测试，提升内聚性，降低耦合度，减少重复，切分关注面，</strong></p><p><strong>模块化系统性关注面，缩小函数尺寸和减少类和函数数量，保证表达力。</strong>（按重要性排序）</p><p>表达力，函数和类的相关规范在上文中提到过，下文则会介绍测试规范和重构思路。</p><hr><h2 id="8-为代码编写测试"><a href="#8-为代码编写测试" class="headerlink" title="8.为代码编写测试"></a>8.为代码编写测试</h2><p>检查自己是否有一套可靠的测试机制，同样是进行代码重构的前提。</p><p>编写测试是为了确保我们的代码能如愿以偿的工作，同时测试的确可以捕捉到大多数bug。</p><p><strong>TDD三原则：</strong></p><p><strong>在编写不能通过的单元测试前，不可编写生产代码；</strong></p><p><strong>只可编写刚好无法通过的单元测试，不能编译也算不通过；</strong></p><p><strong>只可编写刚好足以通过当前失败测试的生产代码；</strong></p><p>我们用较大的比例用测试覆盖代码，就能保证代码的可拓展，可维护，可复用。</p><p>在编写测试代码时同样要确保测试代码的整洁（即可读性）</p><p><strong>确保我们的每段测试代码只测试一个功能，而不是一段超长的测试代码将所有功能纳入其中</strong>。</p><p>测试代码同样也是代码，我们一样遵守上文提到的那些准则就行</p><hr><h2 id="9-代码重构的思路"><a href="#9-代码重构的思路" class="headerlink" title="9. 代码重构的思路"></a>9. 代码重构的思路</h2><p>就如上文所说到的，代码不可能第一次编写时就是简洁且完整的，我们可以先遵从一些编程时的准则（命名，注释）</p><p>在完成目标后我们进行代码的重构。<strong>因此完成重构的前提当然是我们有一段能完成职责的代码。</strong></p><p>重构并不是将程序完全重新写一遍，而是在之前同样的算法和机制上将我们的代码变得具有逻辑性。</p><p>因此我们首先需要一个用例来验证程序的功能，随后我们进行我们所需的改动。</p><p>每当一处小改动发生时，我们就执行这个用例确保程序的行为是否发生了变化。</p><p>代码重构的几个方向：</p><p><strong>将大函数按照模块和行为分为几个小函数</strong>；</p><p><strong>将函数变为内联函数；</strong></p><p><strong>将临时变量（有着复杂表达式赋值并且多次使用的）改为使用查询函数的返回值来取代；</strong></p><p><strong>若临时变量赋值的意义不同则创建新的临时变量并使用不同名称；</strong></p><p><strong>使用临时值而避免对函数参数进行直接修改（会丧失参数的原始值）</strong></p><hr><h2 id="10-格式"><a href="#10-格式" class="headerlink" title="10.格式"></a>10.格式</h2><p>将格式放在最后，并非格式不重要，而是在各种规范和自动化工具的普及下</p><p>拥有一个整洁的代码格式并不是困难的事，但这关乎到团队的沟通，依然很重要。</p><p><strong>我们应该制定一个简单的规则，并在整个项目中贯彻它。</strong></p><p><strong>我们应该限制每个源文件的大小（行数）在同一个数量级的规格上，在源文件的顶部给出最高层次的抽象（概念和算法）</strong></p><p><strong>随后在下文中将细节依次展开，直至源文件最底层的函数和细节；</strong></p><p><strong>关系密切且放在同一源文件的数据间隔应该尽可能小，避免读者在源文件中跳来跳去的阅读；</strong></p><p><strong>变量声明应该尽可能接近使用位置，循环中的控制变量尽可能在循环语句中声明；</strong></p><p><strong>一个函数若调用另一个函数则它俩应该尽可能相近；</strong></p><p><strong>过程中记得用空行来区分各个函数和模块，使得代码块更具有条理性和可读性。</strong></p><p>其他有关每行长度，缩进，对齐，字符间的空格的相关内容则不赘述，</p><p>因为借助于先进的IDE和自动化工具，这些规范早已刻在DNA里了。</p><hr><p>相关文献：《Clean Code》《Game Programming Pattern》《Refactoring》</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;一个庞大系统应该由许多短小的结构组成，我们在让代码能工作的前提下还应该考虑代码的条理性&lt;/p&gt;
&lt;p&gt;因此我们需要一些编程规范来帮助我们编写和重构代码。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>UnityShader入门精要⑥（透明效果）</title>
    <link href="https://aprilnavi.github.io/2021/10/17/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A5%EF%BC%88%E9%80%8F%E6%98%8E%E6%95%88%E6%9E%9C%EF%BC%89/"/>
    <id>https://aprilnavi.github.io/2021/10/17/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A5%EF%BC%88%E9%80%8F%E6%98%8E%E6%95%88%E6%9E%9C%EF%BC%89/</id>
    <published>2021-10-17T01:36:58.000Z</published>
    <updated>2021-10-21T10:02:44.151Z</updated>
    
    <content type="html"><![CDATA[<p>本文为学习UnityShader时所记录的笔记，供学习产出和日后复习使用。</p><p>学习资料为冯乐乐（问就是我女神）的《UnityShader入门精要》</p><span id="more"></span><p>上次写博客是七号来着，已经过去有一段时间了，这段时间有点忙所以shader的学习一直被挤压</p><p>今天刚好离憨色演唱会过去了两个星期，日子过的还是蛮快的</p><p>这星期经历了科三一次过（现在在练科二），还有买了两本书（虚幻4和程序员职业素养）但也没什么时间看</p><p>这星期状态还可以，精神不错，就是学习知识的吸收率不太高，摸鱼现象还是有的（有待提升）</p><p>好消息是自己的c++现在还不错，有大佬建议我春招可以直接试试看冲大厂，我也是这么想的</p><p>考虑到之前写的博客又臭又长，更像是傻瓜指南而不是技术总结，接下来我会改变写博客的方式。</p><p>自己这星期学的蛮少的，时间是一个因素，难度也是一个因素</p><p>那么一库走！</p><hr><h2 id="透明度测试，透明度缓冲"><a href="#透明度测试，透明度缓冲" class="headerlink" title="透明度测试，透明度缓冲"></a>透明度测试，透明度缓冲</h2><p>透明效果由控制渲染问题的<strong>透明通道（Alpha Channel）</strong>来实现，即为RGB，A中的A。</p><p>有两种实现透明效果的方法：<strong>透明度测试（Alpha Test），透明度缓冲（Alpha Blending）</strong></p><p><strong>透明度测试：</strong>一个片元的透明度不满足条件（一般是低于阈值），就直接舍弃。</p><p>效果很极端，要么完全透明看不见，要么完全不透明就像什么都没做。<strong>无需关闭深度写入。</strong></p><p><strong>透明度缓冲：****关闭了深度写入</strong>，但没有关闭深度测试，即深度缓冲是只读的。</p><hr><h2 id="渲染顺序"><a href="#渲染顺序" class="headerlink" title="渲染顺序"></a>渲染顺序</h2><p>为了得到正确的结果，引擎一般对物体进行排序，再渲染。</p><p>先渲染所有不透明物体，并开启深度测试和深度写入</p><p>其次将半透明物体按照从后往前（距离摄像机）的顺序渲染，开启深度测试但关闭深度写入。</p><p>重叠情况依然无法得到完美的解决，但可以通过分割网格或让透明通道更柔和来改善情况。</p><hr><h2 id="渲染队列标签"><a href="#渲染队列标签" class="headerlink" title="渲染队列标签"></a>渲染队列标签</h2><p>unity为解决渲染顺序问题提供了几个渲染队列（详见入门精要p165表格）</p><p>我们在unity中通过设置SubShader的Queue标签来决定模型归于哪个队列。</p><p>透明度测试：</p><pre><code>    SubShader&#123;        Tags&#123;&quot;Queue&quot;=&quot;AlphaTest&quot;&#125;</code></pre><p>透明度缓冲：</p><pre><code>    SubShader&#123;        Tags&#123;&quot;Queue&quot;=&quot;Transparent&quot; &#125;        pass&#123;//关闭深度写入 ZWrite Off</code></pre><hr><h2 id="透明度测试"><a href="#透明度测试" class="headerlink" title="透明度测试"></a>透明度测试</h2><p>以基础的纹理采样代码作为样本进行改进</p><p>初始值多设一个Cutoff作透明度的判断条件</p><pre><code>        _Cutoff(&quot;Alpha Cutoff&quot;,Range(0,1))=0.5</code></pre><p>设渲染队列为AlphaTest，”IgnoreProjector”=”True”意思是Shader不会受投影器影响</p><p>RenderType则是将这个Shader划入提前定义好的组（类似于layer和tags？）</p><pre><code>    SubShader&#123;        Tags&#123;            &quot;Queue&quot;=&quot;AlphaTest&quot;            &quot;IgnoreProjector&quot;=&quot;True&quot;            &quot;RenderType&quot;=&quot;TransparentCutput&quot;            &#125;        pass&#123;            Tags&#123;&quot;LightMode&quot;=&quot;ForwardBase&quot;&#125;</code></pre><p>在做纹理采样得到纹理值时，用a分量做一个裁剪</p><pre><code>                fixed4 texColor=tex2D(_MainTex,i.uv);                //Alpha Test                clip(texColor.a-_Cutoff);</code></pre><p>完成编写后，调大材质中的cutoff时，立方体上的网格会逐渐消失。</p><hr><h2 id="透明度混合"><a href="#透明度混合" class="headerlink" title="透明度混合"></a>透明度混合</h2><p>透明度测试更复杂，使用<strong>当前片元的透明度</strong>作为混合因子与已经储存在<strong>颜色缓冲中的颜色值</strong>进行混合。</p><p>进行混合需要使用混合指令Blend，其中我们使用了Blend SrcFactor DstFactor这种语义。</p><p>（源颜色乘以SrcFactor ，目标颜色乘以DstFactor）</p><p>（详细的混合命令请见入门精要p169）</p><p>以基础的纹理采样代码作为样本进行改进</p><p>材质还是用之前的主颜色Color，主材质MainTex，还有一个_AlphaScale用来控制透明度。</p><p>修改标签，关闭深度写入，设置混合因子（和上边的大同小异）：</p><pre><code>    SubShader&#123;        Tags&#123;            &quot;Queue&quot;=&quot;Transparent&quot;            &quot;IgnoreProjector&quot;=&quot;True&quot;            &quot;RenderType&quot;=&quot;Transparent&quot;            &#125;        pass&#123;            Tags&#123;&quot;LightMode&quot;=&quot;ForwardBase&quot;&#125;                        //关闭深度写入，设置混合因子            ZWrite Off            Blend SrcAlpha OneMinusSrcAlpha//这里的目标颜色混合因子被设为了OneMinusSrcAlpha，以得到半透明效果</code></pre><p>接下来都一样，只需要修改片元着色器的返回值就行（a通道）</p><pre><code>                return fixed4(ambient+diffuse,texColor.a*_AlphaScale);                                Fallback “Transparent/VertexLit”</code></pre><p>完成编写后，可以调节材质面板的Alpha Scale以控制整体透明度。</p><p>关闭深度写入会带来各种问题，依然需要改进。</p><hr><h2 id="开启深度缓冲的半透明效果"><a href="#开启深度缓冲的半透明效果" class="headerlink" title="开启深度缓冲的半透明效果"></a>开启深度缓冲的半透明效果</h2><p>我们使用两个pass来渲染模型，第一个pass开启深度写入，不输出颜色，是为了将模型的深度值写入深度缓冲。</p><p>第二个pass进行正常的透明度混合，因为上一个pass得到了逐像素的正确的深度信息，这个pass就可以进行逐像素的透明渲染。</p><p>多使用一个pass会对性能造成一定影响。</p><p>和上部分的标签设置相同：</p><pre><code>    SubShader&#123;        Tags&#123;            &quot;Queue&quot;=&quot;Transparent&quot;            &quot;IgnoreProjector&quot;=&quot;True&quot;            &quot;RenderType&quot;=&quot;Transparent&quot;            &#125;        Pass&#123;            ZWrite On            ColorMask 0            &#125;                pass&#123;            Tags&#123;&quot;LightMode&quot;=&quot;ForwardBase&quot;&#125;                        //关闭深度写入，设置混合因子            ZWrite Off            Blend SrcAlpha OneMinusSrcAlpha                        CGPROGRAM            ·······                        Fallback “Diffuse”</code></pre><p>第一个Pass是为了将深度信息写入深度缓冲，ColorMask 0是意味着该Pass不写入任何颜色通道</p><p>然后第二个pass就是正常的逐像素的透明渲染。</p><hr><h2 id="双面渲染的透明效果"><a href="#双面渲染的透明效果" class="headerlink" title="双面渲染的透明效果"></a>双面渲染的透明效果</h2><h3 id="透明度测试-1"><a href="#透明度测试-1" class="headerlink" title="透明度测试"></a>透明度测试</h3><p>代码几乎与透明度测试一模一样，就加了一行代码：</p><pre><code>    SubShader&#123;        Tags&#123;            &quot;Queue&quot;=&quot;AlphaTest&quot;            &quot;IgnoreProjector&quot;=&quot;True&quot;            &quot;RenderType&quot;=&quot;TransparentCutput&quot;            &#125;        pass&#123;            Tags&#123;&quot;LightMode&quot;=&quot;ForwardBase&quot;&#125;            Cull Off//关闭剔除功能</code></pre><h3 id="透明度缓冲"><a href="#透明度缓冲" class="headerlink" title="透明度缓冲"></a>透明度缓冲</h3><p>我们将渲染分为两个pass，一个只渲染背面，一个只渲染正面。</p><p>也就是在两个pass中使用Cull剔除不同朝向的渲染图元：</p><pre><code>    SubShader    &#123;        Tags&#123;            &quot;Queue&quot;=&quot;AlphaTest&quot;            &quot;IgnoreProjector&quot;=&quot;True&quot;            &quot;RenderType&quot;=&quot;TransparentCutput&quot;            &#125;        pass&#123;            Tags&#123;&quot;LightMode&quot;=&quot;ForwardBase&quot;&#125;            Cull Front            ...            &#125;                    pass&#123;            Tags&#123;&quot;LightMode&quot;=&quot;ForwardBase&quot;&#125;            Cull Back            ...            &#125;      &#125; Fallback &quot;Transparent/VertexLit&quot;   &#125;</code></pre><hr><p>呜呜呜今天晚上写这么少又摸鱼了，明天估计不能看直播水群边做了</p><p>（不要对直播有什么奇奇怪怪的责任感）</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文为学习UnityShader时所记录的笔记，供学习产出和日后复习使用。&lt;/p&gt;
&lt;p&gt;学习资料为冯乐乐（问就是我女神）的《UnityShader入门精要》&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>UnityShader入门精要⑤（基础纹理）</title>
    <link href="https://aprilnavi.github.io/2021/10/07/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A4%EF%BC%88%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86%EF%BC%89/"/>
    <id>https://aprilnavi.github.io/2021/10/07/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A4%EF%BC%88%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86%EF%BC%89/</id>
    <published>2021-10-07T01:36:58.000Z</published>
    <updated>2021-10-08T05:03:40.104Z</updated>
    
    <content type="html"><![CDATA[<p>本文为学习UnityShader时所记录的笔记，供学习产出和日后复习使用。</p><p>学习资料为冯乐乐（问就是我女神）的《UnityShader入门精要》</p><span id="more"></span><hr><h1 id="基础纹理"><a href="#基础纹理" class="headerlink" title="基础纹理"></a>基础纹理</h1><p>使用<strong>纹理映射（texture mapping）</strong>可以将一张图黏在图形表面，逐<strong>纹素（texel）</strong>的控制模型的颜色</p><p>纹理映射坐标一般被储存在每个顶点上，它定义了该顶点在纹理中对应的2D坐标，通常使用一个<strong>二维向量（u,v）</strong>来表示</p><p>uv坐标一般被归一化到[0,1]范围。</p><p>在OpenGL中，纹理空间的原点位于左下角，而在DirectX中则位于左上角。</p><p>unity使用的纹理空间符合OpenGL传统，即原点位于纹理左下角。</p><hr><h2 id="单张纹理"><a href="#单张纹理" class="headerlink" title="单张纹理"></a>单张纹理</h2><h3 id="着色器编写"><a href="#着色器编写" class="headerlink" title="着色器编写"></a>着色器编写</h3><p>本章中介绍如何在UnityShader中实现最基本的纹理采样，通常使用一张纹理来代替物体的漫反射颜色。</p><p>先是为shader取名：</p><pre><code>Shader &quot;Unity Shaders Book/Chapter 7/Single Textrue&quot;&#123;</code></pre><p>紧接着声明我们所需的属性：</p><pre><code>    Properties&#123;        _Color (&quot;Color Tint&quot;,Color)=(1,1,1,1)        _MainTex(&quot;Main Tex&quot;,2D)=&quot;White&quot;&#123;&#125;        _Specular(&quot;Specular&quot;,Color)=(1,1,1,1)        _Gloss(&quot;Gloss&quot;,Range(8.0,256))=20    &#125;</code></pre><p>其中<strong>color（控制物体整体色调），specular（高光反射系数），gloss（光泽度）</strong>都是我们的老熟人（忘了就回去看前面）=</p><p>这里讲解一下名为**_MainTex<strong>的纹理。我们知道2D是纹理属性的声明方式，使用</strong>一个字符串后跟一个花括号**作为初始值</p><p>使用<strong>“white”</strong>作为内置纹理的名字，即全白纹理。</p><p>随后在SubShader中定义一个Pass，指明该Pass的<strong>光照模式（前向渲染）</strong>：</p><pre><code>    SubShader&#123;        Pass&#123;                        Tags&#123;&quot;LightMode&quot;=&quot;ForwardBase&quot;&#125;</code></pre><p>使用CGPROGRAM和ENDCG来包围代码块，用#pragma来指定顶点着色器和片元着色器。</p><p>为了使用内置变量，我们还包含内置文件Lighting.cginc。</p><pre><code>            CGPROGRAM            #pragma vertex vert            #pragma fragment frag            #include &quot;Lighting.cginc&quot;                                //  ......        //  ENDCG</code></pre><p>在代码片中声明与上述属性类型相匹配的变量，以便和材质面板的属性建立联系：</p><pre><code>            fixed4 _Color;            sampler2D _MainTex;            float4 _MainTex_ST;//用于声明_MainTex的属性            fixed4 _Specular;            float _Gloss;</code></pre><p>我们还多声明了一个float4类型的_MainTex_ST属性。在Unity中我们需要使用<strong>纹理名 _ST</strong>来声明某个纹理的属性。</p><p>其中ST是缩放（scale）和平移（translation）的缩写，_MainTex_ST可以让我们得到该纹理的平移和缩放值。</p><p>其中_ MainTex_ST.xy是缩放值，_MainTex_ST.zw是偏移值（平移）。</p><p>这些值都可以在材质面板的纹理属性中调节。</p><p>接下来定义顶点着色器的输入和输出：</p><pre><code>            struct a2v            &#123;                float4 vertex:POSITION;                float3 normal:NORMAL;                float4 texcoord:TEXCOORD0;//第一组纹理坐标            &#125;;            struct v2f            &#123;                float4 pos:SV_POSITION;                float3 worldNormal:TEXCOORD0;                float3 worldPos:TEXCOORD1;                float2 uv:TEXCOORD2;//用于储存纹理坐标的变量uv，以便在片元着色器使用该坐标进行纹理采样。            &#125;;</code></pre><p>我们在a2v声明了一个变量texcoord，这样模型的第一组纹理坐标就会储存到其中。</p><p>然后在v2f中添加了用于存储纹理的变量uv，以便在片元着色器使用该坐标进行纹理采样。</p><p>定义顶点着色器：</p><pre><code>            v2f vert(a2v v)            &#123;                v2f o;                o.pos=UnityObjectToClipPos(v.vertex);                o.worldNormal=UnityObjectToWorldNormal(v.normal);                o.worldPos=mul(unity_ObjectToWorld,v.vertex).xyz;                o.uv=TRANSFORM_TEX(v.texcoord,_MainTex);                return o;                        &#125;</code></pre><p>顶点着色器首先还是完成<strong>将模型空间中顶点坐标变换到剪裁空间</strong>，然后计算了世界空间下的法线和顶点供之后使用。</p><p>这里我们直接使用一个<strong>内置宏TRANSFORM_TEX</strong>来计算uv</p><p>它接受两个参数，一个是顶点纹理坐标，一个是纹理名。</p><p>具体计算过程其实是这样的，但此处直接改用宏了，了解一下即可。</p><pre><code>o.uv=v.texcoord.xy*_MainTex_ST.xy+_MainTex_ST.zw//使用缩放属性_MainTex_ST.xy对顶点纹理坐标进行缩放，然后使用偏移属性_MainTex_ST.zw进行偏移</code></pre><p>最后定义片元着色器，计算漫反射时使用纹理中的纹素值：</p><pre><code>            fixed4 frag(v2f i):SV_Target            &#123;                fixed3 WorldNormal=normalize(i.worldNormal);                fixed3 worldLightDir=normalize(UnityWorldSpaceLightDir(i.worldPos));                                //使用纹理来采样漫反射颜色                fixed3 albedo=tex2D(_MainTex,i.uv).rgb*_Color.rgb;                fixed3 ambient=UNITY_LIGHTMODEL_AMBIENT.xyz*albedo;                fixed3 diffuse=_LightColor0.rgb*albedo*max(0,dot(WorldNormal,worldLightDir));//albedo取代了之前的漫反射系数Diffuse                //使用布林冯模型计算高光反射                fixed3 viewDir=normalize(UnityWorldSpaceViewDir(i.worldPos));                fixed3 HalfDir=normalize(worldLightDir+viewDir);                fixed3 Specular = _LightColor0.rgb*_Specular.rgb*pow(max(0,dot(WorldNormal,HalfDir)),_Gloss);                return fixed4(ambient+diffuse+Specular,1.0);//将环境光，漫反射，高光反射相加。            &#125;           //ENDCG</code></pre><p>上述代码中，我们先获取世界空间下的法线和光照并归一化</p><p>然后使用tex2D函数（接受两个参数，一个为被采样的纹理，一个为float2类型的纹理坐标）进行采样。</p><p>将采样结果（纹素值）与颜色属性进行相乘作为材质的反射率（albedo），让它与环境光照相乘得到环境光部分。</p><p>在最后使用albedo来计算漫反射光照的结果，并和环境光，高光反射相加后返回。</p><p>最后记得设置合适的Fallback哦。</p><pre><code>    Fallback &quot;Specular&quot;</code></pre><p><img src="/images/loading.jpg" data-original="/2021/10/07/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A4%EF%BC%88%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86%EF%BC%89/image-20211007105621607.png" alt="image-20211007105621607"></p><hr><h3 id="纹理属性"><a href="#纹理属性" class="headerlink" title="纹理属性"></a>纹理属性</h3><p>纹理面板中第一个属性是纹理类型，本节中使用的是<strong>texture</strong>（在笔者的版本找不到texture，默认为<strong>default</strong>）</p><p>在之后的法线纹理中会使用<strong>normal map</strong>类型，在更后面的章节还会看到Cubemap等高级纹理。</p><p>只有设置正确的纹理类型，才能为unityShader传递正确的纹理。</p><p>接下来是<strong>Alpha通道</strong>，在之后会讲到。</p><p>接下来的属性warp mode非常重要，有Repeat和Clamp两种模式。</p><p>在Repeat中若纹理大于1，纹理会不断重复。而Clamp中将会进行截取。</p><p>我们上面的效果图是Repeat的结果，而Clamp的结果是这样的。</p><p><img src="/images/loading.jpg" data-original="/2021/10/07/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A4%EF%BC%88%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86%EF%BC%89/image-20211007110546758.png" alt="image-20211007110546758"></p><p>下一个属性是<strong>Filter mode</strong>，决定了当纹理由于变换而产生拉伸时将使用哪一种滤波模式。</p><p>支持三种模式，Point，Bilinear，Trilinear，得到滤波效果依次提升，耗费的性能也依次增大。</p><p><img src="/images/loading.jpg" data-original="/2021/10/07/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A4%EF%BC%88%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86%EF%BC%89/%5Cimage-20211007111448323.png" alt="image-20211007111448323"></p><p>众所周知近大远小，看向远方时纹理也是缩小的。纹理缩小更加复杂，我们需要处理抗锯齿的问题。</p><p>最常使用的方法是<strong>多级纹理渐变技术（mipmapping）</strong>。</p><p>原理是提前进行滤波处理得到很多更小的图形，组成一个图形金字塔，每层都是对上层图像降采样的结果。</p><p>物体远离相机时可以直接使用较小的纹理，代价是需要多占用33%的空间，是以空间换时间的做法。</p><p>通常我们选择<strong>Bilinear滤波模式</strong>。</p><p><img src="/images/loading.jpg" data-original="/2021/10/07/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A4%EF%BC%88%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86%EF%BC%89/image-20211007113400465.png" alt="image-20211007113400465"></p><p>最后是<strong>最大尺寸和纹理模式</strong>。unity允许我们为不同平台选择不同的分辨率。</p><p>若导入的纹理大于<strong>max texture size</strong>的值，则会被设为这个值。</p><p>导入的纹理可以是非正方形的，但长宽大小应该是2的幂（采用非2幂大小会导致占用更多空间性能下降）</p><p><strong>format</strong>决定了使用哪种格式来储存纹理，<strong>精度越高效果越好，同样的所占空间就要越高</strong>。</p><p>对于一些不需要很高精度的纹理（例如漫反射颜色的纹理），应该<strong>尽量使用压缩格式。</strong></p><hr><h2 id="凹凸映射"><a href="#凹凸映射" class="headerlink" title="凹凸映射"></a>凹凸映射</h2><p>凹凸映射是使用一张纹理来修改模型表面的法线。为模型提供更多的细节，让模型看上去凹凸不平。</p><p>有两种方法进行凹凸映射：一种是使用一张<strong>高度纹理（height map）</strong>模拟表面位移，也称<strong>高度映射。</strong></p><p>另一种方法是使用一张<strong>法线纹理</strong>，直接存储表面法线，又称为<strong>法线映射</strong>。</p><hr><h3 id="高度纹理"><a href="#高度纹理" class="headerlink" title="高度纹理"></a>高度纹理</h3><p>高度图中储存的是强度值，表示模型表面局部的海拔高度。</p><p>颜色越浅表面该位置的表面越向外凸起，越深越向里凹。</p><p>高度映射好处是很直观，缺点是计算复杂，实时计算时不能直接得到表面法线，需要由像素的灰度值计算而得。</p><hr><h3 id="法线纹理"><a href="#法线纹理" class="headerlink" title="法线纹理"></a>法线纹理</h3><p>法线纹理中储存的是表面的法线方向，用于法线的分量范围在**[-1,1]<strong>，像素的范围在</strong>[0,1]**因此我们一般会做如下映射：</p><p><img src="/images/loading.jpg" data-original="/2021/10/07/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A4%EF%BC%88%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86%EF%BC%89/image-20211007120937229.png" alt="image-20211007120937229"></p><p>这就要求我们在shader中对法线纹理进行纹理采样后，对结果进行一次<strong>反映射</strong>，也就是上述函数的逆函数：</p><p><img src="/images/loading.jpg" data-original="/2021/10/07/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A4%EF%BC%88%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86%EF%BC%89/image-20211007121031809.png" alt="image-20211007121031809"></p><p>用于方向是相对于模型空间来说的，法线纹理中储存的法线应该储存在哪个空间呢？</p><p>对于模型自带的顶点法线，它们被定义在模型空间中，因此直接的想法就是将修改后的模型空间的法线储存在一张纹理中。</p><p>实际制作中，往往采用另一种坐标空间，即顶点的切线空间来储存法线，这种纹理被称为<strong>切线空间的法线纹理（tangent-space-normal map）</strong>.</p><p>对于每一个顶点，都有一个自己的切线空间，这个切线空间的原点是顶点本身</p><p>z轴是顶点的<strong>法线</strong>方向（n），x轴是顶点的<strong>切线</strong>方向（t），y轴可由法线和切线叉积而得（又称为<strong>副切线或副法线</strong>）。</p><p><img src="/images/loading.jpg" data-original="/2021/10/07/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A4%EF%BC%88%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86%EF%BC%89/image-20211007124713521.png" alt="image-20211007124713521"></p><p>如图所示，模型空间的法线纹理是五颜六色的，因为所有法线所在的坐标空间都是模型空间</p><p>因此每个点的法线是各异的，经过映射后储存到纹理中就对应各种<strong>RGB值</strong>。</p><p>而切线空间中，每个顶点法线所在的坐标是各异的，法线都为（0,0,1）</p><p>经过映射后就对应了（0.5,0.5,1）浅蓝色，即为法线纹理中大片的蓝色</p><hr><p>实际上，法线储存在哪个空间都可以，后续的光照计算才是我们的重点。</p><p>选择哪个坐标系意味着要将不同的信息转换到响应的坐标系中。</p><p>例如若选择了切线空间，就要把法线纹理中得到的法线方向从切线空间转换到世界空间。</p><p>使用模型空间储存法线优点如下：</p><ul><li><strong>实现简单，更加直观。</strong></li><li><strong>在纹理坐标缝合处和尖锐的边角部分，可见的突变间隙变少，可以提供平滑的边界。</strong></li></ul><p>但使用切线空间优点更多：</p><ul><li><strong>自由度更高</strong>。模型空间下的法线纹理记录的是<strong>绝对法线信息</strong>，仅可用于创建它时的那个模型。切线空间下记录的是相对法线信息，可用于其他模型</li><li><strong>可进行UV动画</strong>。可以移动一个纹理的UV值来实现凹凸移动的效果，例如水波和火山熔岩。</li><li><strong>可重用法线纹理</strong>。例如一张法线纹理可以应用到一个砖块的六个面。</li><li><strong>可压缩</strong>。可以只储存XY方向，推导得到Z方向（总是正的）。模型空间中因为每个方向都是可能的，因此必须不可压缩的储存三个方向的值。</li></ul><hr><h3 id="切线空间下计算"><a href="#切线空间下计算" class="headerlink" title="切线空间下计算"></a>切线空间下计算</h3><p>基本思路是在片元着色器中通过纹理采样得到切线空间下的法线，然后与切线空间下的视角方向，光照方向进行计算，得到光照结果。</p><p>这里我们就不那么啰嗦了，直接来写一些与之前不同的东西吧。</p><p>属性方面，在properties语义块中添加了法线纹理的属性，以及用来控制凹凸程度的属性：</p><pre><code>    Properties&#123;        _Color (&quot;Color Tint&quot;,Color)=(1,1,1,1)        _MainTex(&quot;Main Tex&quot;,2D)=&quot;White&quot;&#123;&#125;        _BumpMap(&quot;Normal Map&quot;,2D)=&quot;bump&quot;&#123;&#125;//法线纹理        _BumpScale(&quot;Bump Scale&quot;,Float)=1.0//凹凸程度        _Specular(&quot;Specular&quot;,Color)=(1,1,1,1)        _Gloss(&quot;Gloss&quot;,Range(8.0,256))=20        &#125;</code></pre><p>法线纹理_BumpMap这里同样也是2D类型的，我们使用bump作为内置的法线纹理默认值。</p><p>_BumpScale则用于控制凹凸程度，当它为0时，法线纹理就不会对光照产生任何影响。</p><p>设前向渲染略，指定着色器略，直接来看在代码块中如何与我们properties中声明的属性建立联系。</p><pre><code>            fixed4 _Color;            sampler2D _MainTex;            float4 _MainTex_ST;//用于声明_MainTex的属性            sampler2D _BumpMap;            float4 _BumpMap_ST;//用于声明_BumpMap的属性            float _BumpScale;            fixed4 _Specular;            float _Gloss;</code></pre><p>上述的纹理_ST则是用来得到<strong>纹理的平铺和偏移系数。</strong></p><p>切线空间是顶点法线和切线构建出的一个坐标空间，因此我们需要得到顶点的切线信息：</p><pre><code>            struct a2v            &#123;                float4 vertex:POSITION;                float3 normal:NORMAL;                float4 tangent:TANGENT;//告诉unity将顶点的切线方向存入tangent，第四个w分量用来储存切线空间中副切线的方向性                float4 texcoord:TEXCOORD0;//第一组纹理坐标            &#125;;</code></pre><p>这里注意tangent是个float4类型的数</p><p>我们需要在顶点着色器中计算出切线空间下的光照和视角方向，因此我们需要在输出结构里面储存他们。</p><pre><code>            struct v2f            &#123;                float4 pos:SV_POSITION;                float4 uv:TEXCOORD0;//用于储存纹理坐标的变量uv，以便在片元着色器使用该坐标进行纹理采样。                float3 lightDir:TEXCOORD1;                float3 viewDir:TEXCOORD2;            &#125;;</code></pre><p>定义顶点着色器：</p><pre><code>            v2f vert(a2v v)            &#123;                v2f o;                o.pos=UnityObjectToClipPos(v.vertex);                o.uv.xy=v.texcoord.xy*_MainTex_ST.xy+_MainTex_ST.zw;//对顶点纹理坐标进行变换                o.uv.zw=v.texcoord.xy*_BumpMap_ST.xy+_BumpMap_ST.zw;//                //计算副切线               // float3 binormal=cross(normalize(v.normal),normalize(v.tangent.xyz))*v.tangent.w;//使用法线和切线做叉积得到副切线               // float3x3 rotation=float3x3(v.tangent.xyz,binormal,v.normal);//切线方向，副切线方向，法线方向按行排列得到变换矩阵                TANGENT_SPACE_ROTATION;//完全等同于于上述语句，得出模型空间到切线空间的变换矩阵                                //TANGENT_SPACE_ROTATION;                o.lightDir=mul(rotation,ObjSpaceLightDir(v.vertex)).xyz;//                o.viewDir=mul(rotation,ObjSpaceViewDir(v.vertex)).xyz;                return o;                            &#125;</code></pre><p>因为我们使用两张纹理，因此需要存储两个纹理坐标。因此v2f的uv为float4类型</p><p>其中xy存储_MainTex的纹理坐标，zw存储BumpMap的纹理坐标。</p><p>然后计算得到副切线，再将模型空间下的切线方向，副切线方向，法线方向按行排列得到变换矩阵rotation。</p><p>unity提供了内置宏TANGENT_SPACE_ROTATION与上述代码语句完全一致。</p><p>使用变换矩阵rotation将光照和视角方向转移到切线空间，然后完成顶点着色器的工作。</p><p>我们在顶点着色器完成了大部分的工作，因此片元着色器只需要采样得到切线空间下的法线，再在切线空间下进行光照计算即可：</p><pre><code>            //片元着色器只需要采样得到切线空间下的法线坐标            fixed4 frag(v2f i):SV_Target&#123;                fixed3 tangentLightDir=normalize(i.lightDir);                fixed3 tangentViewDir=normalize(i.viewDir);                fixed4 packedNormal=tex2D(_BumpMap,i.uv.zw);//tex2D函数进行法线的纹理采样                fixed3 tangentNormal;                tangentNormal=UnpackNormal(packedNormal);                tangentNormal.xy*=_BumpScale;                tangentNormal.z=sqrt(1.0-saturate(dot(tangentNormal.xy,tangentNormal.xy)));                fixed3 albedo=tex2D(_MainTex,i.uv).rgb*_Color.rgb;//tex2D函数进行纹理采样                fixed3 ambient=UNITY_LIGHTMODEL_AMBIENT.xyz*albedo;                fixed3 diffuse=_LightColor0.rgb*albedo*max(0,dot(tangentNormal,tangentLightDir));                fixed3 halfDir=normalize(tangentLightDir+tangentViewDir);                fixed3 specular=_LightColor0.rgb*_Specular.rgb*pow(max(0,dot(tangentNormal,halfDir)),_Gloss);                return fixed4(ambient+diffuse+specular,1.0);            &#125;</code></pre><p>我们将所有所需的变量都转化到切线空间，也就顾名思义是切线空间下的计算啦。</p><p>先用tex2D函数对法线纹理_BumpMap进行采样。随后因为法线纹理储存的是像素值，因此我们需要将其反映射回来。（在没有正确设置normal map的情况下）</p><p>UnpackNormal函数做的就是反映射过程，随后将我们的xy变量乘以凹凸分量，z分量由xy分量计算得到。</p><p>最后设置正确的Fallback “Specular”，得到效果。</p><p><img src="/images/loading.jpg" data-original="/2021/10/07/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A4%EF%BC%88%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86%EF%BC%89/image-20211008110331278.png" alt="image-20211008110331278"></p><hr><h3 id="世界空间下计算"><a href="#世界空间下计算" class="headerlink" title="世界空间下计算"></a>世界空间下计算</h3><p>基本思路是在顶点着色器中计算从切线空间到世界空间的变换矩阵，然后传递给片元着色器。</p><p>变换矩阵由顶点的切线，副法线和法线在世界空间下的表示来得到。</p><p>因此修改输出结构体v2f，让它能传递我们要的变换矩阵：</p><pre><code>            struct v2f            &#123;                float4 pos:SV_POSITION;                float4 uv:TEXCOORD0;//用于储存纹理坐标的变量uv，以便在片元着色器使用该坐标进行纹理采样。                float4 TtoW0:TEXCOORD1;                float4 TtoW1:TEXCOORD2;//从切线空间到世界空间变换矩阵的每一行                float4 TtoW2:TEXCOORD3;             &#125;;</code></pre><p>因为对矢量是变换是3x3的矩阵，因此我们使用float4类型的变量的话，w分量还能用来储存顶点的世界坐标。</p><p>顶点着色器如下：</p><pre><code>            v2f vert(a2v v)            &#123;                v2f o;                o.pos=UnityObjectToClipPos(v.vertex);                o.uv.xy=v.texcoord.xy*_MainTex_ST.xy+_MainTex_ST.zw;                o.uv.zw=v.texcoord.xy*_BumpMap_ST.xy+_BumpMap_ST.zw;                float3 worldPos=mul(unity_ObjectToWorld,v.vertex).xyz;                fixed3 worldNoral=UnityObjectToWorldNormal(v.normal);                fixed3 worldTangent=UnityObjectToWorldDir(v.tangent);//顶点切线                fixed3 worldBinormal=cross(worldNoral,worldTangent)*v.tangent.w;//副切线等于法线和切线做叉积乘以表示方向的w分量；                                //计算从切线空间到世界空间的变换矩阵                o.TtoW0=float4(worldTangent.x,worldBinormal.x,worldNoral.x,worldPos.x);                o.TtoW1=float4(worldTangent.y,worldBinormal.y,worldNoral.y,worldPos.y);                o.TtoW2=float4(worldTangent.z,worldBinormal.z,worldNoral.z,worldPos.z);                return o;                            &#125;</code></pre><p>我们将顶点切线，副切线和法线按列摆放，得到我们所需的矩阵三行。</p><p>片元着色器如下：</p><pre><code>            fixed4 frag(v2f i):SV_Target&#123;                float3 worldPos=float3(i.TtoW0.w,i.TtoW1.w,i.TtoW2.w);                                //算出光照和视线                fixed3 lightDir=normalize(UnityWorldSpaceLightDir(worldPos));                fixed3 viewDir=normalize(UnityWorldSpaceViewDir(worldPos));                                //获取切线空间下的法线                fixed3 bump=UnpackNormal(tex2D(_BumpMap,i.uv.zw));                bump.xy*=_BumpScale;                bump.z=sqrt(1.0-saturate(dot(bump.xy,bump.xy)));                //将法线变换到世界坐标                bump=normalize(half3(dot(i.TtoW0.xyz,bump),dot(i.TtoW1.xyz,bump),dot(i.TtoW2.xyz,bump)));                fixed3 albedo=tex2D(_MainTex,i.uv).rgb*_Color.rgb;//tex2D函数进行纹理采样                fixed3 ambient=UNITY_LIGHTMODEL_AMBIENT.xyz*albedo;                fixed3 diffuse=_LightColor0.rgb*albedo*max(0,dot(bump,lightDir));                fixed3 halfDir=normalize(lightDir+viewDir);                fixed3 specular=_LightColor0.rgb*_Specular.rgb*pow(max(0,dot(bump,halfDir)),_Gloss);                return fixed4(ambient+diffuse+specular,1.0);               &#125;</code></pre><p>我们首先利用w分量将世界坐标取出，由于光照和视线可以直接得到世界空间下的所以直接做归一化就行。</p><p>切线空间下的法线也是用tex2D函数进行纹理映射，xy分量乘凹凸，z分量靠推导（罗里吧嗦）</p><p>接着就是用我们的变换矩阵将切线空间下的法线变换到世界空间。（个人觉得这句语句比较难理解，以后有空多看吧）</p><p>然后用纹理和法线纹理去做漫反射和高光反射输出得到结果。</p><p>从视觉表现上看，切线空间下和世界空间下计算光照几乎没有区别。</p><hr><h2 id="渐变纹理"><a href="#渐变纹理" class="headerlink" title="渐变纹理"></a>渐变纹理</h2><p>我们常常使用渐变纹理来控制漫反射光照的结果，这样对比之前使用表面法线和光照方向的点积和反射率相乘的那种计算会更加灵活。</p><p>可以保证物体轮廓比传统漫反射光照更加明显，还能提供多种色调变化。</p><p>着色器编写直接跳到属性部分：</p><pre><code>    Properties    &#123;        _Color (&quot;Color Tint&quot;, Color) = (1,1,1,1)        _RampTex (&quot;Ramp Tex&quot;, 2D)=&quot;white&quot;&#123;&#125;        _Specular(&quot;Specular&quot;, Color)=(1,1,1,1)        _Gloss(&quot;Gloss&quot;,Range(8.0,256))=20    &#125;</code></pre><p>我们存了一个2D类型的纹理，随后也得定义它的纹理属性变量ST</p><pre><code>        fixed4 _Color;        sampler2D _RampTex;        float4 _RampTex_ST;        fixed4 _Specular;        float _Gloss;</code></pre><p>顶点着色器的输入和输出就是最常规的带纹理的那种</p><pre><code>        struct a2v        &#123;            float4 vertex:POSITION;            float3 normal:NORMAL;            float4 texcoord:TEXCOORD0;                    &#125;;        struct v2f        &#123;            float4 pos: SV_POSITION;            float3 worldNormal :TEXCOORD0;            float3 worldPos:TEXCOORD1;            float2 uv:TEXCOORD2;        &#125;;</code></pre><p>顶点着色器也是最简单的就略过了，这里可以直接用内置宏来得到uv了</p><pre><code>o.uv=TRANSFORM_TEX(v.texcoord,_RampTex);</code></pre><p>注意康康片元着色器</p><pre><code>        fixed4 frag(v2f i):SV_Target        &#123;            ...            //使用纹理来采样漫反射颜色            fixed halfLambert=0.5*dot(worldNormal,worldLightDir)+0.5;            fixed3 diffuseColor=tex2D(_RampTex,fixed2(halfLambert,halfLambert)).rgb*_Color.rgb;            fixed3 diffuse=_LightColor0.rgb*diffuseColor;            fixed3 viewDir=normalize(UnityWorldSpaceViewDir(i.worldPos));            fixed3 halfDir=normalize(worldLightDir+viewDir);            fixed3 specular=_LightColor0.rgb*_Specular.rgb*pow(max(0,dot(worldNormal,halfDir)),_Gloss);            return fixed4(ambient+diffuse+specular,1.0);        &#125;</code></pre><p>这里我们使用了之前提到的半兰伯特模型，这样得到的halfLambert在[0,1]之间，</p><p>我们用halfLambert构建一个纹理坐标，用它来进行纹理采样。</p><p>由于_RampTex其实是一个一维纹理（纵轴方向颜色不变），因此纹理坐标的u和v我们都用halfLambert</p><p>最后将渐变纹理采样得到的颜色和材质颜色相乘，得到最终的漫反射颜色。</p><p><img src="/images/loading.jpg" data-original="/2021/10/07/2021-10-07-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A4%EF%BC%88%E5%9F%BA%E7%A1%80%E7%BA%B9%E7%90%86%EF%BC%89/image-20211008115610063.png" alt="image-20211008115610063"></p><hr><h2 id="纹理遮罩"><a href="#纹理遮罩" class="headerlink" title="纹理遮罩"></a>纹理遮罩</h2><p>纹理遮罩一般让我们来保护某块区域，使他们免于修改，可以得到更为细腻的效果，而不是像我们直接的高光反射直接打在全局上。</p><p>流程一般是通过采样得到遮罩纹理的纹素值，然后使用某个通道的值与某种表面属性进行相乘，当该通道为0时就可以保护不受该属性影响。</p><p>首先Properties需要更多变量来控制高光反射：</p><pre><code>    Properties    &#123;        _Color (&quot;Color Tint&quot;,Color)=(1,1,1,1)        _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125;        _BumpMap(&quot;Normal Map&quot;,2D)=&quot;bump&quot;&#123;&#125;        _BumpScale(&quot;Bump Scale&quot;,Float)=1.0        _SpecularMask(&quot;Specular Mask&quot;,2D)=&quot;white&quot;&#123;&#125;        _SpecularScale(&quot;Specular Scale&quot;,Float)=1.0        _Specular(&quot;Specular&quot;,Color)=(1,1,1,1)        _Gloss(&quot;Gloss&quot;,Range(8.0,256))=20    &#125;</code></pre><p>_SpecularMask就是我们使用的高光反射遮罩纹理， _SpecularScale则是用于控制遮罩影响度的系数</p><p>接下来来声明变量来建立联系吧</p><pre><code>            fixed4 _Color;            sampler2D _MainTex;            float4 _MainTex_ST;            sampler2D _BumpMap;            float _BumpScale;            sampler2D _SpecularMask;            float _SpecularScale;            fixed4 _Specular;            float _Gloss;</code></pre><p>_MainTex_ST是我们为主纹理，法线纹理，遮罩纹理定义的共同使用的纹理属性变量。</p><p>在顶点着色器中对光照方向和视角方向从模型空间转换到切线空间：</p><pre><code>v2f vert (a2v v)&#123;    v2f o;    o.pos = UnityObjectToClipPos(v.vertex);    o.uv.xy=v.texcoord.xy*_MainTex_ST.xy+_MainTex_ST.zw;    TANGENT_SPACE_ROTATION;    o.lightDir=mul(rotation,ObjSpaceLightDir(v.vertex)).xyz;    o.viewDir=mul(rotation,ObjSpaceViewDir(v.vertex)).xyz;    return o;&#125;</code></pre><p>在片元着色器中使用纹理遮罩来控制模型表面的高光反射强度：</p><pre><code>            fixed4 frag (v2f i) : SV_Target            &#123;                fixed3 tangentLightDir=normalize(i.lightDir);                fixed3 tangentViewDir=normalize(i.viewDir);                fixed3 tangentNormal=UnpackNormal(tex2D(_BumpMap,i.uv));                tangentNormal.xy*=_BumpScale;                tangentNormal.z=sqrt(1.0-saturate(dot(tangentNormal.xy,tangentNormal.xy)));                fixed3 albedo=tex2D(_MainTex,i.uv).rgb*_Color.rgb;//tex2D函数进行纹理采样                fixed3 ambient=UNITY_LIGHTMODEL_AMBIENT.xyz*albedo;                fixed3 diffuse=_LightColor0.rgb*albedo*max(0,dot(tangentNormal,tangentLightDir));                fixed3 halfDir=normalize(tangentLightDir+tangentNormal);                fixed specularMask=tex2D(_SpecularMask,i.uv).r*_SpecularScale;                fixed3 specular=_LightColor0.rgb*_Specular.rgb*pow(max(0,dot(tangentNormal,halfDir)),_Gloss)*specularMask;                return fixed4(ambient+diffuse+specular,1.0);            &#125;</code></pre><p>计算高光反射时，我们先对遮罩纹理_SpecularMask进行采样，我们选择使用r值来计算掩码值，</p><p>得到的掩码值和 _SpecularScale相乘，用来控制高光反射结果。</p><hr><p>国庆结束的10.7开始写这篇博客，10.8完成。</p><p>七号的状态很差，国庆爽翻了戒断反应严重，再加上焦虑什么的搞得人状态特别差。</p><p>晚上和喵喵聊了聊引擎的事情，散散步听着航向你的海岛感觉人好起来了（感谢喵喵！感谢鸟憨！）</p><p>最近可能会开始思考如何往引擎开发方向迈开腿，首要问题就是时间真的很不充足，这个得好好安排</p><p>重点是博客的编写我自己也开始慢慢感觉到有问题！</p><p>喵喵提醒我说没必要书上有的网上有的你全都抄一遍，你只需要让读者知道去哪里获取这些基础知识就可以了。</p><p>确实虽然我觉得自己博客有点像在抄书，对我重新理解也有帮助（主要是看着字数多很有成就感），但是真的</p><p>太浪费时间了！~</p><p>动则几千字真的不是人敲的！</p><p>看来以后我应该多谈自己在实现这个技术时遇到的困难，</p><p>我是怎么解决的我的思路是什么样的，而不是做成傻瓜式教程。</p><p>包括我自己是还没写纹理遮罩就开始感觉rnm我是真的写不下去了。</p><p>真的最后一次用这种方式将博客完结，以后尽量精简。</p><p>2021-10-08-13:08</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文为学习UnityShader时所记录的笔记，供学习产出和日后复习使用。&lt;/p&gt;
&lt;p&gt;学习资料为冯乐乐（问就是我女神）的《UnityShader入门精要》&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>UnityShader入门精要④（基础shader编写和光照模型）</title>
    <link href="https://aprilnavi.github.io/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/"/>
    <id>https://aprilnavi.github.io/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/</id>
    <published>2021-09-17T03:06:58.000Z</published>
    <updated>2021-10-07T01:34:06.924Z</updated>
    
    <content type="html"><![CDATA[<p>本文为学习UnityShader时所记录的笔记，供学习产出和日后复习使用。</p><p>学习资料为冯乐乐（问就是我女神）的《UnityShader入门精要》</p><span id="more"></span><hr><h1 id="基础shader编写"><a href="#基础shader编写" class="headerlink" title="基础shader编写"></a>基础shader编写</h1><p>我们正式开始使用unityshader来编写最简单的顶点/片元着色器</p><h2 id="着色器基本结构"><a href="#着色器基本结构" class="headerlink" title="着色器基本结构"></a>着色器基本结构</h2><p>顶点着色器/片元着色器的基本结构大体相同</p><p>包含了<strong>Shader，Properties，SubShader，Fallback</strong>等语义块。</p><pre><code>Shader &quot;MyShaderName&quot;&#123;    Properties    &#123;    //属性    &#125;    SubShader    &#123;        Pass        &#123;            CGPROGRAM                        #pragma vertex vert//用于指定顶点着色器的名字，这里是vert            #pragma fragment frag//用于指定片元着色器的名字，这里是frag            //以下是Cg代码            float4 vert(float4 v：POSITION) &#123;                return mul(UNITY_MATRIX_MVP,v);&#125;            fixed4 frag() : SV_Target&#123;                return fixed4(1.0,1.0,1.0,1.0);        &#125;                        ENDCG        &#125;    &#125;        //Fallback &quot;XXXXX&quot; //上述SubShader渲染失败后回调此Shader&#125;</code></pre><p>在我们的例子中，我们编写了顶点着色器和片元着色器（一般也就写这两个）。</p><p>先看看顶点着色器，float4是函数的返回值，vert的函数名，float4和v是参数类型和形参（和我们的编程语言还蛮像的）</p><p>这里的POSITION是Cg中的语义，是不可省略的，用于告诉系统用户输入的值是什么类型的，以及输出什么样的值。</p><p>我的理解是就和float一样用来表示数据类型的，相当于是在float的前提下再做了一个修饰。</p><p>我们都记得顶点着色器的任务是将模型空间的坐标转化到剪裁空间。</p><p>这里的POSITION就表示输入的float4数据是应用阶段输出的模型顶点坐标，如果没有POSITION我们就不知道这个float4的数据有甚么意义。</p><p>PS：</p><p>dx10中引入了SV_POSITION的系统数值语义，它和POSITION的等阶的</p><p>但在某些平台（索尼ps4）上必须使用SV_POSITION来修饰顶点着色器的输出，否则Shader无法正常工作。</p><p>为了让我们的Shader具有更好的跨平台性，建议使用SV开头的语义进行修饰</p><p>接下来把目光转移到片元着色器上。在我们的例子中它没有任何输入（具体情况肯定不这么写啦），输出一个Fixed4类型的值，并使用了SV_Target进行限定。</p><p>片元着色器的目标是输出一个颜色值，这个SV_Target表示将fixed4的这个数据输出到帧缓存（没听懂？那就记住都要加SV_Target就完事了）</p><p>片元着色器输出的颜色每个分量都在[0,1]之间，其中（0,0,0）表示黑色，而（1,1,1）表示白色。</p><p>按上述代码编写，我们大概会得到一个纯白的材质效果。</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210917121452205.png" alt="image-20210917121452205"></p><hr><h2 id="更多的模型数据"><a href="#更多的模型数据" class="headerlink" title="更多的模型数据"></a>更多的模型数据</h2><p>虽然顶点着色器最基本的任务是将模型顶点转换到剪裁空间，但我们希望获取的顶点信息肯定不仅限它的坐标位置。</p><p>我们同样需要<strong>纹理坐标，法线，切线，顶点颜色等信息</strong>（这个需求是非常常见的），该怎么做呢？答案是使用结构体！</p><pre><code>Pass        &#123;            CGPROGRAM                        #pragma vertex vert            #pragma fragment frag            struct a2v &#123;        float4 vertex:POSITION;//告诉unity用顶点坐标填充vertex向量        float3 normal:NORMAL;//告诉unity用法线方向填充normal        float4 texcoord:TEXCOORD;//告诉unity用模型的第一套纹理坐标填充texcoord变量&#125;;            float4 vert(a2v v) &#123;            return mul(UNITY_MATRIX_MVP,v.vertex);&#125;            fixed4 frag() : SV_Target&#123;            ...        &#125;            ENDCG                                    &#125;            &#125;</code></pre><p>有过编程经验的大家对结构体一定都很熟悉，这里就不说明结构体的声明和使用语法了，照葫芦画瓢就行，但记住这里也要加语义限定哦。</p><p>a2v是什么意思？指的是application to vertex，也就是将数据从应用阶段传递到顶点着色器</p><hr><h2 id="顶点着色器和片元着色器的通信"><a href="#顶点着色器和片元着色器的通信" class="headerlink" title="顶点着色器和片元着色器的通信"></a>顶点着色器和片元着色器的通信</h2><p>在很多情况下，片元着色器的输入都是顶点着色器计算得出的结果，因此就涉及到两个着色器的通信</p><p>其实很简单，我们只需要再建一个结构体就行（有编程经验的学shader代码理解得真的很快对吧）</p><pre><code>Pass        &#123;            CGPROGRAM            #include &quot;UnityCG.cginc&quot;            #pragma vertex vert            #pragma fragment frag            fixed4 _Color;            struct a2v &#123;        float4 vertex:POSITION;//告诉unity用顶点坐标填充vertex向量        float3 normal:NORMAL;//告诉unity用法线方向填充normal        float4 texcoord:TEXCOORD;//告诉unity用模型的第一套纹理坐标填充texcoord变量&#125;;            struct v2f &#123;                float4 pos:SV_POSITION;                fixed3 color:COLOR0;//告诉unity储存颜色    &#125;;            v2f vert(a2v v) &#123;                v2f o;                o.pos = UnityObjectToClipPos(v.vertex);                o.color = v.normal * 0.5 + fixed3(0.5, 0.5, 0.5);                return o;&#125;            fixed4 frag(v2f i) : SV_Target&#123;                fixed3 c = i.color;            c *= _Color.rgb;            return fixed4(c,1.0);        &#125;            ENDCG                                    &#125;            &#125;</code></pre><p>在上面的代码中，我们定义了一个新的结构体v2f（<strong>vertex to fragment</strong>不用我多说了吧），同样里面每个变量也要指定语义。</p><p>得注意的是，<strong>片元着色器的输出结构中必须包含一个语义为SV_POSITION</strong>,否则渲染器就无法得到裁剪空间的坐标，更无法成功将顶点渲染。</p><p>在本例中，顶点着色器接收a2v的数据，计算出一个v2f（位置，颜色）的值为片元着色器所用，片元着色器直接把v2f的颜色信息输出了。</p><p>这样就实现了两个着色器的通信，在今后的案例也是如此的，应该很好理解。</p><hr><h2 id="属性的使用"><a href="#属性的使用" class="headerlink" title="属性的使用"></a>属性的使用</h2><p>假如我们想要直接在材质面板控制屏幕上显示的颜色，记得我们说过的吗？在Properties内声明属性就能将其在材质面板显示。</p><pre><code>Properties&#123;        _Color(&quot;Color Tint&quot;,Color) = (1.0,1.0,1.0,1.0)    &#125;</code></pre><p>属性编写的具体格式在第二章节的笔记有详细说明，包括常见属性和其类型。</p><hr><h2 id="UNITY的内置文件和变量"><a href="#UNITY的内置文件和变量" class="headerlink" title="UNITY的内置文件和变量"></a>UNITY的内置文件和变量</h2><p>包含文件（include file）是类似于C++中头文件的一种文件，后缀为.cginc。</p><p>我们可以使用#include的将其包含进来，这样就能使用Unity为我们提供的特别有用的变量和帮助函数。</p><p>![image-20210917225515044]image-20210917225515044.png)</p><p>其中“UnityCG.cginc”是我们最常接触的包含文件。</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210917225530441.png" alt="image-20210917225530441"></p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210917225546996.png" alt="image-20210917225546996"></p><hr><p>emmm今天一整天都在摸鱼呢 ———-2021.9.17 23:00完成</p><hr><h1 id="Unity中的基础光照"><a href="#Unity中的基础光照" class="headerlink" title="Unity中的基础光照"></a>Unity中的基础光照</h1><p>渲染总是围绕着一个基础问题：我们如何决定一个像素的颜色？</p><p>宏观的来说，这包括一个像素的可见性和光照计算。</p><p>而光照模型就为我们进行光照计算提供了帮助。</p><hr><h2 id="光照概念总述"><a href="#光照概念总述" class="headerlink" title="光照概念总述"></a>光照概念总述</h2><p><strong>辐照度（irradiance）</strong>：垂直于单位面积上单位时间内穿过的能量，是用来量化光的单位。辐照度和cosθ成正比（光源l和法线n的点积）</p><p><strong>散射（scattering）</strong>：只改变光的方向，不改变光的密度和颜色。散射到物体内部的称为<strong>折射（refraction）</strong>，散射到外部的称为<strong>反射（reflection）</strong></p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922090422100.png" alt="image-20210922090422100"></p><p>在光照模型中，我们用<strong>高光反射（specular）</strong>来计算物体表面如何反射光线</p><p>使用<strong>漫反射（diffuse）</strong>来计算多少光线被折射，吸收，散射出表面。</p><p>根据出射光线的数量和方向还能计算出<strong>出射度（和辐照度满足线性关系）</strong></p><p>ps：漫反射和高光反射的概念如果不能理解上面，个人感觉按初中物理那样理解的也可以</p><p><strong>着色（shading</strong>）是指根据材质属性（漫反射属性，光源信息等），使用一个公式流程去计算得出沿某个方向的出射度。</p><p>而这个公式就被称为<strong>光照模型（lighting model）</strong>。</p><p>光照模型并不能反应物体和光照之间的真实交互，但它们都是对真实场景理想化和简化后的模型，能拥有较为理想的效果</p><p>这些光照模型我们称为<strong>经验模型</strong>。</p><hr><p>计算机图形学第一定律：如果它看起来是对的，那么它就是对的。</p><hr><h2 id="标准光照模型（定义和公式）"><a href="#标准光照模型（定义和公式）" class="headerlink" title="标准光照模型（定义和公式）"></a>标准光照模型（定义和公式）</h2><p>我们将进入到摄像机的光线分为四个部分，每部分使用一种方法来计算它的贡献度。</p><p><strong>自发光（emissive）</strong>：用于描述给定一个方向时，物体表面本身会朝该方向发射多少光（辐射量）。</p><p>若没有开启全局光照，自发光并不会真的照亮周围物体，只是让它本身看起来更亮了。</p><p><strong>高光反射（specular）</strong>：用于描述光线从光线照射到表面时，会在完全镜面方向<strong>反射</strong>多少辐射量。</p><p><strong>漫反射（diffuse）</strong>：用于描述光线从光线照射到表面时，会在完全镜面方向<strong>散射</strong>多少辐射量。</p><p><strong>环境光（ambient）</strong>：用于描述其他所有间接光照。</p><hr><h3 id="自发光计算"><a href="#自发光计算" class="headerlink" title="自发光计算"></a><strong>自发光计算</strong></h3><p>直接使用该材质的自发光颜色。</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922094724149.png" alt="image-20210922094724149"></p><p>在此书的学习中，unityshader的编写大部分没有计算这方面。</p><p>若要计算也很简单，在最后片元着色器输出颜色之前将发光颜色添加到输出颜色上就可以。</p><h3 id="环境光计算"><a href="#环境光计算" class="headerlink" title="环境光计算"></a>环境光计算</h3><p>环境光一般被储存为一个全局变量，场景中的所有物体都使用这个环境光（近似认为环境光是一个常数），也是直接调用。</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922094144504.png" alt="image-20210922094144504"></p><p>一般我们通过unity的内置变量UNITY_LIGHTMODEL_AMBIENT就能得到环境光的颜色和强度信息。</p><h3 id="漫反射计算"><a href="#漫反射计算" class="headerlink" title="漫反射计算"></a><strong>漫反射计算</strong></h3><p>漫反射光照满足<strong>兰伯特定律（Lambert’s law）</strong>，即反射光线的强度和表面法线和光源方向夹角的余弦值成正比。</p><p>因此漫反射计算如下：</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922094708578.png" alt="image-20210922094708578"></p><h3 id="高光反射计算（重头戏）"><a href="#高光反射计算（重头戏）" class="headerlink" title="高光反射计算（重头戏）"></a>高光反射计算（重头戏）</h3><p>高光反射是一种经典的经验模型，计算高光反射需要知道的信息比较多，</p><p>如表面法线，视角方向，光源方向，反射方向等。</p><p>以上信息我们一般只需要知道三个，因为反射方向可以通过这三个计算。</p><h4 id="冯模型（phong）"><a href="#冯模型（phong）" class="headerlink" title="冯模型（phong）"></a>冯模型（phong）</h4><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922095304007.png" alt="image-20210922095304007"></p><p>我们来一一讲解其中系数的意义。</p><p>其中，<strong>m</strong>gloss是材质的光泽度，它是最后一个公式中最后一个项的指数，用于控制该高光区域亮点的大小。<strong>m</strong>gloss越大亮点就越小。</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922095835584.png" alt="image-20210922095835584"></p><p>图中所示p就是我们的<strong>m</strong>gloss</p><p><strong>m</strong>specular是材质的高光反射颜色，用于控制高光反射的强度和颜色。</p><p><strong>C</strong>light是光源的颜色和强度。</p><p>最后我们会需要一个max函数来确保v和r（反射方向和视线方向）的余弦不为负值。</p><hr><h4 id="布林-冯模型（Blinn-Phong）"><a href="#布林-冯模型（Blinn-Phong）" class="headerlink" title="布林-冯模型（Blinn-Phong）"></a>布林-冯模型（Blinn-Phong）</h4><p>与上述的冯模型相比，布林冯模型提出了简单的修改方式来得到近似的效果，与此同时拥有更快的计算速度。</p><p>具体方法是引入一个新的矢量h（半程向量），通过对v和l（视线方向和入射方向）取平均再归一化得到它。</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922101938081.png" alt="image-20210922101938081"></p><p>此时布林-冯模型的光照模型如下：</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922102113790.png" alt="image-20210922102113790"></p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922102123162.png" alt="image-20210922102123162"></p><p>我们通过使用n和h之间的夹角进行运算来取代冯模型中的v和r的夹角，这样就能避免计算r来加快运算速度。</p><p>若摄像机和光源距离模型足够远时，布林冯模型会快于冯模型。</p><p>这两种光照模型都是经验模型，不该认为布林冯模型是对冯模型的”正确近似“。</p><hr><h3 id="逐顶点光照和逐像素光照（着色频率）"><a href="#逐顶点光照和逐像素光照（着色频率）" class="headerlink" title="逐顶点光照和逐像素光照（着色频率）"></a>逐顶点光照和逐像素光照（着色频率）</h3><p>我们有两种选择，在顶点着色器中计算或是在片元着色器中计算。</p><hr><p>逐顶点运算也称为<strong>高洛德着色（Gouraud shading）</strong>，在每个顶点上计算光照，然后通过在渲染图元内进行线性插值。最后输出成像的颜色。</p><p>由于顶点数目往往远小于像素数目，因此逐顶点光照的计算量往往小于逐像素光照。</p><p>但逐顶点光照依赖线性插值，因此光照模型中有非线性运算时（例如计算高光反射）</p><p>逐顶点光照会有严重且明显的棱角现象。</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922103411549.png" alt="image-20210922103411549"></p><hr><p>逐像素运算也称<strong>冯着色（Phong shading）</strong>，冯插值，法线插值着色技术。</p><p>我们以每个像素为基础得到它的法线，再对法线进行插值。</p><p>ps：注意与前文的冯模型区分开来。冯着色和冯模型都是同一个人发明的，但一个是光照模型，一个是着色频率。</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922103907806.png" alt="image-20210922103907806"></p><hr><p>因此哪一种着色频率更好呢？并无绝对。</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922104026399.png" alt="image-20210922104026399"></p><p>几何足够复杂时，使用相对简单的着色模型也能得到不错的结果。</p><p>例如我们发现第三种几何形体已经很复杂了，但使用三种方法都相差无几，但使用冯着色模型会造成更大开销。</p><hr><h2 id="在Unityshader中实现各种光照"><a href="#在Unityshader中实现各种光照" class="headerlink" title="在Unityshader中实现各种光照"></a>在Unityshader中实现各种光照</h2><h3 id="漫反射光照模型"><a href="#漫反射光照模型" class="headerlink" title="漫反射光照模型"></a>漫反射光照模型</h3><p>我们在上文给出了基本光照模型中漫反射部分的计算公式：</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922105025269.png" alt="image-20210922105025269"></p><p>我们需要知道四个参数，<strong>c</strong>light（入射光的颜色和强度），<strong>m</strong>diffuse（材质的反射系数），n（表面法线），l（光源方向）。</p><p>Cg提供了saturate（x）函数来将x截取在[0,1]之内来完成max的操作。</p><h4 id="漫反射逐顶点光照"><a href="#漫反射逐顶点光照" class="headerlink" title="漫反射逐顶点光照"></a>漫反射逐顶点光照</h4><p>为了得到并能控制材质的漫反射颜色，我们构造Properties语义块声明一个color。</p><pre><code>    properties    &#123;        _Diffuse(&quot;Diffuse&quot;, Color) = (1, 1, 1, 1)    &#125;</code></pre><p>随后我们在pass的第一行指明该pass的光照模式为前向渲染。</p><pre><code>        SubShader&#123;        Pass&#123;                Tags&#123; &quot;LightMode&quot; = &quot;ForwardBase&quot;&#125;//前向渲染</code></pre><p>随后CGPROGRAM和ENDCG来包围Cg代码片，再包含内置文件lighting.cging，别忘了定义properties中属性相匹配的变量。</p><pre><code>        CGPROGRAM        #pragma vertex vert#pragma fragment frag#include &quot;Lighting.cginc&quot;        fixed4 _Diffuse;                ...        ...                ENDCG</code></pre><p>然后定义顶点着色器的输入和输出结构（顶点着色器的输出也是片元着色器的输入）</p><pre><code>    struct a2v    &#123;        float4 vertex:POSITION;//顶点        float3 normal:NORMAL;//法线    &#125;;    struct v2f    &#123;        float4 pos : SV_POSITION;//剪裁空间的顶点        fixed3 color : COLOR;//颜色    &#125;;</code></pre><p>接下来就是最为关键的顶点着色器，漫反射部分都在顶点着色器中完成。</p><p>还记得我们的公式吧：</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922105025269.png" alt="image-20210922105025269"></p><pre><code>    v2f vert(a2v v)    &#123;        v2f o;        //将顶点位置从模型空间转换到剪裁空间        o.pos = UnityObjectToClipPos(v.vertex);        //通过内置变量获取环境光        fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;        //获取法线方向并归一化（世界坐标）        fixed3 worldNormal = normalize(mul(v.normal, (float3x3)unity_WorldToObject));        //获取入射光并归一化（在这里是平行光）        fixed3 worldLight = normalize(_WorldSpaceLightPos0.xyz);        //漫反射计算（入射光线的信息和漫反射系数都来自内置变量）        fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, worldLight));        //输出之前把环境光也加上。        o.color = ambient + diffuse;        return o;    &#125;</code></pre><p>我们在计算点积时，务必将两个向量置于同一个坐标系下，否则就没有意义了。这里我们选择的是世界空间。</p><p>因为a2v得到的顶点法线是模型空间下的，因此我们使用一个矩阵将法线转换到了世界空间。</p><p>光照方向则是内置变量直接做了归一化。</p><p>由于所有的计算在顶点着色器中完成了，因此片元着色器直接输出顶点颜色即可。</p><pre><code>    fixed4 frag(v2f i) :SV_Target    &#123;        return fixed4(i.color,1.0);    &#125;</code></pre><p>最后记得将UnityShader的回调shader设为内置的diffuse</p><pre><code>        Fallback &quot;Diffuse&quot;</code></pre><p>至此，我们详细的解释了逐顶点的漫反射光照实现。</p><p>对于一些细分程度高的模型，逐顶点光照也能得到不错的结果。</p><p>细分程度较低的话就有可能出现锯齿</p><hr><h4 id="漫反射逐像素光照"><a href="#漫反射逐像素光照" class="headerlink" title="漫反射逐像素光照"></a>漫反射逐像素光照</h4><p>逐像素光照就是将计算部分从顶点着色器迁移到了片元着色器进行运算而已。</p><p>所使用的光照模型是一样的。代码和逐顶点光照较为相似。</p><p>修改顶点着色器的输出结构v2f（因为我们不在顶点着色器中计算光照模型了，因此只需要传递顶点就行）</p><pre><code>    struct v2f    &#123;        float4 pos : SV_POSITION;        float3 worldNormal : TEXCOORD0;    &#125;;</code></pre><p>顶点着色器只需要将世界空间下的法线传递给片元着色器即可</p><pre><code>    v2f vert(a2v v)    &#123;        v2f o;        //转化顶点坐标        o.pos = UnityObjectToClipPos(v.vertex);        //法线方向（世界坐标）        o.worldNormal = mul(v.normal, (float3x3)unity_WorldToObject);                return o;    &#125;</code></pre><p>在片元着色器中计算光照模型</p><pre><code>    fixed4 frag(v2f i) :SV_Target    &#123;        //环境光        fixed3 ambient = UNITY_LIGHTMODEL_AMBIENT.xyz;        //法线方向（世界坐标）        fixed3 worldNormal = normalize(i.worldNormal);        //光照方向（世界坐标）        fixed3 worldLight = normalize(_WorldSpaceLightPos0.xyz);        //漫反射计算（入射光线的信息和漫反射系数都来自内置变量）        fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * saturate(dot(worldNormal, worldLight));        //环境光 +漫反射        fixed3 color = ambient + diffuse;        return fixed4(color,1.0);    &#125;</code></pre><p>上述计算过程与逐顶点光照完全相同。</p><p>逐像素光照可以得到更加平滑的光照效果，代价是更大的开销。</p><p>我们会发现不管是逐顶点还是逐像素光照，在光线到达不了的区域，模型的外观是全黑的，丢失了模型的细节表现。</p><p>我们可以添加环境光来得到非全黑效果，但这是治标不治本，因为这样光面的明暗是一样的（不该这样对吧）</p><p>为此，<strong>半兰伯特光照模型（Half Lambert）</strong>被提出。</p><hr><h4 id="半兰伯特光照模型"><a href="#半兰伯特光照模型" class="headerlink" title="半兰伯特光照模型"></a>半兰伯特光照模型</h4><p>前文中我们使用的漫反射光照模型被称为兰伯特光照模型，因为他符合兰伯特定律。</p><p>即<strong>在某点漫反射的光强和该反射点的法向量和入射光的余弦成正比</strong>。</p><p>由于我们在原兰伯特光照模型上做了简单修改，因此该改进技术被称为<strong>半兰伯特光照模型</strong>。</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922113144933.png" alt="image-20210922113144933"></p><p>不难看出，半兰伯特没有使用max操作来防止点积为负值</p><p>而是进行了一个α倍的缩放再加上一个β大小的偏移</p><p>绝大多数情况下两个系数的值都为0.5。</p><p>即公式为：</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922113355925.png" alt="image-20210922113355925"></p><p>通过这样的方式就可以把点积结果从[-1,1]映射到[0,1]</p><p><strong>需要注意的是，半兰伯特模型没有任何物理依据，仅仅是一个视觉加强技术</strong>（好像有小伙伴说被面试官问到这个）</p><p>我们在片元着色器中使用半兰伯特公式来取代原本的漫反射光照模型（兰伯特光照模型）</p><pre><code>    fixed4 frag(v2f i) :SV_Target    &#123;    //环境光    ...        //法线方向（世界坐标）    ...    //光照方向（世界坐标）    ...    //漫反射计算    fixed halfLambert=dot(worldNormal,worldLight)*0.5+0.5;    fixed3 diffuse = _LightColor0.rgb * _Diffuse.rgb * halfLambert;    //环境光 +漫反射    fixed3 color = ambient + diffuse;    return fixed4(color,1.0);&#125;</code></pre><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922114444160.png" alt="image-20210922114444160"></p><p>从左到右依次为半兰伯特模型，逐顶点光照，逐像素光照</p><hr><h3 id="高光反射光照模型"><a href="#高光反射光照模型" class="headerlink" title="高光反射光照模型"></a>高光反射光照模型</h3><p>在上文中我们同样给出了高光反射的计算公式</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922114831845.png" alt="image-20210922114831845"></p><p>我们需要知道三个参数：<strong>c</strong>light（入射光的颜色和强度），<strong>m</strong>specular（材质的反射系数），v（视角方向）</p><p>还有一个参数r（反射方向）可以由表面法线n和光源方向l计算而得。</p><p>Cg提供了计算反射方向的函数reflect（i，n）来返回反射方向。</p><p>注意<strong>这里的i是光源方向l的取反，是由光源指向交点处的矢量</strong>。</p><hr><h4 id="高光反射逐顶点光照"><a href="#高光反射逐顶点光照" class="headerlink" title="高光反射逐顶点光照"></a>高光反射逐顶点光照</h4><p>我们这次在Properties语义中构造三个属性以便于更方便控制高光反射属性</p><p>渲染模式设为前向渲染，包含文件Lighting.cginc，设置与属性相匹配的变量</p><pre><code>    Properties    &#123;        _Diffuse(&quot;Diffuse&quot;, Color) = (1,1,1,1)        _Specular(&quot;Specular&quot;,Color)=(1,1,1,1)        _Gloss(&quot;Gloss&quot;,Range(8.0,256))=20    &#125;                    SubShader&#123;        Pass        &#123;            Tags &#123; &quot;LightMode&quot;=&quot;ForwardBase&quot; &#125;            CGPROGRAM                        #pragma vertex vert            #pragma fragment frag            #include &quot;Lighting.cginc&quot;            fixed4 _Diffuse;//颜色属性在0~1因此使用fixed的精度来储存            fixed4 _Specular;//颜色属性在0~1因此使用fixed的精度来储存            float _Gloss;//Gloss用来表示一个指数，范围较大，使用float来储存</code></pre><p>定义顶点着色器的输入和输出结构体（和漫反射是一样的）</p><pre><code>            struct a2v            &#123;                float4 vertex : POSITION;                float3 normal : NORMAL;                            &#125;;            struct v2f            &#123;                float4 pos : SV_POSITION;                fixed3 color: COLOR;            &#125;;</code></pre><p>在顶点着色器中包含高光反射的光照模型</p><p>这里是公式君：</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922095304007.png" alt="image-20210922095304007"></p><pre><code>            v2f vert (a2v v)//高光反射逐顶点光照            &#123;                v2f o;                //顶点变换                o.pos=UnityWorldToClipPos(v.vertex);                //获取环境光                fixed3 ambient=UNITY_LIGHTMODEL_AMBIENT.xyz;                //获取法线（世界坐标）                fixed3 worldNormal=normalize(mul(v.normal,(float3x3)unity_WorldToObject));                //获取入射光并归一化（在这里是平行光）                fixed3 worldLightDir=normalize(_WorldSpaceLightPos0.xyz);                //计算漫反射部分                fixed3 diffuse=_LightColor0.rgb*_Diffuse.rgb*saturate(dot(worldNormal,worldLightDir));                //计算反射光                fixed3 reflectDir = normalize(reflect(-worldLightDir, worldNormal));                //获取视线方向                fixed3 viewDir = normalize(_WorldSpaceCameraPos.xyz - mul(unity_ObjectToWorld, v.vertex).xyz);                //计算高光反射                fixed3 specular=_LightColor0.rgb*_Specular.rgb*pow(saturate(dot(reflectDir,viewDir)),_Gloss);                //把环境光和漫反射加上                o.color=ambient+diffuse+specular;                                return o;            &#125;</code></pre><p>漫反射部分的计算与前文完全一致。随后我们使用reflect函数计算反射光的方向。</p><p><strong>注意这里对worldLightDir取反后再传入reflect函数</strong>。</p><p>我们通过_WorldSpaceCameraPos（内置变量）获取世界空间中的摄像机位置， </p><p>随后将世界坐标的顶点（从模型空间变换而来）和 _WorldSpaceCameraPos相减获得我们的视线矢量。</p><p>至此我们所需的四个参数（<strong>c</strong>light（入射光的颜色和强度），<strong>m</strong>specular（材质的反射系数），v（视角方向）r（反射方向））已经全部获取</p><p>代入公式计算即可得到高光反射的光照部分。</p><p>片元着色器也同上直接返回顶点颜色，最后将回调shader设为内置的Specular</p><pre><code>            fixed4 frag (v2f i) : SV_Target            &#123;                return fixed4(i.color,1.0);            &#125;            ENDCG        &#125;    &#125;   Fallback &quot;Specular&quot; </code></pre><p>需要注意的是使用逐顶点计算得到的高光效果有比较大的问题</p><p>这是因为高光反射的计算是非线性的，而逐顶点计算的过程依赖线性插值进行。</p><hr><h4 id="高光反射逐像素光照"><a href="#高光反射逐像素光照" class="headerlink" title="高光反射逐像素光照"></a>高光反射逐像素光照</h4><p>修改结构体v2f</p><pre><code>            struct v2f            &#123;                float4 pos : SV_POSITION;                float3 worldNormal:TEXCOORD0;                float3 worldPos: TEXCOORD1;            &#125;;</code></pre><p>顶点着色器只需要计算世界空间下的法线方向和顶点坐标，并传递给片元着色器</p><pre><code>            v2f vert (a2v v)//高光反射逐顶点光照            &#123;                v2f o;                //顶点变换到剪裁空间                o.pos = UnityObjectToClipPos(v.vertex);                //获取法线（世界坐标）                o.worldNormal=mul(v.normal,(float3x3)unity_WorldToObject);                //获取顶点的世界坐标                o.worldPos=mul(unity_ObjectToWorld,v.vertex).xyz;                                return o;            &#125;</code></pre><p>随后在片元着色器计算关键的光照模型</p><pre><code>           fixed4 frag (v2f i) : SV_Target            &#123;                //获取环境光                fixed3 ambient=UNITY_LIGHTMODEL_AMBIENT.xyz;                //获取法线（世界坐标）                fixed3 worldNormal=normalize(i.worldNormal);                                //获取平行光（归一化）                fixed3 worldLightDir=normalize(_WorldSpaceLightPos0.xyz);                                //计算漫反射部分                fixed3 diffuse=_LightColor0.rgb*_Diffuse.rgb*saturate(dot(worldNormal,worldLightDir));                                //计算反射光                fixed3 reflectDir=normalize(reflect(-worldLightDir,worldNormal));                                //获取视线                fixed3 viewDir=normalize(_WorldSpaceCameraPos.xyz-i.worldPos.xyz);                //计算高光反射                fixed3 specular=_LightColor0.rgb*_Specular.rgb*pow(saturate(dot(reflectDir,viewDir)),_Gloss);                                return fixed4(ambient+diffuse+specular,1.0);            &#125;</code></pre><p>计算过程与逐顶点完全相同。</p><p>按照逐像素方式可以实现更平滑的高光效果，至此我们实现了一个完整的冯光照模型。</p><hr><h4 id="布林冯光照模型"><a href="#布林冯光照模型" class="headerlink" title="布林冯光照模型"></a>布林冯光照模型</h4><p>还记得布林冯公式吗？</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922102113790.png" alt="image-20210922102113790"></p><p>我们直接修改逐片元光照的片元着色器：</p><pre><code>            fixed4 frag (v2f i) : SV_Target            &#123;                ...                //计算半程向量h                fixed3 HalfDir=normalize(viewDir+worldLightDir);                //计算高光反射                fixed3 specular=_LightColor0.rgb*_Specular.rgb*pow(saturate(dot(worldNormal,HalfDir)),_Gloss);                                return fixed4(ambient+diffuse+specular,1.0);            &#125;</code></pre><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922123915513.png" alt="image-20210922123915513"></p><p>从左到右依次是布林冯模型，逐顶点光照，逐像素光照</p><p>可以看出布林冯的高光部分更大更亮，实际渲染中我们大部分会选择布林冯模型。</p><p>但要记住，冯模型和布林冯模型都是经验模型，都不存在“正确”的概念。</p><hr><h3 id="unity的内置函数"><a href="#unity的内置函数" class="headerlink" title="unity的内置函数"></a>unity的内置函数</h3><p>上述shader的编写中，我们都是手动计算得到各个矢量变量，既不方便也不一定准确</p><p>例如_WorldSpaceLightPos0.xyz只适用平行光，若不是平行光则会得到错误结果。</p><p>但起码我们弄明白了其中的原理。</p><p>unity提供了内置函数来帮助我们计算这一系列的信息。</p><p><img src="/images/loading.jpg" data-original="/2021/09/17/2021-09-17-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A3%EF%BC%88%E5%9F%BA%E7%A1%80shader%E7%BC%96%E5%86%99%EF%BC%8C%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B%EF%BC%89/image-20210922124733669.png" alt="image-20210922124733669"></p><p>使用他们可以使我们减少编写shader时的痛苦。</p><p>例如</p><pre><code>o.worldNormal=mul(v.normal,(float3x3)unity_WorldToObject);//手动计算得到世界坐标系下的法线o.worldNormal=UnityObjectToWorldNormal(v.normal);//使用内置函数</code></pre><p>需要注意的是，使用内置函数的结果是没有归一化的，因此请记得对结果进行normalize</p><hr><p>终于写完了，从9点开始写现在已经一点了5555，2021-9-22 12:52</p><p>不过古人所言温故而知新是真的没有错，产出内容以后，对这章的内容的理解更加深刻了。</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文为学习UnityShader时所记录的笔记，供学习产出和日后复习使用。&lt;/p&gt;
&lt;p&gt;学习资料为冯乐乐（问就是我女神）的《UnityShader入门精要》&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>UnityShader入门精要③（图形学数学基础）</title>
    <link href="https://aprilnavi.github.io/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/"/>
    <id>https://aprilnavi.github.io/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/</id>
    <published>2021-09-10T01:06:58.000Z</published>
    <updated>2021-09-10T04:53:21.832Z</updated>
    
    <content type="html"><![CDATA[<p>本文为学习UnityShader时所记录的笔记，供学习产出和日后复习使用。</p><p>学习资料为冯乐乐（问就是我女神）的《UnityShader入门精要》</p><span id="more"></span><p>这一张讲的是各类变换矩阵，以及如何将模型空间的物体一步步变换到屏幕空间实现光栅化</p><p>默认都有一定的线性代数基础，所以矩阵的乘法之类的基础知识直接略过</p><hr><h2 id="4-3-矢量"><a href="#4-3-矢量" class="headerlink" title="4.3 矢量"></a>4.3 矢量</h2><p>矢量本身不是很难的东西，这里直接以我的理解来记录矢量内容的重点。</p><p>矢量之间可以进行乘法，有<strong>点积</strong>（dot product）和<strong>叉积</strong>（cross product）两种种类。</p><hr><h3 id="矢量的点积（点乘）"><a href="#矢量的点积（点乘）" class="headerlink" title="矢量的点积（点乘）"></a>矢量的点积（点乘）</h3><p>在unityshader中，点积为dot(a,b)。</p><p><strong>点积的结果为一个值。点积满足交换律。</strong>点积公式懂的都懂。</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210418114037370.png" alt="image-20210418114037370"></p><p>重点是<strong>点积的几何意义</strong>（朋友面试被考到过被刷掉了hhh印象深刻）：</p><p><strong>求一个向量在另一个向量的投影</strong></p><p><strong>测量两个方向有多近</strong></p><p><strong>分解一个向量</strong></p><p><strong>确定两个向量是同向还是反向（方向相反点积小于0，方向垂直点积等于0，方向相同点积大于0）</strong></p><hr><h3 id="矢量的叉积（叉乘）"><a href="#矢量的叉积（叉乘）" class="headerlink" title="矢量的叉积（叉乘）"></a>矢量的叉积（叉乘）</h3><p><strong>叉积不满足交换律！叉积结果为垂直于原两个向量的所在平面的新向量。</strong></p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210418115836909.png" alt="image-20210418115836909"></p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210418120436013.png" alt="image-20210418120436013"></p><p>其中有个公式比较特别，即axb的长度等于a和b的模的乘积乘以他们之间夹角的正弦值。</p><p>叉积的几何意义：</p><p><strong>计算垂直于一个平面的矢量（法向量）。</strong></p><p><strong>用于定义左和右，定义里和外（abc三点连线取叉积，结果方向都相同则在三角形内）。</strong></p><hr><h2 id="4-4-矩阵"><a href="#4-4-矩阵" class="headerlink" title="4.4 矩阵"></a>4.4 矩阵</h2><p>逆矩阵转置矩阵的公式和性质记得好好复习。</p><p>正交矩阵的定义要好好理解。</p><hr><h2 id="4-5-各种变换"><a href="#4-5-各种变换" class="headerlink" title="4.5 各种变换"></a>4.5 各种变换</h2><h3 id="变换简述"><a href="#变换简述" class="headerlink" title="变换简述"></a>变换简述</h3><p><strong>缩放矩阵（scale）和旋转（rotation）矩阵</strong>皆为<strong>线性变换（linear transform）</strong>，都能直接用3x3的矩阵来表示。</p><p>平移变换不为线性变换，无法使用3x3的矩阵来直接表示。</p><p>为了将旋转缩放和平移在同一个矩阵内表示，引入**齐次坐标(homogeneous)**的概念，将矩阵变为4x4。</p><p>合并了旋转和平移的变换称为<strong>仿射变换（affine transform）。</strong></p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910095825353.png" alt="image-20210910095825353"></p><hr><h3 id="齐次坐标"><a href="#齐次坐标" class="headerlink" title="齐次坐标"></a>齐次坐标</h3><p>齐次坐标是将三维转换成四维的结果。</p><p>对于一个点来说，新增的<strong>w分量为1。</strong></p><p>对于一个矢量来说，新增的<strong>w分量为0。</strong></p><p>这样设置会导致使用4x4矩阵对一个点进行变换时，平移缩放旋转都会施加于该点。</p><p>而对一个向量进行变换时，平移的效果会被忽略（平移不会对方向矢量产生影响，即矢量没有位置属性）。</p><hr><h3 id="平移矩阵（translation）"><a href="#平移矩阵（translation）" class="headerlink" title="平移矩阵（translation）"></a><strong>平移矩阵</strong>（translation）</h3><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910100556224.png" alt="image-20210910100556224"></p><p>可以看出，<strong>平移矩阵并不是一个正交矩阵。</strong></p><p>平移矩阵的逆矩阵是将三个平移系数加上负号（相当于是反向平移）。</p><hr><h3 id="缩放矩阵（scale）"><a href="#缩放矩阵（scale）" class="headerlink" title="缩放矩阵（scale）"></a><strong>缩放矩阵</strong>（scale）</h3><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910100831575.png" alt="image-20210910100831575"></p><p>如果三个缩放系数k相等，则将这样的缩放称为<strong>统一缩放（uniform scale）。</strong></p><p>统一缩放不会改变角度和比例信息（例如非统一缩放操作法线会得到错误结果）。</p><p>缩放帧的逆矩阵是使用原缩放系数的倒数进行缩放（相当于反向的缩放）。</p><p>缩放<strong>一般不是正交矩阵</strong>。</p><hr><h3 id="旋转矩阵（rotation）"><a href="#旋转矩阵（rotation）" class="headerlink" title="旋转矩阵（rotation）"></a><strong>旋转矩阵（rotation）</strong></h3><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910101254512.png" alt="image-20210910101254512"></p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910101315687.png" alt="image-20210910101315687"></p><p>旋转矩阵的逆矩阵是旋转相反方向的矩阵。</p><p><strong>旋转矩阵是正交矩阵，多个旋转矩阵的串联同样是正交矩阵。</strong></p><hr><h3 id="复合矩阵："><a href="#复合矩阵：" class="headerlink" title="复合矩阵："></a><strong>复合矩阵：</strong></h3><p>可以将平移旋转缩放组合起来成为一个复杂的变换过程。</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910101830740.png" alt="image-20210910101830740"></p><p>我们使用的是列矩阵，阅读顺序是从右到左。</p><p>绝大多数情况下我们规定变换的顺序为<strong>先缩放，再旋转，最后平移。</strong></p><hr><h2 id="4-6-坐标空间"><a href="#4-6-坐标空间" class="headerlink" title="4.6 坐标空间"></a>4.6 坐标空间</h2><h3 id="坐标空间的变换"><a href="#坐标空间的变换" class="headerlink" title="坐标空间的变换"></a>坐标空间的变换</h3><p>现如今有两个坐标空间，父坐标空间P和子坐标空间C。</p><p>将子坐标空间C下表示的点或矢量Ac转换到父坐标空间P下的表示为Ap。</p><p>将父坐标空间P下表示的点或矢量Bp转换到子坐标空间C下的表示为Bc。</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910102454639.png" alt="image-20210910102454639"></p><p>我们只需要知道<strong>新坐标空间的原点和坐标轴在原坐标空间中的表示</strong>就可以求出变换矩阵。</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910103317871.png" alt="image-20210910103317871"></p><p>因为矢量没有位置，所以不需要表示平移：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910103247635.png" alt="image-20210910103247635"></p><hr><h3 id="模型空间（model-space）"><a href="#模型空间（model-space）" class="headerlink" title="模型空间（model space）"></a>模型空间（model space）</h3><p>模型空间与某个模型（对象）有关，也称对象空间。</p><p>在模型空间经常使用前（forward）后（back）左（left）右（right）上（up）下（down）的概念。</p><p><strong>模型空间为左手坐标系</strong>。</p><hr><h3 id="世界空间（world-space）"><a href="#世界空间（world-space）" class="headerlink" title="世界空间（world space）"></a>世界空间（world space）</h3><p>世界空间表示了我们所关心的最大的最外层次的空间，可以被用于表述绝对位置。</p><p><strong>世界空间同样是左手坐标系</strong>。</p><p>我们可以构造出<strong>模型变换</strong>（model transform）的矩阵，<strong>将顶点从模型空间变换到世界空间</strong>，这是顶点变换的第一步：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910111803948.png" alt="image-20210910111803948"></p><p>即先缩放，后旋转，最后平移。</p><hr><h3 id="观察空间（view-space）"><a href="#观察空间（view-space）" class="headerlink" title="观察空间（view space）"></a>观察空间（view space）</h3><p>观察空间可以被认为是特殊的模型空间，即摄像机对象的模型空间。</p><p>观察空间中使用的<strong>是右手坐标系</strong>，他的正前方指向-z轴的方向，用于表示深度（z分量越小深度越深）。</p><p>我们需要将摄像机看到的转换到屏幕上，也就是将观察空间转换到屏幕空间，中间的阶段被称为<strong>投影（projection）</strong>。</p><p>我们可以想象相当于是将摄像机平移到原点，坐标轴与世界空间的坐标轴重合，得到观察变换的矩阵。</p><p><strong>将顶点从世界空间变换到观察空间</strong>，这是顶点变换的第二步，被称为<strong>观察变换（view transform）</strong>：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910112649588.png" alt="image-20210910112649588"></p><p>但由于观察空间使用右手坐标系，因此我们还需要对z分量进行取反操作。</p><p>就好比这样：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910112821611.png" alt="image-20210910112821611"></p><p>这样就是最终的观察变换矩阵了。</p><hr><h3 id="剪裁空间（clip-space）"><a href="#剪裁空间（clip-space）" class="headerlink" title="剪裁空间（clip space）"></a>剪裁空间（clip space）</h3><p>剪裁空间又称齐次剪裁空间，目标是对这块渲染图元进行剔除和剪裁（位于剪裁空间内的部分会被保留，位于空间外的部分会被剔除）</p><p>这块空间由视锥体决定，也就是unity的摄像机中前面的锥形范围。</p><p>视锥体有两种类型，涉及到两种投影类型，即<strong>透视投影（perspective projection）和正交投影（orthographic projection）</strong>。</p><p>透视投影模拟了人眼看世界的方式，有近大远小的效果</p><p>正交投影则完全保留了物体的角度和距离。</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910114703231.png" alt="image-20210910114703231"></p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910114636278.png" alt="image-20210910114636278"></p><p>其中视锥体剪裁平面的<strong>近剪裁平面（near clip plane）和远剪裁平面（far clip plane）</strong>决定了摄像机可以看到的深度范围。</p><p>这阶段的变换用于将观察空间的顶点转换到剪裁空间，这是顶点变换的第三步，被称为<strong>投影变换（projection transform）</strong>：</p><p>投影变换并没有真正进行投影工作，而是在为投影做准备。经过投影变换的运算后，w分量将具有实际意义。</p><h4 id="透视投影"><a href="#透视投影" class="headerlink" title="透视投影"></a>透视投影</h4><p>unity中的fov（field of view）属性决定了视锥体竖直方向的张开角度。</p><p>而Clipping Plane中有Near和Far参数来让我们控制两个剪裁平面距离摄像机的远近。</p><p>因此两个剪裁平面的高度：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910115148320.png" alt="image-20210910115148320"></p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910115132901.png" alt="image-20210910115132901"></p><p>我们还需要横纵比信息，我们假设当前横纵比为Aspect。</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910115249403.png" alt="image-20210910115249403"></p><p>根据已知的以上参数，我们可以推导出透视投影的投影矩阵：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910115337976.png" alt="image-20210910115337976"></p><p>我们的投影矩阵是建立在unity上的，因此此时针对的观察空间是右手系的，使用列矩阵在矩阵右侧进行相乘。</p><p>变换后的z分量范围在[-w，w]之间。而在DirectX中变换后的z分量范围在[0，w]之间。</p><p>将一个顶点和透视投影的矩阵相乘的结果为：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910115614888.png" alt="image-20210910115614888"></p><p>我们相当于是对原先的xyz分量进行了不同程度的缩放，而原先的w分量不再是1，而是原先z分量的取反结果。</p><p>若一个顶点在视锥体之内，变换后的坐标必须满足：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910115758919.png" alt="image-20210910115758919"></p><p>不满足以上不等式的图元就会被剔除或剪裁。</p><hr><h4 id="正交投影"><a href="#正交投影" class="headerlink" title="正交投影"></a>正交投影</h4><p>正交投影的视锥体为长方形，计算更为简单。</p><p>Camera组件的size为视锥体竖直方向上的一半。</p><p>而Clipping Plane中有Near和Far参数来让我们控制两个剪裁平面距离摄像机的远近。</p><p>因此两个剪裁平面的高度：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910120159041.png" alt="image-20210910120159041"></p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910120225236.png" alt="image-20210910120225236"></p><p>横纵比信息：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910120318327.png" alt="image-20210910120318327"></p><p>因此正交投影矩阵如下：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910120347588.png" alt="image-20210910120347588"></p><p>一个顶点与正交投影矩阵相乘的结果为：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910120418717.png" alt="image-20210910120418717"></p><p>与透视投影不同，使用正交投影进行变换后，w分量依然为1</p><hr><h3 id="屏幕空间（screen-space）"><a href="#屏幕空间（screen-space）" class="headerlink" title="屏幕空间（screen space）"></a>屏幕空间（screen space）</h3><p>这一步所进行的是真正的投影，我们需要将视锥体投影到屏幕空间。</p><p>首先我们进行<strong>标准齐次除法（homogeneous division）</strong>，也称透视除法</p><p>即用齐次坐标系的w分量去除以xyz分量，在OpenGL中这一步会得到<strong>归一化的设备坐标（normalized device coordinate，NDC）</strong></p><p>经过透视投影变换后的剪裁空间会变换到一个立方体内，按照OpenGL的标准此时xyz分量范围为[-1,1]，而DirectX中z分量范围是[0,1]</p><p>而在正交投影变换后的剪裁空间本身就是一个立方体了，因此齐次除法过后顶点的w分量为1，xyz不产生影响。</p><p>unity采用的是OpenGL这样的齐次剪裁空间，在左下角像素坐标为(0,0)，右上角为(pixelWidth,pixelHeight)</p><p>齐次除法和屏幕映射的过程使用以下公式来总结：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910121417036.png" alt="image-20210910121417036"></p><p>此时得到的就是最终一个顶点在<strong>屏幕空间的位置（二维）</strong></p><p>上面的式子对xy分量做了处理，而z分量则会被用于<strong>深度缓冲。</strong></p><p>在unity中，裁剪空间到屏幕空间的转换由底层为我们实现，我们的顶点着色器只需要完成将顶点坐标转换到剪裁空间。</p><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以上过程描述了一个顶点如何从模型空间变换到屏幕空间中的二维坐标</p><p>总结一下就是这样：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910123431856.png" alt="image-20210910123431856"></p><p>顶点着色器的基本任务是<strong>把顶点坐标从模型空间转换到剪裁空间</strong>，对应了前三个过程（<strong>MVP变换</strong>）</p><p>片元着色器则能得到<strong>该片元在屏幕空间的像素位置。</strong></p><p> 变换过程中（unity），只有<strong>观察空间使用了右手坐标系</strong>。</p><hr><h3 id="4-7-法线变换"><a href="#4-7-法线变换" class="headerlink" title="4.7 法线变换"></a>4.7 法线变换</h3><p>顶点一般会携带额外的信息，其中就包括顶点法线，当我们变换模型时它的法线也得进行变换。</p><p>我们上文说过，如果使用变换矩阵直接变换法线，可能会引起错误的结果</p><p>进行一些巴拉巴拉的推导后，我们发现，使用<strong>原变换矩阵的逆转置矩阵</strong>来变换法线可以得到正确结果</p><p>如果变换矩阵为正交矩阵，即只包含旋转变换，也可以直接用变换矩阵来变换法线。</p><p>因为正交矩阵的逆矩阵和转置矩阵相同，逆转置矩阵则是原矩阵。</p><p>若变换矩阵只包含旋转和统一缩放，而不包含非统一缩放，则我们可以利用同一缩放系数k来得到变换矩阵</p><p>即：</p><p><img src="/images/loading.jpg" data-original="/2021/09/10/2021-09-10-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A2%EF%BC%88%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%EF%BC%89/image-20210910124627119.png" alt="image-20210910124627119"></p><hr><p>2021.9.10 12:46完成，写了大概三小时。</p><p>做完知识的产出之后感觉整个体系都清晰起来了，以后要坚持写。</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文为学习UnityShader时所记录的笔记，供学习产出和日后复习使用。&lt;/p&gt;
&lt;p&gt;学习资料为冯乐乐（问就是我女神）的《UnityShader入门精要》&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>UnityShader入门精要②（UnityShader基础）</title>
    <link href="https://aprilnavi.github.io/2021/08/28/2021-08-28-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A1%EF%BC%88UnityShader%E5%9F%BA%E7%A1%80%EF%BC%89/"/>
    <id>https://aprilnavi.github.io/2021/08/28/2021-08-28-UnityShader%E5%85%A5%E9%97%A8%E7%B2%BE%E8%A6%81%E2%91%A1%EF%BC%88UnityShader%E5%9F%BA%E7%A1%80%EF%BC%89/</id>
    <published>2021-08-27T19:06:58.000Z</published>
    <updated>2021-08-29T08:24:52.307Z</updated>
    
    <content type="html"><![CDATA[<p>本文为学习UnityShader时所记录的笔记，供学习产出和日后复习使用。</p><p>学习资料为冯乐乐（问就是我女神）的《UnityShader入门精要》</p><span id="more"></span><p>呜呜呜今天看书看这节的时候已经感觉人开始略微劝退了，不过还是充满激情的！</p><hr><h2 id="3-1-UnityShader概述"><a href="#3-1-UnityShader概述" class="headerlink" title="3.1 UnityShader概述"></a>3.1 UnityShader概述</h2><p>在unity中，Shader需要和材质配合使用。</p><p>unity中提供了四种Shader模板：</p><p>Standard Surface Shader：包含了标准光照模型的表面着色器模板</p><p>Unlit Shader：不包含标准光照的基本顶点/片元着色器（教程中大部分使用）</p><p>Image Effect Shader：实现各种屏幕后处理效果</p><p>Compute Shader：产生特殊Shader文件来利用GPU并行性进行与渲染无关的计算（一般用不到）</p><hr><h2 id="3-2-UnityShaderLab"><a href="#3-2-UnityShaderLab" class="headerlink" title="3.2 UnityShaderLab"></a>3.2 UnityShaderLab</h2><p>UnityShaderLab是专门用来为UnityShader服务的语言，是高级层的渲染抽象层。</p><p>一个UnityShader基础结构如下：</p><pre><code>Shader &quot;ShaderName&quot;&#123;Properties&#123;//属性&#125;SubShader&#123;//子着色器A&#125;SubShader&#123;//子着色器B&#125;Fallback “VertexLit”&#125;</code></pre><p>unity会根据目标平台将以上的UnityShaderLab代码编译成真正的代码和Shader文件。</p><hr><h2 id="3-3-UnityShader的结构"><a href="#3-3-UnityShader的结构" class="headerlink" title="3.3 UnityShader的结构"></a>3.3 UnityShader的结构</h2><h3 id="起个名字"><a href="#起个名字" class="headerlink" title="起个名字"></a>起个名字</h3><p>每个Unity Shader 第一行都需要通过Shader语义来指定该Unity Shader的名字。</p><pre><code>Shader &quot;MyShader&quot;</code></pre><p>或者是这样</p><pre><code>Shader &quot;Custom/MyShader&quot;</code></pre><p>在字符串中添加斜杠可以控制Shader在材质面板出现的位置</p><hr><h3 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h3><p>Propertie是材质和UnityShader的桥梁，他包含了一系列属性，这些语义会出现在材质面板中。</p><p>Properties语义块定义一般如下：</p><pre><code>Properties&#123;Name (&quot;display name&quot;,PropertyType)=DefaultValue&#125;</code></pre><p>声明这些属性是为了在材质面板中能方便的调整。</p><p>若需要在Shader中访问这些属性，则需要使用每个属性的<strong>名字（Name</strong>）一般由下划线开始。</p><p><strong>显示的名称（display name）</strong>是出现在材质面板上面的名字。</p><p>我们还需要为每个属性指定他的<strong>类型（PropertyType）</strong>并指定一个默认值</p><p>下列代码展示了所有的属性：</p><pre><code>Shader &quot;Custom/MyShad类型er&quot;&#123;    Properties    &#123;        //number and slider        _MainTex(&quot;Texture&quot;, 2D) = &quot;white&quot; &#123;&#125;        _Int(&quot;Int&quot;,Int) = 2        _Float(&quot;Float&quot;,Float) = 1.5        _Range(&quot;Range&quot;,Range(0.0,5.0)) = 3.0            //color and vector            _Color(&quot;Color&quot;,Color) = (1,1,1,1)            _Vector(&quot;Vector&quot;,Vector) = (2,3,6,1)            //texture            _2D(&quot;2D&quot;,2D) = &quot;&quot;&#123; &#125;            _3D(&quot;3D&quot;,3D) = &quot;Black&quot;&#123; &#125;            _Cube(&quot;Cube&quot;,Cube) = &quot;White&quot;&#123;&#125;    &#125;        FallBack &quot;Diffuse&quot; </code></pre><p>对于<strong>Int Float Range</strong>这些数字类型的属性，其默认值是一个单独的数字。</p><p>对于<strong>Color和Vector</strong>这类属性，默认值是圆括号包围的四维向量。</p><p>对于<strong>2D,Cube,3D</strong>这类属性，默认值是一个字符串跟着一个花括号。</p><p>字符串要么是空的要么是内置的纹理名称（white,black，yellow）</p><hr><h3 id="SubShader"><a href="#SubShader" class="headerlink" title="SubShader"></a>SubShader</h3><p>每一个Unity Shader文件可以包含多个SubShader语义块，但最少得有一个。</p><p>Unity会扫描所有语义块，选择第一个能在目标平台运行的语义块。若都不支持则会使用Fallback语义指定的Unity Shader。</p><p>原因是这样可以供不同性能的显卡使用不同复杂程度的语义块。</p><p>SubShader语义块包含的定义通常如下：</p><pre><code>SubShader&#123;//可选的标签设置[Tags]//可选的状态设置[RenderSetup]Pass&#123;&#125;//其他pass&#125;</code></pre><p>SubShader中提供了一系列Pass和<strong>可选的状态设置（tag）和标签设置（RenderSetup）。</strong></p><p><strong>每个Pass定义了一套完整的渲染流程</strong>，但如果Pass过多就好造成渲染性能的下降。应尽量使用尽可能少数目的Pass。</p><p>Tags和RenderSetup可在SubShader中定义，若在SubShader中定义则会用于所有Pass；也可以在Pass中单独定义。</p><p>其中Tags有些特定设置，在SubShader和Pass是不一样的。而RenderSetup的语法则完全相同。</p><hr><p><strong>状态设置（RenderSetup）：</strong></p><p>ShaderLab提供了一系列渲染状态的设置指令，用于设置显卡的各种状态。</p><p>例如：</p><p>Cull Back | Front |Off （剔除背面/正面/关闭）</p><p>ZTest 巴拉巴拉（设置深度测试使用的函数）</p><p>ZWrite On | Off（开启关闭深度写入）</p><p>Blend 巴拉巴拉（开启并设置混合模式）</p><p><strong>在SubShader中设置以上渲染状态时，将会应用到所有的Pass。</strong></p><p>若不想这样也可以在Pass中单独进行以上设置。</p><hr><p><strong>标签设置（Tags）：</strong></p><p>Tags是一个键值对，值和键都是字符串类型</p><pre><code>Tags&#123;&quot;TagName1&quot;=&quot;Value1&quot; &quot;TagName2&quot;=&quot;Value2&quot;&#125;</code></pre><p>标签有以下（具体的键对应的值上网查吧太懒了555）：</p><p>Queue（控制渲染顺序，指定该物体属于哪一个渲染队列）</p><p>RenderType（对着色器进行分类）</p><p>DisableBatching（是否禁用批处理）</p><p>ForceNoShadowCasting（控制该物体是否会投射阴影）</p><p>IgnoreProjector（是否受Projector影响，通常用于半透明物体）</p><p>CanUseSpriteAtlas（当SubShader用于精灵时将这个设为false）</p><p>PreviewType（指明材质面板该如何预览该材质，Plane，SkyBox）</p><p><strong>上面的标签只能在SubShader中声明，而不能在Pass内。</strong></p><p>Pass中声明的标签不同于SubShader的标签类型。</p><hr><p><strong>Pass语义块：</strong></p><p>Pass语义块定义如下</p><pre><code>Pass&#123;[Name][Tags][RenderType]//Other Type</code></pre><p>首先可以定义名字</p><p>例如<code>Name &quot;MyPassName&quot;</code>这样</p><p>通过这个名字，可以使用UsePass命令来直接使用其他Unity Shader的Pass。</p><p>例如：</p><pre><code>UsePass &quot;MyShader/MYPASSNAME&quot;</code></pre><p>这样能提高代码的复用性，注意Unity内部会把所有Pass的名字转换为大写，因此使用UsePass命令时必须使用大写的名字。</p><p>Pass可以单独设置状态，这个在上面提到过了，用的是和在SubShader里面一样的状态类型。</p><p>但Pass内的标签就不同与SubShader的标签了，Pass内使用的是：</p><p>LightMode(定义该Pass在渲染流水线的角色)</p><p>RequireOptions（用于指定满足某些条件时才渲染该pass）</p><hr><h3 id="Fallback"><a href="#Fallback" class="headerlink" title="Fallback"></a>Fallback</h3><p>Fallback是我们的后路，紧跟在SubShader语义块之后。</p><p>意味着所有的SubShader都不能在这张显卡上运行的情况下，使用Fallback指定的最低级的Shader。</p><pre><code>Fallback &quot;Name&quot;//或者Fallback Off</code></pre><p>Fallback还会影响阴影的投射，所以正确的设置Fallback是很重要的。</p><hr><h2 id="3-4-UnityShader的形式"><a href="#3-4-UnityShader的形式" class="headerlink" title="3.4 UnityShader的形式"></a>3.4 UnityShader的形式</h2><p>我们可以用表面着色器（Surface Shader），顶点/片元着色器（Vertex/Fragment Shader），固定函数着色器（Fixed Function Shader）的形式来编写UnityShader。</p><p>其中固定函数着色器很少使用，所以略掉。</p><h3 id="表面着色器（Surface-Shader）"><a href="#表面着色器（Surface-Shader）" class="headerlink" title="表面着色器（Surface Shader）"></a>表面着色器（Surface Shader）</h3><p>表面着色器是Unity自己创造的一种着色器代码类型，渲染的代价比较大。</p><p>本质上和顶点/片元着色器相同，实际上unity也在背后转换成顶点/片元着色器。</p><p>可以理解为<strong>表面着色器是顶点/片元着色器更高一层的抽象，并为我们处理了很多光照细节。</strong></p><pre><code>SubShader&#123;Tags&#123;&quot;RenderType&quot;=&quot;Opaque&quot;&#125;CGPROGRAM#pragma surface surf Lambertstruct Input&#123; float 4 color : COLOR;&#125;;void surf (Input IN,inout SurfaceOutput o)&#123;o.Albedo=1;&#125;ENDCG&#125;</code></pre><p>表面着色器被定义在SubShader语义块（非pass内），不需要关心使用了多少个Pass，Unity会在背后为我们处理好一切。</p><p>CGPROGRAM和ENDCG之间的代码使用Cg/HLSL编写，相当于将Cg/HLSL嵌套在ShaderLab中，语法和标准Cg/HLSL几乎一致。</p><hr><h3 id="顶点-片元着色器（Vertex-Fragment-Shader）"><a href="#顶点-片元着色器（Vertex-Fragment-Shader）" class="headerlink" title="顶点/片元着色器（Vertex/Fragment Shader）"></a>顶点/片元着色器（Vertex/Fragment Shader）</h3><p>以下代码来源于Unity新建的Unlit Shader模板。</p><p>现在可以不用看懂，只关注语义框架。</p><pre><code> SubShader            &#123;                Pass                &#123;                    CGPROGRAM                    #pragma vertex vert                    #pragma fragment frag                    #pragma multi_compile_fog                    #include &quot;UnityCG.cginc&quot;                    struct appdata                    &#123;                        float4 vertex : POSITION;                        float2 uv : TEXCOORD0;                    &#125;;                    struct v2f                    &#123;                        float2 uv : TEXCOORD0;                        UNITY_FOG_COORDS(1)                        float4 vertex : SV_POSITION;                    &#125;;                    sampler2D _MainTex;                    float4 _MainTex_ST;                    v2f vert(appdata v)                    &#123;                        v2f o;                        o.vertex = UnityObjectToClipPos(v.vertex);                        o.uv = TRANSFORM_TEX(v.uv, _MainTex);                        UNITY_TRANSFER_FOG(o,o.vertex);                        return o;                    &#125;                    fixed4 frag(v2f i) : SV_Target                    &#123;                        // sample the texture                        fixed4 col = tex2D(_MainTex, i.uv);                    // apply fog                    UNITY_APPLY_FOG(i.fogCoord, col);                    return col;                &#125;                ENDCG            &#125;            &#125;</code></pre><p><strong>顶点/片元着色器代码也需要定义在CGPROGRAM和ENDCG之间</strong></p><p><strong>但顶点/片元着色器需要写在Pass内，而非SubShader内</strong></p><p>因为与表面着色器不同，此处我们需要自己单独定义每个pass的Shader代码。</p><p>虽然这样需要编写更多代码，但灵活性也更高，我们可以由此控制渲染细节。</p><p>这里CGPROGRAM和ENDCG之间的代码也使用Cg/HLSL编写。</p><hr><h3 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h3><ul><li>除非在非常旧的设备（iPhone3）上运行，否则一般使用可编程管线的着色器而不是固定管线着色器。</li><li>若希望和各类光源打交道，不妨试试表面着色器（小心移动平台的性能表现）</li><li>若所需光源数目少（例如只有一个平行光），则使用顶点/片元着色器是更好的选择。</li><li>若需要很多自定义的渲染效果，则也请使用顶点/片元着色器。</li></ul><hr><hr><p>昨天中间跑去约会又去酒吧爽喝，又睡了个大觉，拖下来十几个小时才完成这些，不过这两天还是蛮开心的！2021.8.29 16:24</p><hr><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文为学习UnityShader时所记录的笔记，供学习产出和日后复习使用。&lt;/p&gt;
&lt;p&gt;学习资料为冯乐乐（问就是我女神）的《UnityShader入门精要》&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
</feed>
