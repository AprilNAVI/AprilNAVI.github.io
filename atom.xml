<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>AprilNAVI&#39;s Blog | You are the best</title>
  
  
  <link href="https://aprilnavi.github.io/atom.xml" rel="self"/>
  
  <link href="https://aprilnavi.github.io/"/>
  <updated>2023-12-08T15:34:43.781Z</updated>
  <id>https://aprilnavi.github.io/</id>
  
  <author>
    <name>AprilNAVI</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>UMG渲染分析，规范制定，工具制作</title>
    <link href="https://aprilnavi.github.io/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/"/>
    <id>https://aprilnavi.github.io/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/</id>
    <published>2023-12-08T15:31:47.000Z</published>
    <updated>2023-12-08T15:34:43.781Z</updated>
    
    <content type="html"><![CDATA[<p>历经三天经历了对Slate流程的分析，规范指定，和简易工具落地</p><span id="more"></span><h1 id="UMG渲染分析，规范制定，工具制作"><a href="#UMG渲染分析，规范制定，工具制作" class="headerlink" title="UMG渲染分析，规范制定，工具制作"></a>UMG渲染分析，规范制定，工具制作</h1><h2 id="渲染原理和流程"><a href="#渲染原理和流程" class="headerlink" title="渲染原理和流程"></a>渲染原理和流程</h2><h3 id="Slate模块："><a href="#Slate模块：" class="headerlink" title="Slate模块："></a>Slate模块：</h3><p>Slate模块包括Slate，SlateCore，SlateRHIRenderer，UMG。</p><p>Slate和SlateCore共同构筑了逻辑层部分，SlateRHIRenderer则是渲染部分。</p><p>UMG是在Slate和SlateCore上面的封装层，由编辑器客户端主要使用。</p><h3 id="UMG资产："><a href="#UMG资产：" class="headerlink" title="UMG资产："></a><strong>UMG资产：</strong></h3><p>UWidget是UMG模块中许多控件的基类，包括UserWidget</p><p>UWidget持有SWidget，继承UObject,有UObject的GC系统，支持反射和蓝图功能</p><p>SWidget处于SlateCore模块中，控件的绘制、点击以及大部分控件逻辑都集中在这里面</p><p>每个UserWidget在计算时都会储存为WidgetTree规定的树状结构</p><h3 id="绘制基本流程："><a href="#绘制基本流程：" class="headerlink" title="绘制基本流程："></a><strong>绘制基本流程：</strong></h3><p><strong>在游戏线程 （Game Thread），Slate Tick 每一帧会遍历两次 Widget Tree，主要负责渲染数据的收集</strong></p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231208224722445.png"></p><hr><p><strong>DrawPrepass，计算Layout：</strong></p><p>自底向上的先计算最叶子节点UI的DesiredSize，然后之上的每一层UI根据子UI的DesiredSize计算自己的DesiredSize</p><p>这个过程发生在FSlateApplication::DrawPrepass，默认情况下会递归遍历所有的子节点。</p><p><strong>DrawWindows，调用子控件的OnPaint，收集渲染元素：</strong></p><p>自顶向下的过程，对于UI的叶子节点来说，这一步会输出可见图元</p><p>对于有子节点的UI（比如各种Panel），它一般会先根据子UI的期望大小和自身的逻辑，控制子UI的位置</p><p>在前面的DrawWindows阶段之前，会初始化一个DrawBuffer，其中存了绘制所需的ElementList。</p><p>开启正式绘制之前，会把UI的图元全部压入这个ElementList才行，因此执行了DrawWindowAndChildren</p><p>内部是给子UI分配特定的显示区域，再递归调用子控件的OnPaint方法，给每个控件分配LayerId，并从控件抽象出FSlateDrawElement。</p><p>子UI的OnPaint方法会将具体的图元类型添加到这个List里</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231206161552115.png"></p><p><strong>Renderer-&gt;DrawWindows，生成批数据，创建渲染命令</strong>：</p><p>前面一步完成之后，就可以开始正式渲染，但从调用Renderer-&gt;DrawWindows之后的过程，包括合批也发生在GameThread上</p><p>ElementList已经被填充好了这一次渲染需要提交的元素，这个列表会被送往ElementBatcher生成批数据。</p><p>渲染器把FSlateDrawElement包装成FSlateRenderBatch批数据，并根据控件的信息生成VertexBuffer，执行渲染命令</p><p>调用DrawWindow_RenderThread送往下游的渲染线程去做。</p><hr><p><strong>对于渲染线程（Render Thread）而言，Slate的渲染主要经历DrawWindow_RenderThread的过程。</strong></p><p>Renderer-&gt;DrawWindows是每次渲染的入口，这里的Renderer会根据平台选择对应的渲染器</p><p>在对WindowElementList做完合批，内部生成好渲染命令之后，调用DrawWindow_RenderThread把数据送往渲染层</p><p>渲染线程主要做的是：</p><ol><li>合批更新定点数据和顶点索引数据到GPU缓冲区</li><li>渲染操作类执行绘制:生成FRHICommand</li><li>生成任务等待RHIThread执行完上一帧的FRHICommand</li></ol><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231208224635579.png"></p><h2 id="UMG渲染的性能热点分析，制作规范"><a href="#UMG渲染的性能热点分析，制作规范" class="headerlink" title="UMG渲染的性能热点分析，制作规范"></a>UMG渲染的性能热点分析，制作规范</h2><p>使用的引擎版本是UE 5.2，主要通过Unreal Insight分析Slate渲染流程，使用Stat 相关命令行查看runtime耗时数据：</p><p>主要关注Render Thread中SlateUI的渲染耗时，包括Draw Call，OverDraw现象，如果Game Thread中有造成瓶颈的部分也会关注</p><p>主线程的耗时主要为Slate::DrawWindow，其中包括了Prepass，DrawWindow，AddElement的过程。</p><p>这个过程较为耗时，平均耗时4ms左右，在一些坏帧可以到5ms，占用Game Thread一次逻辑帧的10%~15%左右，是一次绘制的主要瓶颈</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231207111343653.png"></p><p>渲染线程虽然有时会出现用时大于逻辑帧的情况，但有大部分时间都是在Wait Game Thread Task，瓶颈的可能性较小</p><p>而对于一次渲染线程的DrawWindow而言，平均耗时不到1ms，做一次Slate绘制只占了Render Thread一次渲染帧的2~3%</p><p>Slate作为绘制瓶颈的可能性较小，且Unreal本身对于Slate已经做了合批，剔除的操作。</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231206165248564.png"></p><p>RHI Thread基本上在等待Render Thread分配任务，几乎没有这方面的瓶颈。</p><hr><p>Stat Slate相关性能参数，主要关注：</p><p>Total Slate Tick Time：GameThread FSlateApplication::Tick总时间</p><p><strong>SlatePrepass：</strong> DrawPrepass自底向上计算Size时间 SWidget::SlatePrepass</p><p><strong>Draw Window And Children Time：</strong>自顶向下tickwidget paintUI的总时间</p><p><strong>Num Layers :</strong> 总的批次层级</p><p><strong>Num Batches：</strong> 总的批次</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231207110336020.png"></p><hr><p>因此对UMG做Runtime时期的优化，主要聚焦于Game Thread上的CPU瓶颈优化，能减轻一次Slate绘制的总体压力。</p><p>这方面应该从Widget Tree本身的遍历耗时，重建操作去分析，优化Widget Tree的耗时。</p><p>对于渲染而言，UE自己本身对Slate进行了合批处理，但Runtime时GPU如果进行Bind的操作，就会打断合批，显著提高DrawCall的次数</p><p>从Batch，DrawCall角度入手，考虑静止不动的静态资产是否会打断引擎合批。</p><p>对于UMG资产中的资源（texture）方面的使用，也应该加以规范限制。</p><p>由于UI的开销是线性增长的，哪怕制定了每个UI制作时的规范，如果同屏UI的数量同时出现过多，也可能导致性能异常</p><p>这一点不便于做离线的规范和扫描，但也需要在开发时好好注意维护UI的生命周期。</p><p>以下小标题是制作中需要遵守的具体规范，底下是对规范进一步的具体分析，讲清为什么这么做能达到优化目的</p><hr><h3 id="Game-Thread"><a href="#Game-Thread" class="headerlink" title="Game Thread"></a>Game Thread</h3><p>对于Game Thread而言，<strong>静态UI可以着重去降低Prepass，OnPaint这样的Tick耗时</strong>，手段可以通过缓存Element数据，</p><p>WidgetTree是Slate模块用来管理UI资产，统计图元绘制信息的容器结构。对Widget的重建操作，会导致额外的CPU消耗。</p><p>对于动态变化的UI，<strong>应该入手Widget Tree相关的开销</strong>，分为降低Widget Tree重构耗时和避免Widget Tree重构两个方向来分析。</p><hr><h4 id="对于静态UI，通过使用InviladitionBox来开启FathPath，加速整棵Widget-Tree的PrePass和OnPaint："><a href="#对于静态UI，通过使用InviladitionBox来开启FathPath，加速整棵Widget-Tree的PrePass和OnPaint：" class="headerlink" title="对于静态UI，通过使用InviladitionBox来开启FathPath，加速整棵Widget Tree的PrePass和OnPaint："></a>对于静态UI，通过使用InviladitionBox来开启FathPath，加速整棵Widget Tree的PrePass和OnPaint：</h4><p><strong>结论：最好的使用方式是根据Widget更新变化的频率，将Widget拆分到不同的 Invalidation Box 中</strong>。</p><p><strong>对于布局需要，不太方便划分Invalidation Box的Widget的，可以将Widget设为Is Volatile易变的，</strong></p><p><strong>这样上层在缓存时就会跳过这个Widget，这个Widget可能每次都会在Prepass 和 OnPaint被重新计算，但不会影响整棵Widget Tree的缓存</strong></p><p><strong>由于两个InvalidationBox中的内容不能合批，所以具体怎么使用需要测试和权衡</strong></p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231207180839577.png"></p><p>目前分析来看，没有添加InviladitonBox的UI走的都是SlowPath，这意味着每次Tick都是从头到尾将所有的节点都遍历了一遍</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231207151636073.png"></p><p>使用InviladitonBox将子控件收录之后，UE就可以通过FastPath索引到变化的UI，当ui需要被更新的时候，才会重新计算UI大小。</p><p><strong>所有 Prepass 和 OnPaint 计算结果，也就是DrawElements都会被缓存下来</strong></p><p>如果某个 Child Widget 的渲染信息发生变化，就会通知 Invalidation Box 重新计算一次 Prepass 和 OnPaint 更新缓存信息。</p><p>由于计算DesiredSize是其中比较耗时的操作，可以尝试更进一步采用更加激进的做法重写一些Widget的ComputeDesiredSize函数</p><p>在成功开启了FastPath之后，在UI被更新但大小不改变的情况下，做一个强制缓存的机制跳过Widget的重新计算大小，继续使用缓存</p><p>但使用时也需要注意，InviladitonBox渲染信息更新时，都会重新缓存Vertex Buffer，频繁的缓存Widget Tree也会造成很大的开销。</p><p>备注：</p><ol><li>InviladitonBox的<strong>Cache Relative Transform功能</strong>可以达到缓存相对坐标，从而在更新位置不更新大小时继续使用缓存，</li></ol><p>但这个功能在我使用的UE 5.2已经被移除了，类似机制需要自己手动实现</p><ol start="2"><li>命令<strong>Global Invalidation</strong>能够直接启用整个Swindow的Inviladiton功能，将整个UI封在一个InviladitonBox中，</li></ol><p>但会遇到上述所说的有Widget改变就会重复更新缓存，导致开销更大的问题，不建议使用。</p><ol start="3"><li><p>对于控件中引用的，<strong>使用动画编辑器制作的Sequencer动画效果</strong>，在动画播放时引起渲染更新也会导致Layout失效，进而导致重新计算。</p><p>为了避免这种情况，也应该将类似的Widget设为Is Volatile。对于循环动画，应考虑使用材质来实现，因为纯材质动画本身不产生CPU开销。</p></li></ol><hr><h4 id="开发时尽可能避免Widget-Tree的层数（layer）太多，对层级进行合并，Layer尽可能扁平化"><a href="#开发时尽可能避免Widget-Tree的层数（layer）太多，对层级进行合并，Layer尽可能扁平化" class="headerlink" title="开发时尽可能避免Widget Tree的层数（layer）太多，对层级进行合并，Layer尽可能扁平化"></a><strong>开发时尽可能避免Widget Tree的层数（layer）太多，对层级进行合并，Layer尽可能扁平化</strong></h4><p>因为使用Widget Tree时来管理子控件时，Widget Tree的Layer数量直接影响到整颗Widget Tree的计算复杂度。</p><p>由于PrePass和DrawWindow阶段都需要遍历整棵树，因此整棵树的Layer增加时，SlateTick的耗时因此增加。</p><p>制作时应该尽可能保证Widget Layer扁平，可以将相邻的Layer重新合并成到同一个Layer。</p><p>这样能限制整颗树Runtime时期的递归总体深度，来减少Widget Tree每次Rebuild和遍历所需要的耗时。</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231207180737131.png"></p><hr><h4 id="对于动态UI做生命周期维护，避免Runtime做会导致重构Widget-Tree的操作（插入和删除）："><a href="#对于动态UI做生命周期维护，避免Runtime做会导致重构Widget-Tree的操作（插入和删除）：" class="headerlink" title="对于动态UI做生命周期维护，避免Runtime做会导致重构Widget Tree的操作（插入和删除）："></a>对于动态UI做生命周期维护，避免Runtime做会导致重构Widget Tree的操作（插入和删除）：</h4><p>可以<strong>参考UE Common UI插件中的UCommonActivatableWidget的优化思路</strong>，</p><p>Common UI单独了实现一套机制，<strong>让UI控制自身在生命周期内被激活和停用而非删除创建</strong>，能避免Runtime时期Widget Tree被重建。</p><p>我们自己也可以通过类似对象池这样的结构来维护UI的生命周期，<strong>避免在Runtime时期对控件进行删除和动态创建并插入操作</strong>，从而重建Widget Tree。</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231207180520837.png"></p><hr><h4 id="提高UMG逻辑性能本身（驱动方式），做更新频率划分："><a href="#提高UMG逻辑性能本身（驱动方式），做更新频率划分：" class="headerlink" title="提高UMG逻辑性能本身（驱动方式），做更新频率划分："></a><strong>提高UMG逻辑性能本身（驱动方式），做更新频率划分：</strong></h4><p>控件尽量使用事件驱动UI更新，本身尽可能少绑定（将属性绑定到UI字段上会触发轮询）或者避免使用Tick，避免不必要的开销</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231207193954054.png"></p><p>逻辑部分迁移到C++或者脚本中，避免使用蓝图，以获取更高的性能。</p><p><strong>根据Widget的使用和更新频率，将Widget拆分为：始终可见的，必须尽快显示的，可以承受在显示时略有延迟的</strong></p><p><strong>对于不同更新频率的Widget，放入不同的InviladitonBox，且采用不同的加载策略，</strong></p><p>需要快速响应，使用频繁的的UI，例如竞技游戏中的物品栏和技能栏，最好将其保持在后台加载但不可见的状态。</p><p>长时间不出现也没有快速响应需求的Widget，可以尝试使用异步加载策略，消除时评估对Widget Tree的影响选择销毁或者停用。</p><p>这样一来可以避免一次性加载所有资源，加快启动时间，同时降低初始的内存占用。</p><hr><h3 id="Render-Thread"><a href="#Render-Thread" class="headerlink" title="Render Thread"></a>Render Thread</h3><p>对于Render Thread而言，减少Batch Draw Call的次数，不一定可以显著提高帧率，但可以减少对GPU的API调用，在移动端上有助于控制发热。</p><p>这部分主要聚焦于规范那些会打断合批的操作，同时也会列举一些制作规范来提高渲染的效率。</p><hr><h4 id="检查可能打断合批的操作或者配置："><a href="#检查可能打断合批的操作或者配置：" class="headerlink" title="检查可能打断合批的操作或者配置："></a>检查可能打断合批的操作或者配置：</h4><p><strong>控制降低整体最终的Layer ID在一个理想的数目，设置合理的配置参数，是提高合批效率降低Draw Call的有效手段</strong></p><p><strong>手动是否检查合批较为繁琐，应进一步开发自动化工具，检查资产的合批情况。</strong></p><p>绘制是从SWindow::Paint开始，LayerId初始为0，在绘制中开始传递和更新；</p><p>大部分控件使用参数中的LayerId，少部分控件改变LayerId，并作为返回值传递给父节点</p><ol><li><strong>引擎生成的LayerID如果不同则不能合批</strong></li><li><strong>ShaderResource，使用Texture、图集不同的Image控件不能合批</strong></li><li><strong>Tiling，设置Tiling的不能和普通控件合批</strong></li><li><strong>ShaderType，DrawAs选了Border和文本控件，不能和普通控件合批</strong></li><li><strong>DrawEffects，自己和父控件不能去掉IsEnable</strong></li><li><strong>ClippingState， 设置了裁剪的不能参与合批</strong></li></ol><p>常用的Widget操作对LayerID的影响如下：</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231207202114081.png"></p><hr><h4 id="使用Retainer-Box提高渲染效率，加速OnPaint过程，动静分离降低OverDraw："><a href="#使用Retainer-Box提高渲染效率，加速OnPaint过程，动静分离降低OverDraw：" class="headerlink" title="使用Retainer Box提高渲染效率，加速OnPaint过程，动静分离降低OverDraw："></a><strong>使用Retainer Box提高渲染效率，加速OnPaint过程，动静分离降低OverDraw：</strong></h4><p><strong>结论：对于静态的UI，可以使用RetainerBox，在参数中设置每几帧会触发一次重新绘制，控制每个像素的整体绘制频率。</strong></p><p><strong>Retainer Box的使用区域应该尽量小，有助于提高渲染效率、降低显存使用。重复使用的 User Widget 不要使用 Retainer Box</strong></p><p><strong>使用Retainer Box优化渲染需要创建Render Target占用内存，具体怎么使用需要测试和权衡</strong></p><p><strong>Invalidation Box 放置在 Retainer Box 上方没有意义，通常做法是在 Retainer Box 下层放一个 Invalidation Box。</strong></p><p><strong>可以拓展URetainerBox 和 SRetainerWidget，将Retainer Box改为事件驱动而非Tick，进一步优化。</strong></p><p>通过合并批次和合并贴图的方式，UI 的 Draw Call 数量可以减少到比较低，但仍然会有很高的像素填充率。</p><p>在很多情况下，静态UI 不需要每帧都重新渲染，因此可以通过 Retainer Box 缓存渲染结果，设置每隔几帧更新一次，</p><p>PhaseCount表示多少帧绘制一次，Phase表示在第几帧绘制。</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231207195010791.png"></p><p>Retainer Box 的原理是将 UI 渲染缓存在 Render Target上，在OnPaint的时候可以直接提交，但由于需要缓存Render Target，所以会带来一定的内存消耗</p><p>本质上还是用空间预计算来换时间，因此对于经常需要改变的UI不适用RetainerBox，且如果UI的覆盖面越大，RT的内存费用就会越高，需要权衡</p><p>主要是优化了OnPaint的流程，渲染层也可以直接拿RT去做了，对于Game Thread和Render Thread都能起到帮助</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231207195624292.png"></p><hr><h4 id="尽可能的对UI元素进行合并（图集，材质）："><a href="#尽可能的对UI元素进行合并（图集，材质）：" class="headerlink" title="尽可能的对UI元素进行合并（图集，材质）："></a><strong>尽可能的对UI元素进行合并（图集，材质）：</strong></h4><p><strong>结论：将多个小的UI纹素合并成一个大图集，使用一张大图集而不是多张小纹理可以降低纹理切换的开销。</strong></p><p><strong>同材质的component也可以合并成一个元素，这样也可以起到降低Draw Call的作用。</strong></p><p>切换材质，切换纹理，都会触发GPU Bind，从而打断合批，增加Draw Call的次数。</p><p>这对于减少内存开销，提高纹理的采样效率也能起到帮助。可以使用一些图集工具来合并纹理，在材质和 UMG 中使用这个图集</p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231208224546780.png"></p><hr><h4 id="引擎中开启优化项使用Canvas-Panel的合批功能："><a href="#引擎中开启优化项使用Canvas-Panel的合批功能：" class="headerlink" title="引擎中开启优化项使用Canvas Panel的合批功能："></a>引擎中开启优化项使用Canvas Panel的合批功能：</h4><p><strong>结论：对于Canvas Panel的Child Widget，在项目设置中开启Explicit Canvas Child ZOrder，设定好ZOrder 属性，ZOrder 相同的可以自动合批</strong></p><p><strong>尽可能使用Size Box，Horizontal Box、Vertical Box，Grid Box 结合使用来处理布局，Overlay也应该减少使用。</strong></p><p>Slate中的Draw Call按Widget的Layer ID分组，Vertical Box或Horizontal Box等其他容器Widget会将其子Widget的Layer ID合并，从而减少Draw Call的数量。</p><p>不开启优化设置的情况下，Canvas Panel会递增其子Widget的Layer ID，以便它们可以在必要时相互叠加渲染，这会造成Canvas Panel使用多个Draw Call。</p><p>使用Overlay时，也会递增LayerID导致更多的Draw Call，也应该加以限制。</p><hr><h4 id="Texture分辨率检查："><a href="#Texture分辨率检查：" class="headerlink" title="Texture分辨率检查："></a><strong>Texture分辨率检查：</strong></h4><p><strong>结论：对于常规的UI，纹理的Texture Group应该设置为在UI，压缩格式应该为应该为User Interface 2D (RGBA)。</strong></p><p><strong>对于3D的场景UI，所有纹理尺寸必须是2的乘数：2，4，8，16，32，64，128，256，512，1024，2048，4096，8193.</strong></p><p>纹理尺寸是２的乘数引擎会在导入Texture时自动创建这个Texture的Mipmap，尺寸不是必须为正方形，4x16都是可以的，只要保证是2的乘数就好。</p><p>这个规则只需要在制作3DUI的时候需要考虑，2DUI需要拥有保持最高分辨率不需要考虑Mipmap，3DUI有距离原因所以需要考虑引擎这个关于贴图优化的设置。</p><p>3DUI的纹理应该要有一个TerxtureGroup，能更好的管理这些纹理的压缩设置，引擎内部管理TerxtureGroup时能有更好的渲染性能。</p><hr><h4 id="UMG资产开发时定期清理没有引用到的Widget。"><a href="#UMG资产开发时定期清理没有引用到的Widget。" class="headerlink" title="UMG资产开发时定期清理没有引用到的Widget。"></a>UMG资产开发时定期清理没有引用到的Widget。</h4><hr><h2 id="Editor下的UMG资产检查工具"><a href="#Editor下的UMG资产检查工具" class="headerlink" title="Editor下的UMG资产检查工具"></a>Editor下的UMG资产检查工具</h2><h4 id="检查项，可能有哪些配置会打断合批？"><a href="#检查项，可能有哪些配置会打断合批？" class="headerlink" title="检查项，可能有哪些配置会打断合批？"></a>检查项，可能有哪些配置会打断合批？</h4><p>由于LayerID不好控制，影响因素多，且不直观，和在Widget Tree上的层级没有直接关系，因此这里统计的层级都指的是Widget Tree上的层级。</p><p>主要检查静态资产中，可能导致导致GPU Bind的操作或配置，这些操作或配置可能会打断UMG的合批</p><p><strong>从资产配置角度，对常用的非结构性需要渲染的UWidget做检查，包括UImage，UButton，UText，UProgressBar等。</strong></p><p>这些设置通常是在美术制作时就可以很容易注意的。</p><ol><li><p>因为不同Layer下的Widget会导致LayerID不同，所以一定不能合批，因此对同Layer下的常见Widget的一些配置参数做检查。</p></li><li><p>检查同一层级下UWidget是否使用同样的Texture，使用Texture不同，则不能合批。</p></li><li><p>检查同一层级下UWidget的Till属性是否被设置，如果被设置则不能和普通控件合批。</p></li><li><p>检查同一层级下UWidget的DrawAs选项是否为Border或者Text，如果被设置则不能被合批</p></li><li><p>检查Enable属性是否被勾选，如果没被勾选，则自己和自己的Child Widget都无法合批。</p></li></ol><hr><p><strong>工具主要思路为，从需要检查的资产开始作为根节点，创建一个UMG实例，递归遍历整棵Widget Tree，对需要检查的UWidget做属性设置的检查。</strong></p><p><strong>触发检查的入口，可以是当前Asset进行保存前进行检查，重写Uobject的PreSave函数，对于检查到可能导致合批失败的行为，弹出弹窗，提示不规范的行为。</strong></p><p><strong>由于Widget Tree只在Runtime时存在，无法直接在Editor获得</strong></p><p><strong>所以这里还需要获取对应的包目录，通过AssetRegistryModule搜索资产，然后转为UWidgetBlueprint以获取Widget Tree</strong></p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231208172204939.png"></p><p><strong>递归遍历每层Widget Tree，对处于同一Layer下的Widget做检查，检查通过就返回True</strong></p><p><strong>检查失败需要向容器中添加对应的Widget名称和不规范的行为，在检查结束后同一打印</strong></p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231208221742570.png"></p><p><strong>检查通过：</strong></p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231208191640922.png"></p><p><strong>检测到不规范的行为：</strong></p><p><img src="/images/loading.jpg" data-original="/2023/12/08/UMG%E6%B8%B2%E6%9F%93%E5%88%86%E6%9E%90%EF%BC%8C%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%EF%BC%8C%E5%B7%A5%E5%85%B7%E5%88%B6%E4%BD%9C/image-20231208221403577.png"></p><hr><h3 id="最终结论（规范-工具思路）"><a href="#最终结论（规范-工具思路）" class="headerlink" title="最终结论（规范+工具思路）"></a>最终结论（规范+工具思路）</h3><p><strong>针对UI开发人员：</strong></p><ol><li>对于静态UI，通过通过使用InviladitionBox来开启FathPath。</li><li>避免Widget Tree有太多层级，扁平化管理Widget</li><li>使用Retainer Box提高渲染效率，加速OnPaint过程，动静分离降低OverDraw：</li></ol><p><strong>针对美术人员：</strong></p><ol><li><p>美术填充资源时，尽可能避免导致合批会被打断的设置（通过合批检查工具）</p></li><li><p>确保Texture的分辨率和压缩格式合规，尽量使用同样的大图集</p></li></ol><p><strong>针对程序人员：</strong></p><ol><li><p>UMG逻辑性能本身：逻辑迁移到C++中或者脚本，采用事件驱动UI。根据更新频率和响应效率划分不同的UI，采用不同的策略，InviladitionBox的分区也可以参考这个。</p></li><li><p>对于动态UI做生命周期维护，避免Runtime时期重构Widget Tree的操作。</p></li></ol><hr><p><strong>UMG合批检查工具开发思路：</strong></p><ol><li>对于常用被渲染的UWidget进行配置检查，检查项是可能打断合批的不合理设置</li><li>从资产保存作为触发检查的入口，获取对应目录下的资产转为UMG蓝图资产（UWidgetBlueprint）</li><li>获取对应UWidgetBlueprint的Widget的RootWidget，自顶向下查找对应UWidge不规范的配置，记录违规Widget的名称和不规范原因</li><li>继续保存流程（不阻断），输出违规Widget的名称和不规范原因，辅助相关人员进行排查</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;历经三天经历了对Slate流程的分析，规范指定，和简易工具落地&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>AprilProfiler——简单的安卓端UE4性能分析器</title>
    <link href="https://aprilnavi.github.io/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/"/>
    <id>https://aprilnavi.github.io/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/</id>
    <published>2022-06-22T11:36:58.000Z</published>
    <updated>2023-12-08T15:42:52.599Z</updated>
    
    <content type="html"><![CDATA[<p>在魔方实习的第二个星期，当我了解完UE引擎的执行流程（game render rhi多线程tick）之后</p><p>亲爱的导师提出了下一个课题：</p><p>把玩一下adb（安卓调试桥），然后试试看在游戏屏幕上实时显示一些数据（内存，CPU占用率，GPU Time）</p><p>经过痛苦的一个月（写了十天其余时间都在苦痛debug），最后写出来的也算是比较完整的玩具了（能不能跑动随缘）</p><span id="more"></span><p>最终仓库URL：<a href="https://github.com/AprilNAVI/April-Profiler/tree/master">AprilNAVI/April-Profiler at master (github.com)</a></p><h2 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h2><p>得益于手机proc伪文件系统的存在，许多手机进程相关</p><p>以及当前整体手机runtime的软硬件信息我们都能从中拿到</p><p>我们的许多信息便是从此中提取然后加工得到的</p><p>不过在未root的手机上，许多文件的没有读写权限的，我们能获取的信息极为有限，不过对我们来说已经足够了</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220621173435126.png" alt="image-20220621173435126"></p><hr><p>整个profiler涉及到一个subsystem的编写（subsystem全局单例的特性符合我们的需求）</p><p>以及RHI上的OpenGL分支修改和插桩，一些实现过程借鉴了UE4的disjoint query和一些unity的插件实现</p><p>主要的难点在于实现过程的idea（完全没有写这方面的经验）还有安卓端的麻烦调试和bug的排除</p><p>（虽然鉴于本人教菜的项目经验，代码可能并不是那么的符合规范，但还是有尽量的朝正常的项目规格靠）</p><p>其余在编码的数据结构组织以及方法的组织上来说，过程还算轻松</p><p>（基本功能可以较快写完，只是跑不动而已2333）</p><hr><p>测试样机：小米9Pro 5g版（骁龙855,8+256）&lt;—这玩意是真的又烫又卡</p><hr><h2 id="整体设计"><a href="#整体设计" class="headerlink" title="整体设计"></a>整体设计</h2><p>在subsystem中设Start方法，其中设timer定时运行函数查询（如果证实放tick里面不大影响性能也会考虑放tick）</p><p>其中为了支持timer使用，所以用的是WorldSubsystem而非EngineSubSystem（一开始用的EngineSubSystem会crash）</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622190647491.png" alt="image-20220622190647491"></p><p>GPU time的部分则插在RHI中，伴随着渲染帧的结束每次更新全局变量GPU Time，我在tick中拿取</p><p>这也是为什么后文提到由于渲染帧和逻辑帧的差异，要给query做缓存操作</p><hr><h2 id="进程id和内存率"><a href="#进程id和内存率" class="headerlink" title="进程id和内存率"></a>进程id和内存率</h2><p>在proc系统中，目录：进程ID/Stat 中存放着的信息有助于我们获取到进程和内存相关的信息</p><p>有助于一个叫self的目录也能让我们快速定位到当前进程的stat文件，而无须进程ID</p><p>一个pid/stat中的文件如下所示（这里以运行崩坏3为例，在游戏项目中获取只需要获取self/stat就行，无须进程ID）：</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220621220416761-16558202580467.png" alt="image-20220621220416761"></p><p>从前往后的24个参数分别是（我们所能用到的）：</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622092006772.png" alt="image-20220622092006772"></p><p>从前往后便是这些参数的含义，我们会在运行时将其读取并导入我们的数据结构</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220621172938717-16558167202624.png" alt="image-20220621172938717"></p><p>如图所示，第一个参数就是我们当前进程的进程id，这是我们所需要的值之一</p><p>在导入数据时为了方便操作，我是以原生是string类型来导入这些数据的</p><p>因此最后进程ID的转化以这样的方式：</p><pre><code>int32 ProcessId=std::stoi(this-&gt;PidStat.pid.c_str());</code></pre><p>一般来说，在手机的内存管理中，以Pss（实际使用的物理内存，比例分配共享库占用的内存）是更加合理的</p><p>但为了便于计算我这里只计算了RSS（Resident Set Size 实际使用物理内存）</p><p>在安卓内存中，默认分配一页是4KB，因此我们最终拿到当前进程的占用内存（kb）的代码是这样的</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220621221815865.png" alt="image-20220621221815865"></p><p>总内存的获取则是存放在proc/meminfo内，也可以用一样的方法（c++的原生io）读取获得</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220621222623506.png" alt="image-20220621222623506"></p><p>将内存占用除以总的内存便能得到我们当前进程的内存占用率</p><p>这些数据通过adb都能拿到，实测在手机ue4项目runtime时也能直接读取相应目录得到</p><hr><h2 id="CPU占用率"><a href="#CPU占用率" class="headerlink" title="CPU占用率"></a>CPU占用率</h2><p>CPU占用率的计算只需要一个很简单的公式：USAGE=ACTIVE_TIME/TOTAL_TIME</p><p>拿到计算所需参数的过程则更为复杂一些，我们需要读取计算每个核心的信息录入我们的数据结构</p><p>读取每个核心ACTIVE_TIME和TOTAL_TIME，相加它们得到总的时间再相除</p><p>核心相关的信息存放在proc/stat（存放系统进程整体的统计信息）中，如图所示：</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622093803722.png" alt="image-20220622093803722"></p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622094213631.png" alt="image-20220622094213631"></p><p>这里我用一个结构体CPU data和枚举来管理各个字段：</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622101444950-16558640862298.png" alt="image-20220622101444950"></p><p>在读入数据时，使用的是c++原生的io和字符串相关函数，函数会将十个字段按序放入我们的CPU data中</p><p>并会自动根据proc/stat中的数据来判断CPU的数量，用一个vector来储存当前所有核的信息，将这个整体返回</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622103703461.png" alt="image-20220622103703461"></p><p>计算过程则会读入前后两次不同的Entity数据，以两次数据的差量作为最后用于计算的数据</p><p>其中Active Time由字段USER，NICE，SYSTEM，IRQ，SOFTIRQ相加得到</p><p>Idle Time由字段IDLE，IOWAIT相加得到，Active Time和Idle Time相加便得到</p><p>两次的数据相减便是这两次读取期间的CPU用量数据，稍加计算便能得到最终结果：</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622111046000.png" alt="image-20220622111046000"></p><p>这里计算出来的是总体的CPU用量和占用率，对于特定进程的占用率的计算暂时没有写出，但思路同样很简单</p><p>对于在上一步的proc/pid/stat文件中存在字段utime、stime、cutime、cstime的四元组</p><p>某进程的Process Cpu Time = utime + stime+ cutime + cstime，该值包括了其他所有线程的cpu时间</p><p>同样取一段时间内读取的差量，用来除以Total CPU Time就能得到当前进程的CPU占用率</p><p>在数据的读取和管理方面，我们在每次计算中将其读取进我们的数据结构，然后与原本储存的上一次读取的状态进行比对和计算</p><p>在计算完毕后我们会弃置旧的CPU data（类成员），并将新的写入以供下一次运算：</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622112841361-165586852381210.png"></p><hr><h2 id="GPU-Time"><a href="#GPU-Time" class="headerlink" title="GPU Time"></a>GPU Time</h2><p>GPU Time的测量在Android端则是比较不方便的，过程碰了很多壁用了很多时间，但最终还是得以成功实现</p><p>（ue自己写的在移动端跑不了，原因未知）</p><p>最终的实现过程参照了一个unity插件和UE自带的disjoint query实现</p><p>其实回头看来虽然几乎是把人家的版本copy了一遍，但确实大家写出来最终都是这个样子的</p><p>（毕竟学习的最快方式就是抄）</p><p>思路也很简单，在RHI的OpenGL分支用gl指令做插桩操作就能拿到，反而是debug的过程花了比较多的时间</p><p>首先对于这方面确实不了解，不知道安卓上哪些不了解的地方会影响到gl指令结果的返回</p><p>我不知道用ue原生的跨平台函数，会跳到哪个奇怪的地方然后给个奇怪的crash</p><p>因此我先是把默认的开关全打开（我不清楚哪一步是必要的，但最终可以取到结果）</p><p>AndroidOpenGL：</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622153924446.png" alt="image-20220622153924446"></p><p>OpenGL.h：<img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622154016195.png" alt="image-20220622154016195"></p><p>紧接着，为了方便之后test，我不想直接改变引擎自带的全局变量GGPU Time的值（我可能用这个变量也做一些test）</p><p>总而言之一个是不够我用的，因此我在EngineGlobal中增加了新的同为unit32类型的全局变量：</p><p>（当然这么做的代价是一次全量编译，但换了SSD之后编译整个引擎的速度还是可观的）</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622154424667.png" alt="image-20220622154424667"></p><p>对于GPU profiler的部分，我的数据结构和可能用到的init和release方法是直接照抄ue</p><p>UE的实现分为一个Timing（使用glQuerycounter指令）的实现和disjoint（glBeginQuery）的实现</p><p>其余部分做了一些简化，我去掉了加锁的部分，去掉了Event Node的统计，只留下Disjoint的实现方案：</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622161947054.png" alt="image-20220622161947054"></p><p>采用的查询和计算的数据结构直接用的UE自己写的FOpenGLDisjointTimeStampQuery</p><p>因为渲染帧和逻辑帧不是一一对应的，我们在读数据的时候拿的不一定是确切的渲染帧</p><p>因此我们在Profiler中构建了一个数组来存放每次渲染帧中query的结果</p><p>（UE用了4个buffer，但实际上用2个就够了，因为game线程只会比渲染线程快1到2帧）</p><p>对于每一个单独的query结构而言，数据结构的布局是这样的，这方面和另一个unity插件也是差不多的</p><p>一个上下文，一个储存内容，一个bool记录资源可用性，精简且使实用</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622154843887.png" alt="image-20220622154843887"></p><p>初始化阶段，会调用每个query的init函数，实际上做的是调用UE封装的函数PlatformGetNewRenderQuery</p><p>这个函数封装了使用gl指令来生成query查询结构的过程（我不知道这个函数能不能放心用，所以还是亲自把它搬出来了）：</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622164129353.png" alt="image-20220622164129353"></p><p>在渲染帧开始的时候（RHIBeginFrame）和渲染帧结束的时候（RHIEndFrame）插入我们的profiler函数</p><p>（实际上架构方面的东西也很取巧，UE往哪插我就往哪插，省了很多研究这部分架构的时间）</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622165624885.png" alt="image-20220622165624885"></p><p>对于Begin来说，做的是确认初始化，然后确定查询的index调用查询函数</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622170218396.png" alt="image-20220622170218396"></p><p>tracking方面则是简单的调用了glBeginQuery和glEndQuery指令</p><p>其中我会在EndTracking时尝试获取当前操作是否成功，并返回相应的错误代码（在debug阶段绑了大忙）</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622170103605.png" alt="image-20220622170103605"></p><p>对于EndFrame来说，除了停止tracking之外，还会根据确切的index对应的query结果来计算这个渲染帧的GPU Time</p><p>查询query结果时使用的glGetQueryObjectui64v指令很有意思，会根据传入的枚举值不同然后执行不同的操作</p><p>UE也对此操作做了封装（改为使用UE的枚举而非OpenGL的枚举，亲测使用OpenGL的枚举在Android上打包会失败）</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/image-20220622170459940.png" alt="image-20220622170459940"></p><p>之后会返回一个未经加工的时间，一般来说将其除以1e9就能得到最后所需的单位ms（下图算完就是1.05ms）：</p><p><img src="/images/loading.jpg" data-original="/2022/06/22/AprilProfiler%E2%80%94%E2%80%94%E7%AE%80%E5%8D%95%E7%9A%84%E5%AE%89%E5%8D%93%E7%AB%AFUE4%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%99%A8/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_16557313882382.png" alt="img"></p><p>我们将其写入我们的全局变量中（这样我在另一个profiler Subsystem中就可以直接拿到）</p><p>这样我们测量GPU Time的部分也完成了</p><h2 id="难点及解决方案"><a href="#难点及解决方案" class="headerlink" title="难点及解决方案"></a>难点及解决方案</h2><h3 id="实现过程的Idea"><a href="#实现过程的Idea" class="headerlink" title="实现过程的Idea"></a>实现过程的Idea</h3><p>由于本身一开始对于Android这块领域的知识是很空白的，因此Idea的构思花了比较多的时间</p><p>对于Android来说，许多信息都需要计算得来，不像pc平台例如进程id这种数据可以直接用一个api拿到</p><p>一开始我对于adb，shell，Android memory，proc这些概念是完全空白的不了解的</p><p>甚至对于c++的输入输出以及文件读写的api操作用的都还不是很熟练</p><p>在实现功能的时候碰了很多和最终结果完全不着调的壁（当时甚至还想到hook方面还有接入安卓sdk）</p><p>后面经过一些其他同学和前辈的指点和开导，对于Android和linux的共通性有了一些脑中的概念</p><p>通过KM还有一些其他地方零零碎碎的资料，对于不同种类的内存（pss，vss，rss）也有了一定的了解</p><p>proc中一些闻所未闻的参数也和我之前所学OS的概念能慢慢对应上</p><p>最终是借鉴了一个linux上计算cpu和memory的方案（实际上proc也是linux的东西）</p><p>代码的编写过程没有遇到什么太大的阻碍，反而是借机还学习了一下正规项目的代码规范和命名规则</p><p>其实最后总结的时候看来，要写出一个同款profiler的思路还是很简单很好借鉴的</p><p>不过思考问题寻求答案的过程对我来说感觉还是很有意义的（每次问导师有没有提示都说先Google一下）</p><hr><h3 id="Android端读写proc的Debug"><a href="#Android端读写proc的Debug" class="headerlink" title="Android端读写proc的Debug"></a>Android端读写proc的Debug</h3><p>PC不是linux或者安卓平台，不存在proc可以直接读写调试</p><p>因此确定能不能拿到proc的值并且成功计算，就成了一件很麻烦的事情</p><p>再加上硬盘是HDD，CPU性能也比较羸弱，编译和打包要花很长很长的等待时间</p><p>每次改代码都到手机上打包去看一眼结果，最后带来的就是地狱级的体验（有时候加一行log编译再打包就能花半小时）</p><p>后来善用adb将proc内的文件数据进行cat，copy到PC上存进txt一定程度上的方便了读数据功能时的调试</p><p>然后我也能拿到UE在Android端的log数据（之前问很多人不知道目录最后还是导师告诉的我）</p><p>最后还是顺利完成了有关proc方面相关的功能（比较尴尬的就是runtime时proc/stat在项目上拿不到）</p><hr><h3 id="Android端的OpenGL-Debug"><a href="#Android端的OpenGL-Debug" class="headerlink" title="Android端的OpenGL Debug"></a>Android端的OpenGL Debug</h3><p>OpenGL在Android上的限制比较多，例如很多查询功能在源码内默认是关的</p><p>对于以前简单的用win32 c++配置搭个框架就能写shader的环境</p><p>在安卓上虽然不做什么开发操作反而感觉举步维艰，有很多限制</p><p>最尴尬的就是每次glGetError结果都是1182_GL_INVALID_OPERATION</p><p>然后查各种手机GPU的文档还有Android的文档都发现没问题（Android确实支持OpenGL的）</p><p>然后每天盯着屏幕插log都快把ue插成海绵了还找不出问题</p><p>最后导师提醒可能是我的query和ue自带的query产生了冲突（刚好我插桩代码的地方每次ue的代码都比我先跑）</p><p>然后卡了十几天破案了我只觉得特别震撼（总的花了一个月左右，1/4想，1/4敲代码，1/4卡在查询指令）</p><p>中间还一直很怀疑自己，就简简单单的一个指令的事情做不好，导师会不会觉得我是笨蛋哈哈哈</p><hr><p>总体而言虽然花了很多时间遇到了各种奇奇怪怪的bug</p><p>但一边补知识框架，一边写功能的开发过程给我带来的收益，让我感到发自内心的喜悦</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在魔方实习的第二个星期，当我了解完UE引擎的执行流程（game render rhi多线程tick）之后&lt;/p&gt;
&lt;p&gt;亲爱的导师提出了下一个课题：&lt;/p&gt;
&lt;p&gt;把玩一下adb（安卓调试桥），然后试试看在游戏屏幕上实时显示一些数据（内存，CPU占用率，GPU Time）&lt;/p&gt;
&lt;p&gt;经过痛苦的一个月（写了十天其余时间都在苦痛debug），最后写出来的也算是比较完整的玩具了（能不能跑动随缘）&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>UE的render线程和RHI</title>
    <link href="https://aprilnavi.github.io/2022/05/14/UE%E7%9A%84%E6%B8%B2%E6%9F%93%E7%BA%BF%E7%A8%8B%E5%92%8CRHI/"/>
    <id>https://aprilnavi.github.io/2022/05/14/UE%E7%9A%84%E6%B8%B2%E6%9F%93%E7%BA%BF%E7%A8%8B%E5%92%8CRHI/</id>
    <published>2022-05-14T13:36:58.000Z</published>
    <updated>2022-05-14T15:12:26.172Z</updated>
    
    <content type="html"><![CDATA[<p>在入职一星期多一点的时候，成功的通过集思广益一些前辈的文章还有对源码的了解</p><p>梳理出了主线程和render以及RHI线程是如何分工的</p><p>这样一来，虽然不清楚各个模块的细节，但UE的整体架构和执行流程弄清楚了</p><p>也根据自己已学的内容和前辈的经验尝试总结出了一些优化的方案</p><p>我很庆幸我拥有一个特别好的导师，在学习的旅途中总是及时出现为我梳理思路解答难题</p><p>而我也很幸运的一路向前冲没有掉进哪个模块的坑里，最后能把全局都大体拿下</p><p>能在一星期掌握整套的流程，真的感觉十分的开销</p><span id="more"></span><h1 id="UE的渲染线程和RHI以及相关优化"><a href="#UE的渲染线程和RHI以及相关优化" class="headerlink" title="UE的渲染线程和RHI以及相关优化"></a>UE的渲染线程和RHI以及相关优化</h1><p>在UE中，game线程负责逻辑tick和其他线程的调度</p><p>render线程负责剔除、合批，场景遍历和draw api的生成</p><p>RHI线程负责drawapi的执行（我理解是把渲染命令serialize，通过图形API到GPU）</p><p>UE以前是没有RHI的，只有game线程和render线程</p><p>为了加快渲染线程的计算能力，把场景遍历放到了task system中的其他线程上，</p><p>可见性剔除则继续留在渲染线程中，提交渲染命令就轮给RHI来做</p><p>本篇会梳理一次EngineLoop中，提交渲染命令的几个关键点，</p><p>适当的深入源码，配合insight还有一些前辈的整合的资料来分析UE的渲染和RHI是如何执行的</p><p>Let’s Go！</p><hr><h2 id="渲染线程一览"><a href="#渲染线程一览" class="headerlink" title="渲染线程一览"></a>渲染线程一览</h2><p>拿张图来稍微梳理一下三大线程模型的概念是什么样的</p><p><img src="/images/loading.jpg" data-original="/2022/05/14/UE%E7%9A%84%E6%B8%B2%E6%9F%93%E7%BA%BF%E7%A8%8B%E5%92%8CRHI/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_16522382484033-16522385781534.png" alt="img"></p><p><img src="/images/loading.jpg" data-original="/2022/05/14/UE%E7%9A%84%E6%B8%B2%E6%9F%93%E7%BA%BF%E7%A8%8B%E5%92%8CRHI/52235fc6156142d29460fd0f510da2f0-16525086961133.png"></p><p><img src="/images/loading.jpg" data-original="/2022/05/14/UE%E7%9A%84%E6%B8%B2%E6%9F%93%E7%BA%BF%E7%A8%8B%E5%92%8CRHI/image-20220511111049070-16522386502305.png" alt="image-20220511111049070"></p><p>不难看出，我们在render线程从BeginFrame开始作为一个循环，在EndFrame结束渲染工作进入CPU Stall Wait</p><p>render线程的具体工作分为两部分，即Draw Scene和Draw Slate，在他们的流程中调度RHI线程来协助工作</p><p>render线程依次从渲染队列拿任务来做的，当没有任务时就会等待，同时在渲染中也可能等待RHI</p><p>当任务特别多时，game线程会在许多阶段触发flush操作强行等待渲染线程执行到某个位置，这样则会导致game线程等待</p><p>我们还是会希望尽量把线程跑满，尽可能减少等待的情况发生</p><hr><h3 id="BeginFrame-and-EndFrame"><a href="#BeginFrame-and-EndFrame" class="headerlink" title="BeginFrame and EndFrame"></a>BeginFrame and EndFrame</h3><p>把开始和结束放在一起，是因为他们性质相似，都在FengineLoop中简单的往渲染队列发送命令</p><p>render线程会告知相关的rhi线程开始和停止工作</p><pre><code>FengineLoop::Tick()&#123;....        // beginning of RHI frame        ENQUEUE_RENDER_COMMAND(BeginFrame)([CurrentFrameCounter](FRHICommandListImmediate&amp; RHICmdList)        &#123;            BeginFrameRenderThread(RHICmdList, CurrentFrameCounter);        &#125;);        ....                // end of RHI frame        ENQUEUE_RENDER_COMMAND(EndFrame)(            [CurrentFrameCounter](FRHICommandListImmediate&amp; RHICmdList)            &#123;                EndFrameRenderThread(RHICmdList, CurrentFrameCounter);            &#125;);....&#125;</code></pre><p>两个操作分别在FengineLoop::Tick()的开头与末尾，他们的具体执行的函数分为两部分，之后往后其他入队操作也是如此</p><p>一部分后边传入进宏的lambda表达式，用于计算和提供信息，而ENQUEUE_RENDER_COMMAND对应的宏的则跑了：</p><pre><code>template&lt;typename TSTR, typename LAMBDA&gt;FORCEINLINE_DEBUGGABLE void EnqueueUniqueRenderCommand(LAMBDA&amp;&amp; Lambda)</code></pre><p>这个函数一般跑在渲染线程上，同时根据一些状态判断来决定是否调用RHI或者其他线程来协助渲染任务的进行。</p><p>一般情况下往往会走到调用传入的lambda然后调度RHI的if分支。</p><hr><h3 id="DrawScene"><a href="#DrawScene" class="headerlink" title="DrawScene"></a>DrawScene</h3><p>我们一般在计算完场景之后，往渲染队列发送渲染场景的命令，具体位置如下</p><pre><code>FengineLoop Tick()&#123;   UGameEngine::Tick()   &#123;     UGameEngine::RedrawViewports()      &#123;       FViewport::Draw()       &#123;          EnqueueBeginRenderFrame()  //实际上是更新RT到BackBuffer上          ...          ViewportClient-&gt;Draw()          &#123;             UGameViewportClient::Draw()             &#123;                             //calculate scene in game thread                 FRendererModule::BeginRenderingViewFamily()                &#123;                  ...                  ENQUEUE_RENDER_COMMAND(FDrawSceneCommand)                  ...                &#125;                             &#125;          &#125;          ...          UGameViewportClient::OnViewportRendered().Broadcast(this);        &#125;      &#125;   &#125;&#125;</code></pre><p>由Insight和渲染关系的流程图可知，计算场景的部分还是由game线程做的</p><p>计算场景完之后才往渲染队列发送FDrawSceneCommand命令，两个过程是串行的同步的，有依赖关系</p><p>在ENQUEUE_RENDER_COMMAND(FDrawSceneCommand)中将SceneRenderer以lambda传给渲染线程</p><p>FDrawSceneCommand分为三个部分，Init，PostInit，ExecCmd</p><p>实际上每个阶段所做的都是Flush一些API calls</p><p><strong>Init：</strong></p><p>主要是做visibility（裁剪）和shadow的计算</p><p><strong>PostInit：</strong></p><p>这个时候需要等待RHI线程执行完（所以说RHI线程如果执行有瓶颈也会反卡到Render线程）</p><p><strong>ExecCmd：</strong></p><p>这个地方就真正的生成各种Pass流程的api往RHI上送</p><p>可以说这个部分是一次绘制中真正的大头</p><p>（实际观察发现这里的时间并不是最多的，有些时候在Init阶段做裁剪甚至比这个阶段时间更多）</p><hr><p>结束场景绘制之后，还会进行一些DebugHUD（stat）的绘制，</p><p>这个步骤也处于ReDrawViewport中，紧接着场景的计算之后由Game线程执行</p><p>可以理解绘制场景和HUD都依赖场景的计算，而绘制场景在Render线程中进行，绘制HUD则在Game线程</p><hr><h3 id="DrawState"><a href="#DrawState" class="headerlink" title="DrawState"></a>DrawState</h3><p>真正绘制UI的地方绘制场景之后，由Game线程上的Slate::Tick(Time and Widget)</p><p>在Game线程的FSlateApplication::TickAndDrawWidgets中发生，相关的计算都进行在Game线程</p><p>在调用相关的宏之后往render线程塞入RenderCmd_DrawSlate</p><p>render线程在完成绘制场景的任务后才会执行绘制State的部分</p><p>因为game线程往往跑得快，而绘制State也不需要什么预计算直接拿着game线程的数据跑</p><p>因此这一步在渲染线程上也不怎么耗时</p><p><img src="/images/loading.jpg" data-original="/2022/05/14/UE%E7%9A%84%E6%B8%B2%E6%9F%93%E7%BA%BF%E7%A8%8B%E5%92%8CRHI/image-20220513190949587.png" alt="image-20220513190949587"></p><p>此时render线程上做的和当时在绘制场景时做的也差不多，也是flush生成一堆api往RHI送</p><hr><h3 id="ENQUEUE-RENDER-COMMAND"><a href="#ENQUEUE-RENDER-COMMAND" class="headerlink" title="ENQUEUE_RENDER_COMMAND"></a>ENQUEUE_RENDER_COMMAND</h3><p>ENQUEUE_RENDER_COMMAND执行在Rendering线程，调用则是一般在Game线程</p><p>我们可以看看这个ENQUEUE_RENDER_COMMAND的宏是做什么的</p><pre><code>#define ENQUEUE_RENDER_COMMAND(Type) \    struct Type##Name \    &#123;  \        static const char* CStr() &#123; return #Type; &#125; \        static const TCHAR* TStr() &#123; return TEXT(#Type); &#125; \    &#125;; \    EnqueueUniqueRenderCommand&lt;Type##Name&gt;</code></pre><p>以FengineLoop中每帧结束的地方为例，将原处替换就变成了</p><pre><code>// end of RHI frame        struct EndFrameName         &#123;          static const char* CStr() &#123; return &quot;EndFrame&quot;; &#125;         static const TCHAR* TStr() &#123; return TEXT(&quot;EndFrame&quot;); &#125;         &#125;;         EnqueueUniqueRenderCommand&lt;EndFrameName&gt;(            [CurrentFrameCounter](FRHICommandListImmediate&amp; RHICmdList)        &#123;            EndFrameRenderThread(RHICmdList, CurrentFrameCounter);        &#125;);</code></pre><p>实际上所做的是将lambda表达式子的值传入到EnqueueUniqueRenderCommand里面</p><p>我们可以看看几个比较典型此处的lambda中的函数（因为不习惯lambda一开始还以为只跑一个函数）</p><p><strong>EndFrameRenderThread：</strong></p><pre><code>static inline void EndFrameRenderThread(FRHICommandListImmediate&amp; RHICmdList, uint64 CurrentFrameCounter)&#123;    RHICmdList.EnqueueLambda([CurrentFrameCounter](FRHICommandListImmediate&amp; InRHICmdList)    &#123;        GEngine-&gt;SetRenderSubmitLatencyMarkerEnd(CurrentFrameCounter);    &#125;);    FCoreDelegates::OnEndFrameRT.Broadcast();    RHICmdList.EndFrame();&#125;</code></pre><p>实际上是接受了RHI的命令列表还有帧数的计数器</p><p>在其中做一个广播，通知RT已经清空，然后在RHI的列表上告知这一帧已结束</p><p>同理我们也可以分析一下BeginFrame时做了什么</p><p><strong>BeginFrameRenderThread：</strong></p><pre><code>static inline void BeginFrameRenderThread(FRHICommandListImmediate&amp; RHICmdList, uint64 CurrentFrameCounter)&#123;    GRHICommandList.LatchBypass();    GFrameNumberRenderThread++;    RHICmdList.BeginFrame();    FCoreDelegates::OnBeginFrameRT.Broadcast();    RHICmdList.EnqueueLambda([CurrentFrameCounter](FRHICommandListImmediate&amp; InRHICmdList)    &#123;        GEngine-&gt;SetRenderSubmitLatencyMarkerStart(CurrentFrameCounter);    &#125;);&#125;</code></pre><p>同样接受了RHI的命令列表还有帧数的计数器</p><p>从命名上推断，给渲染线程的帧数计数++，然后在RHI列表里面启动这一帧，做一个广播通知RT已经准备完成</p><p>看了一下GFrameNumberRenderThread等重要数据会放在CoreGlobalscpp里面</p><p>其中还存了GInputTime，GFrameNumber，推测这里的G可能是Global或者是Game的意思（感觉前者）</p><p>其实和渲染相关的函数内部也很符合直觉，有较高的可读性，毕竟这些线程什么都是跑在CPU上的</p><hr><p>我们的函数EnqueueUniqueRenderCommand，在RenderingThread.cpp上</p><p>这个是在ENQUEUE_RENDER_COMMAND宏之内的，用于发送渲染命令的较为通用的一个函数</p><pre><code>template&lt;typename TSTR, typename LAMBDA&gt;FORCEINLINE_DEBUGGABLE void EnqueueUniqueRenderCommand(LAMBDA&amp;&amp; Lambda)&#123;    typedef TEnqueueUniqueRenderCommandType&lt;TSTR, LAMBDA&gt; EURCType;    if (IsInRenderingThread())    &#123;            FRHICommandListImmediate&amp; RHICmdList = GetImmediateCommandList_ForRenderCommand();        Lambda(RHICmdList);        //执行lambda表达式    &#125;    else    &#123;        if (ShouldExecuteOnRenderThread())        &#123;            //检查渲染线程，创建一个渲染任务，压入渲染队列立即由渲染线程执行            CheckNotBlockedOnRenderThread();            TGraphTask&lt;EURCType&gt;::CreateTask().ConstructAndDispatchWhenReady(Forward&lt;LAMBDA&gt;(Lambda));        &#125;        else        &#123;            //直接由主线程执行            EURCType TempCommand(Forward&lt;LAMBDA&gt;(Lambda));            FScopeCycleCounter EURCMacro_Scope(TempCommand.GetStatId());            TempCommand.DoTask(ENamedThreads::GameThread, FGraphEventRef());        &#125;    &#125;&#125;</code></pre><p>调用ENQUEUE_RENDER_COMMAND一般都在主线程，也就是Game线程</p><p>而ENQUEUE_RENDER_COMMAND执行往往是在Rendering线程，所以往往走if的第一个分支</p><p>我们传入的Lambda表达式由此处被执行，因此假如在BeginFrame时调用的ENQUEUE_RENDER_COMMAND，</p><p>则展开就是EnqueueUniqueRenderCommand<BeginFrame>(LAMBDA&amp;&amp; Lambda)</BeginFrame></p><p>实际上就是将底下的这个式子传入给RHI线程跑，我们最终也是通过这个来调度RHI的</p><pre><code>[CurrentFrameCounter](FRHICommandListImmediate&amp; RHICmdList)        &#123;            BeginFrameRenderThread(RHICmdList, CurrentFrameCounter);        &#125;);</code></pre><hr><h2 id="Insight截取分析"><a href="#Insight截取分析" class="headerlink" title="Insight截取分析"></a>Insight截取分析</h2><p>我们跑了UE官方的的ActionRPG项目（手游，PC端调试运行，延迟渲染管线）</p><p>添加了-statnamedevents命令行参数，获得了我们所需的几乎所有想知晓的事件</p><p><img src="/images/loading.jpg" data-original="/2022/05/14/UE%E7%9A%84%E6%B8%B2%E6%9F%93%E7%BA%BF%E7%A8%8B%E5%92%8CRHI/image-20220510183221588-16521787442661.png" alt="image-20220510183221588"></p><hr><p>这个案例走的是延迟渲染的管线，截取帧耗时16.4ms，其中13.4ms用于Wait FPS，游戏线程的真实tick实际上只做了2.9ms</p><p>看得出来我们的目标帧率为60fps，13.4ms的时间在等待说明我们很轻易的就在游戏线程上跑Tick</p><p>假设我们耗时16.4ms的gameloop对应的是图中右下角的render loop</p><p>同样的看我们从WaitFPS时塞入渲染队列的BeginFrame，渲染用时4.9ms</p><p>一样是很轻松，大部分时间都用于CPU Stall，出色的完成了任务</p><p>这证明在此机器上，我们在较低负载的情况下完成了游戏循环，循环进行的较为理想和可控</p><p>因此综上所述，目前没有明显的性能瓶颈。</p><hr><h2 id="移动端的性能优化目标"><a href="#移动端的性能优化目标" class="headerlink" title="移动端的性能优化目标"></a>移动端的性能优化目标</h2><p>笔者目前在研究移动平台的性能优化，对比PC端来说，移动端的硬件性能较为羸弱</p><p>需要考虑尽可能的减少Wait时间来提高CPU和GPU的效率，并结合安卓/IOS的平台做线程的优化</p><p>同时也需要考虑高负载带来的电量消耗和性能问题，所以满载运行也不一定是最好的选择</p><p>因此我所理解的性能优化，是根据不同设备进行不同的性能分级</p><p>尽可能的在目标机型可以承受的情况下拉高占用率提高硬件效率跑到目标帧率</p><p>同时通过限定目标帧率来控制功耗和温度，达到尽可能长时间在移动平台上有稳定表现</p><p>（例如能偶尔跑上60或者刚开始可以跑3分钟60，不如全程锁45）</p><hr><h2 id="目前能想到的优化手段"><a href="#目前能想到的优化手段" class="headerlink" title="目前能想到的优化手段"></a>目前能想到的优化手段</h2><p>按照前面的截取示例来说，我们的游戏循环已经较为理想了</p><p>但假设我们会希望再好一些，把等待的时间再缩短，负载率再提高，应该怎么做呢</p><h3 id="优化Uworld的分组Tick"><a href="#优化Uworld的分组Tick" class="headerlink" title="优化Uworld的分组Tick"></a>优化Uworld的分组Tick</h3><p>在我们截取的项目中，Uworld的Tick中的PrePhysics阶段是耗时较高的一个阶段</p><p>PrePhysics用的是上一次Tick完的最新的物理数据，也是我们的默认tick，不加以优化的话可能很多事情都会在这里做</p><p>此时会启动物理线程来进行物理模拟，和DuringPhysics并行执行</p><p>而由于分组Tick是串行的，所以后续步骤需要等待DuringPhysics和他并行的物理线程走完才能接着往下</p><p>也就是说即使我们在DuringPhysics什么也不做，他也会被物理线程拖慢时间</p><p><img src="/images/loading.jpg" data-original="/2022/05/14/UE%E7%9A%84%E6%B8%B2%E6%9F%93%E7%BA%BF%E7%A8%8B%E5%92%8CRHI/v2-386a23e022143754706776076d79501e_720w.jpg" alt="img"></p><p>因此我们可以将一些不依赖物理结果的步骤放到During或者其他地方</p><p>这样看来我们在等待物理线程执行时Game线程在During时期就不用处于等待状态，也能进行一些Tick的工作</p><p>这样一来虽然总的Tick任务还是一样的，但是省去了Game线程上等待物理线程的时间</p><hr><h3 id="提前写入UI的深度跳过一些绘制"><a href="#提前写入UI的深度跳过一些绘制" class="headerlink" title="提前写入UI的深度跳过一些绘制"></a>提前写入UI的深度跳过一些绘制</h3><p>在Render线程中，每次渲染Slate的部分都是在渲染场景之后才进行的</p><p>这样不免有一些像素可能会被UI挡住，这些被挡住的场景像素实则是浪费掉的</p><p>可以考虑在每次渲染流程开始之前，先在RT上UI的对应位置先写入深度值</p><p>这样在处理场景绘制的时候在进行到深度测试时就会自动跳过这些对应区域的绘制</p><hr><h3 id="在合适的情况下增加RHI线程"><a href="#在合适的情况下增加RHI线程" class="headerlink" title="在合适的情况下增加RHI线程"></a>在合适的情况下增加RHI线程</h3><p>经过一些前辈的优化文章和对RHI线程的介绍，我对RHI的也多了一些了解和想法</p><p>在4.22时RHI甚至还是实验性功能，也就是说一开始UE的渲染是不包含RHI的</p><p>RHI是Render Hardware Interface的缩写，把各个平台的图形API包装成统一接口，供上层渲染来使用</p><p>RHI线程负责将Render API serialize推送到GPU上执行（iOS不开RHI单独的线程，安卓会开单独的RHI线程）</p><p>而图形API中的一些heavy指令例如glDrawArray这种，会要求GPU分配缓冲区执行各种操作</p><p>GPU此时会禁止CPU再提交命令过来，这个时候CPU就会进行等待，而单RHI线程只拥有单个cmdbuffer的serialize能力</p><p>因此在渲染场景中的大物件或者其他需要大量Draw Call的情况下，RHI线程会成为瓶颈</p><p>有些先进的图形API例如METAL/Vulkan则具有多个cmdbuffer，可以多开RHI然后并行化的serialize API command</p><hr><p>所以不难看出，其实并不是越多draw call就越有可能引起RHI卡顿，实际上还是heavy api的锅</p><p>RHI通常是卡GPU在对api的处理上，而不是对api的serielize上</p><p>所以在一些前辈的优化方案中可以看到他们采取的是将一些heavy api分离到其他的RHI中去做</p><p>但本身RHI一条线上具有依赖时序关系的工作线被分到几条线上去做</p><p>如果不能解决相对应的依赖关系，最后导致几个RHI线程互等也是没法解决问题的</p><p>例如，draw api有对资源的依赖（buffer，shader link to program，texture）</p><p>因此如何最终的真正做到将RHI线程上的工作做到并行化才是真正的难题</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在入职一星期多一点的时候，成功的通过集思广益一些前辈的文章还有对源码的了解&lt;/p&gt;
&lt;p&gt;梳理出了主线程和render以及RHI线程是如何分工的&lt;/p&gt;
&lt;p&gt;这样一来，虽然不清楚各个模块的细节，但UE的整体架构和执行流程弄清楚了&lt;/p&gt;
&lt;p&gt;也根据自己已学的内容和前辈的经验尝试总结出了一些优化的方案&lt;/p&gt;
&lt;p&gt;我很庆幸我拥有一个特别好的导师，在学习的旅途中总是及时出现为我梳理思路解答难题&lt;/p&gt;
&lt;p&gt;而我也很幸运的一路向前冲没有掉进哪个模块的坑里，最后能把全局都大体拿下&lt;/p&gt;
&lt;p&gt;能在一星期掌握整套的流程，真的感觉十分的开销&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>UE4中Game线程的主流程Tick</title>
    <link href="https://aprilnavi.github.io/2022/05/10/Gengine.tick%E6%B5%81%E7%A8%8B/"/>
    <id>https://aprilnavi.github.io/2022/05/10/Gengine.tick%E6%B5%81%E7%A8%8B/</id>
    <published>2022-05-10T13:36:58.000Z</published>
    <updated>2022-05-14T15:11:44.036Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章中间磨洋工磨了比较久，整体写的也不是很好</p><p>主要是Uworld的更新涉及到太多的宏和函数跳转嵌套，给我整的麻麻的</p><p>但好在最后还是弄清楚了最主要的tick流程是在做什么</p><p>为接下来弄清楚RHI线程和Render线程做好铺垫</p><span id="more"></span><h1 id="UGameEngine-tick"><a href="#UGameEngine-tick" class="headerlink" title="UGameEngine::tick"></a>UGameEngine::tick</h1><p>是FengineLoop中游戏线程的tick主体，实际上是UGameEngine::tick</p><p>其实这里困惑了我好久，因为我对着Gengine-&gt;Tick并不能直接找到其定义，到相关的cpp文件找也没找到</p><p>再加上ue源码的头文件和Cpp文件也不是一一对应的，一度怀疑自己眼花了还是cpp学的有问题</p><p>然后发现了是PURE_VIRTUAL这个宏搞的鬼，最后定位到了真正的tick函数的位置</p><p>（cpp文件中可以不用实现此函数，同时自己其他函数中又可以直接调用此函数，且子类需要强制实现此函数）</p><p>在FengineLoop的注释上对这个函数的解释是main game engine tick (world, game objects, etc.)</p><p>也印证game线程的主要tick都是在这个函数里面完成的</p><p>主要的学习方式还是按照一些前辈整合的一些流程先看看有个印象，然后再去源码里面挨个验证思想</p><hr><h2 id="总体流程"><a href="#总体流程" class="headerlink" title="总体流程"></a>总体流程</h2><p>engine的tick分为以下几个阶段：</p><p><strong>TickAsyncLoading：</strong></p><p>也被称为StaticTick阶段，主要是做一些异步资源的更新</p><p><strong>WorldTick：</strong></p><p>遍历WorldList，逐World的做tick，也是我们这阶段tick的主体</p><p>里面其实还包含了对每个world都做一遍TickWorldTravel处理关卡加载逻辑</p><p><strong>Tickable GameObjects Without World</strong>：</p><p>引擎会让一些对象继承FTickableGameObject来获得tick的功能</p><p>我们这里tick的是不在世界内的tick，世界内Tickable的tick在Utick里面做</p><p><strong>RedrawViewPort：</strong></p><p>注释写的是Render everything，意思就是说这个draw操作就渲染了所有所需的元素</p><p>但写成Redraw让我怀疑这一次Loop里面在这之前也有draw的操作</p><p>后边想想这个Redraw可能是对应上一帧的，所以说Redraw也没错</p><p>渲染的流程走完以后还会进行一些后处理，例如PostRenderAllViewports做一些渲染完场景才能做的任务</p><p>然后还会给渲染队列塞个TickRenderingTimer来更新RT池</p><hr><h2 id="TickAsyncLoading"><a href="#TickAsyncLoading" class="headerlink" title="TickAsyncLoading"></a>TickAsyncLoading</h2><p>这里应该是涉及到UE4运行时期间加载资源的方法，引擎在这里调用了一个StaticTick</p><p>这样看得出来UE4的有些资源是runtime进行异步加载的，而且是逐tick</p><p>（可能猜想有些资源是逐world或者逐level更新，但还没有注意到相关内容）</p><hr><h2 id="WorldTick："><a href="#WorldTick：" class="headerlink" title="WorldTick："></a>WorldTick：</h2><p>worldtick是GameEngine::Tick的主体之一，我们的逐level和分组tick都在里面完成</p><p>我们除了对每个world都做了tick之前还对他们做TickWorldTravel(Context, DeltaSeconds)来处理关卡加载的逻辑</p><hr><h3 id="Level的分组tick之前"><a href="#Level的分组tick之前" class="headerlink" title="Level的分组tick之前"></a>Level的分组tick之前</h3><p>首先是<code>FDrawEvent* TickDrawEvent = BeginTickDrawEvent();</code></p><p>BeginTickDrawEvent()的构造里有ENQUEUE_RENDER_COMMAND(BeginDrawEventCommand)</p><p>向渲染队列发送一个BeginDrawEventCommand的命令，之后在DrawViewport阶段还会再塞一个BeginDrawingCommand</p><p>这种很相似的命名让我目前还没能分出这俩的功能差异</p><p>这个TickDrawEvent 会在最后再被调用一次，给渲染队列发送一个EndDrawEventCommand</p><hr><p>首先会发送一个广播告知世界开始tick</p><pre><code>FWorldDelegates::OnWorldTickStart.Broadcast(this, TickType, DeltaSeconds);</code></pre><p>然后会更新我们的网络</p><pre><code>        BroadcastTickDispatch(DeltaSeconds);        BroadcastPostTickDispatch();        if( NetDriver &amp;&amp; NetDriver-&gt;ServerConnection )        &#123;            TickNetClient( DeltaSeconds );        &#125;</code></pre><p>接着验证是否是启用了高优先级的加载和无缝的切换地图，如果是就给异步加载更多时间</p><pre><code>    if (Info-&gt;bHighPriorityLoading || Info-&gt;bHighPriorityLoadingLocal || IsInSeamlessTravel())    &#123;        CSV_SCOPED_SET_WAIT_STAT(AsyncLoading);        // Force it to use the entire time slice, even if blocked on I/O        ProcessAsyncLoading(true, true, GPriorityAsyncLoadingExtraTime / 1000.0f);    &#125;</code></pre><p>然后Tick我们的Nav导航系统：</p><pre><code>    if (NavigationSystem != nullptr)    &#123;        NavigationSystem-&gt;Tick(DeltaSeconds);    &#125;</code></pre><p>Nav更新完以后会进行一个广播作为分组Tick开始的标志，在分组tick结束时也会进行一个广播</p><pre><code>FWorldDelegates::OnWorldPreActorTick.Broadcast(this, TickType, DeltaSeconds);....FWorldDelegates::OnWorldPostActorTick.Broadcast(this, TickType, DeltaSeconds);</code></pre><p>然后会遍历LevelCollection收集需要Tick的level假如到LevelsToTick，进行分组Tick</p><p>这取决于关卡是静态的还是动态的（一般我们所想可能是只会tick已加载的level）</p><hr><h3 id="Level的分组tick"><a href="#Level的分组tick" class="headerlink" title="Level的分组tick"></a>Level的分组tick</h3><p>分组tick如下：</p><pre><code>    for (int32 i = 0; i &lt; LevelCollections.Num(); ++i) &#123;               RunTickGroup(TG_PrePhysics);        RunTickGroup(TG_StartPhysics);        RunTickGroup(TG_DuringPhysics, false);        RunTickGroup(TG_EndPhysics);        RunTickGroup(TG_PostPhysics);                GetTimerManager().Tick(DeltaSeconds);        FTickableGameObject::TickObjects(this, TickType, bIsPaused, DeltaSeconds);                PlayerController-&gt;UpdateCameraManager(DeltaSeconds);                RunTickGroup(TG_PostUpdateWork);        RunTickGroup(TG_LastDemotable);            &#125;</code></pre><p>其实一般写Gameplay我们能够选择的分组主要就是四个：</p><p><strong>TG_PrePhysics，TG_DuringPhysics，TG_PostPhysics，TG_PostUpdateWork</strong></p><p>首先在PrePhysics开始之前就会StartFrame，进行模拟之前的工作，构建碰撞树</p><p><strong>PrePhysics组</strong>：</p><p>是一帧的开始。UE4很多component和actor的tick都在这里执行</p><p>此 tick 中的物理模拟数据属于上一帧，因为这一帧的物理模拟还没有开始</p><p>TG_StartPhysics：</p><p>在此之前会EnsureCollisionTreeIsBuilt()检查是否构建完物理树</p><p>随后通知PhysX进行物理模拟</p><p><strong>TG_DuringPhysics</strong>：</p><p>这个步骤和物理线程TG_StartPhysics组是并行的，不依赖物理的actor和component一般放这里tick</p><p>常见用途为更新物品栏画面或小地图显示。此处物理数据完全无关，或显示要求不精确，一帧延迟不会造成问题。</p><p>TG_EndPhysics：</p><p>通知PhysX停止物理模拟</p><p><strong>TG_PostPhysics</strong>：</p><p>物理模拟已经完成，假如我们的actor或者component需要依赖物理（骨骼，布料），则一般放在这里tick</p><p>渲染此帧时所有物理对象是位于它们的最终位置。</p><p> <strong>GetTimerManager().Tick：</strong></p><p>Timer是Unreal 的定时器调度机制, 服务对象为 <strong>Delegate</strong></p><p><strong>FTickableGameObject::TickObjects(this, TickType, bIsPaused, DeltaSeconds)：</strong></p><p>Tickable Ticking 服务对象为 C++ 类, 我们会让对象继承自 <strong>FTickableGameObject</strong> 基类</p><p>重载<strong>Tick</strong>和<strong>GetStatId</strong>函数来获得Tick的功能</p><p>实现是每次 Tick 后遍历 FTickableStatics 集合中的所有 Tickable 对象并执行</p><p>因此 Tickable 对象会在每一帧执行, 不能设置 Tick 的时间间隔</p><p><strong>UpdateCamera：</strong></p><p>PlayerController-&gt;UpdateCameraManager(DeltaSeconds)会在这里更新相机</p><p><strong>TG_PostUpdateWork：</strong></p><p> 在摄像机更新后发生。如特效必须知晓摄像机朝向的准确位置，可将控制这些特效的 actor 放置于此。</p><p>这也可用于在帧中绝对最靠后运行的游戏逻辑，如解决格斗游戏中两个角色在同一帧中尝试抓住对方的情况。</p><p>其中每个分组任务之间是串行的，必须在执行上一阶段分组Tick完成之后（否则阻塞）</p><p>才能执行下一阶段的分组Tick任务</p><p>Actor的Tick蓝图版本是实现了ReceiveTick(DeltaSeconds)</p><p>而cpp是通过LatentActionManager.ProcessLatentActions(this, MyWorld-&gt;GetDeltaSeconds());</p><p>这个函数在FengineLoop一些地方也能看到</p><p>Pawn是包含了AController的，它的tick通过AController 的 AddPawnTickDependency来实现</p><p>其他想获得Tick功能继承Uobject的则是通过继承FTickableGameObject获得Tick功能</p><p>在完成世界内的分组tick后，会进行一次广播宣告世界内的Tick完成</p><pre><code>FWorldDelegates::OnWorldPostActorTick.Broadcast(this, TickType, DeltaSeconds);</code></pre><hr><h3 id="Level的分组tick之后"><a href="#Level的分组tick之后" class="headerlink" title="Level的分组tick之后"></a>Level的分组tick之后</h3><p>在进行完Level的分组之后会简单的进行两次广播来刷新网络</p><pre><code>BroadcastTickFlush(RealDeltaSeconds); BroadcastPostTickFlush(RealDeltaSeconds);</code></pre><p>引擎会尝试GC（看来GC也是每帧都有），更新FX特效系统</p><p>最后执行EndTickDrawEvent往渲染队列塞一个EndDrawEventCommand</p><p>这样便于渲染线程知道卡在这里边的指令都是Uworld::Tick的</p><hr><h2 id="Tickable-GameObjects-Without-World"><a href="#Tickable-GameObjects-Without-World" class="headerlink" title="Tickable GameObjects Without World"></a><strong>Tickable GameObjects Without World</strong></h2><p>前边tick Tickable的时候是Tick处于Uworld之内的，剩下的就会在这一步进行Tick</p><p>其实和Uworld内调用是同一个函数，只是参数Uworld设成了空指针</p><hr><h2 id="RedrawViewPort"><a href="#RedrawViewPort" class="headerlink" title="RedrawViewPort"></a>RedrawViewPort</h2><p>RedrawViewPort（只谈EngineTick里面的部分）在游戏线程也是大头，</p><p>（我们的大头其实就是UWorld::Tick,DrawViewPort,DrawSlate）</p><p>分为渲染场景和渲染UI的部分，渲染UI的部分只会渲染一些Debug的UI信息例如stat</p><p>游戏UI采用的Slate的Tick层级实际上是和UworldTick在同一层级的）</p><p>不过我想实际上Game线程中这部分的Tick耗时主要还是做的线程调度和计算</p><p>渲染线程做culling、batching和渲染API的生成，RHI线程做渲染API的执行</p><hr><p>首先进行GameViewport-&gt;Tick(DeltaSeconds)来tick，实际上是发送一个TickDelegate的广播</p><p>接着进入FViewport::Draw函数，进行一些截图数据的准备</p><p>准备完之后调用EnqueueBeginRenderFrame(bShouldPresent)</p><p>其中是ENQUEUE_RENDER_COMMAND(BeginDrawingCommand)发给渲染队列</p><p>接着调用ViewportClient-&gt;Draw(this, &amp;Canvas)进行场景相关的计算</p><p>Draw函数有许多的继承，游戏调用的实际上是UgameViewportClient::Draw</p><p><img src="/images/loading.jpg" data-original="/2022/05/10/Gengine.tick%E6%B5%81%E7%A8%8B/Users\apnaviyang\AppData\Roaming\Typora\typora-user-images\image-20220510104406541.png" alt="image-20220510104406541"></p><p>有一句重要的语句决定了我们走的是什么样的渲染管线，以及之后的渲染细节</p><pre><code>GetRendererModule().BeginRenderingViewFamily(SceneCanvas,&amp;ViewFamily);    &#123;...FSceneRenderer* SceneRenderer = FSceneRenderer::CreateSceneRenderer(ViewFamily, Canvas-&gt;GetHitProxyConsumer());...ENQUEUE_RENDER_COMMAND(FInitFXSystemCommand)...ENQUEUE_RENDER_COMMAND(FDrawSceneCommand)...&#125;</code></pre><p>这一句根据我们的ShadingPath决定走的是延迟渲染还是Mobile渲染（Mobile也可以做延迟渲染）</p><p>接着会将场景计算完成，打包成一个FDrawSceneCommand然后也发送给渲染线程</p><p>渲染场景的步骤完成后广播一次EndScene</p><p>跳出这一步后会把RT给clear掉然后继续渲染HUD，不过渲染与否居然是Slate决定的</p><pre><code>// Clear areas of the rendertarget (backbuffer) that aren&#39;t drawn over by the views....// Render the UIif (FSlateApplication::Get().GetPlatformApplication()-&gt;IsAllowedToRender())&#123;...&#125;</code></pre><p>做完这些以后做一个广播，然后根据是否开启垂直同步进行一个渲染队列的入队操作</p><pre><code>Canvas.Flush_GameThread();UGameViewportClient::OnViewportRendered().Broadcast(this);...SetRequiresVsync(bLockToVsync);EnqueueEndRenderFrame(bLockToVsync, bShouldPresent);</code></pre><p>做完RedrawViewports的操作之后会通知渲染线程TickRenderingTimer，实际上所做的更新RT池的操作</p><p>这些以上就是ReDrawViewports的大部分主要操作，同时也是一套UGameEngine::tick的基本流程</p><hr><p>全程的广播，函数嵌套，虚函数继承，多次往渲染队列添加命令让人感觉眼花缭乱</p><p>即使是大概看了一遍所有的流程依然还是觉得很晕，框架并没有像他的外层EngineLoop那么的简单明了</p><p>不过之后结合Render和RHI线程来理解再次加深分析应该还能再加深一点印象</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;这篇文章中间磨洋工磨了比较久，整体写的也不是很好&lt;/p&gt;
&lt;p&gt;主要是Uworld的更新涉及到太多的宏和函数跳转嵌套，给我整的麻麻的&lt;/p&gt;
&lt;p&gt;但好在最后还是弄清楚了最主要的tick流程是在做什么&lt;/p&gt;
&lt;p&gt;为接下来弄清楚RHI线程和Render线程做好铺垫&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>UE4中Game线程的最外层Tick</title>
    <link href="https://aprilnavi.github.io/2022/05/06/UE%E7%9A%84game%E7%BA%BF%E7%A8%8Btick%E6%B5%81%E7%A8%8B/"/>
    <id>https://aprilnavi.github.io/2022/05/06/UE%E7%9A%84game%E7%BA%BF%E7%A8%8Btick%E6%B5%81%E7%A8%8B/</id>
    <published>2022-05-06T13:36:58.000Z</published>
    <updated>2022-05-14T15:11:23.635Z</updated>
    
    <content type="html"><![CDATA[<p>在印象里面，这篇文章只用了两天时间就完成了</p><p>也就是在入职的第二天，在别人都还在配环境拉项目的时候</p><p>我已经速度拉满的根据profiler和源码弄懂了最外圈的引擎循环！</p><span id="more"></span><h1 id="FengineLoop-Tick"><a href="#FengineLoop-Tick" class="headerlink" title="FengineLoop::Tick"></a>FengineLoop::Tick</h1><p><strong>前言</strong></p><p>我们从启动入口launch.cpp中的流程来看</p><p>引擎在完成PreInitPreStartupScreen，PreInitPostStartupScreen，init</p><p>等一些初始化操作完成之后，便调用进入FengineLoop::Tick，这也是我们这次分析的主体</p><p>本次分析会以game线程所执行的流程来理解</p><p>由于UE的运行代码涉及到许多宏，插入性能测试，还有一些可能写了注释也看不懂的玩意</p><p>所以希望按图索骥先逐步摸清game线程中引擎所做的事情，而后再进一步分析game线程是怎么和渲染线程结合的</p><p>有些比较简单的流程会稍微深入查看1或者2层Depth看看他们的细节（具体怎么跑的，有什么需要注意的）</p><hr><h2 id="总体流程"><a href="#总体流程" class="headerlink" title="总体流程"></a>总体流程</h2><p>GameThread是引擎运行的心脏，承载游戏逻辑、运行流程的职责</p><p>在FEngineLoop::Tick函数执行每帧逻辑的更新</p><p>宏观来看，GameThread的流程包括以下部分</p><p><strong>WaitFPS</strong>：</p><p>如果上一帧没有达到<strong>最小的MaxFPS所需的时间</strong>（这里理解最大帧率也就是最小帧耗时没有达到最小帧耗时就是这一帧处理的太快了）</p><p>会在此处进行Sleep让这一帧耗时更久点（可能是为了更新尽可能稳定，同时也方便其他线程和GameThread通信）</p><p>PS：Stat显示的FrameTIme其实是下一帧WaitFPS结束减去这一帧的WaitFPS结束</p><p>因为其实把WaitFPS连在结尾更符合直觉，Stat也是这么算的</p><p><strong>SlateInput：</strong></p><p><strong>Slate</strong> UE4自带的自定义与平台无关的用UI框架</p><p>SlateInput阶段主要用于接收slate收到的鼠标键盘输入</p><p><strong>EngineTick：</strong></p><p>EngineTick是整个引擎流程Tick的主体，也是主要的耗时部分</p><p>其中的UWorld::Tick以每个level为单位进行分组方式</p><p>调用actor ticking，timer ticking ，tickable三种tick框架</p><p><strong>SlateTick：</strong></p><p>对Slate利用先前已经处理好的input进行Tick</p><p>这也是一个FengineLoop单位里面比较耗时的部分</p><p><strong>FrameSync：</strong></p><p>FrameSync一个loop里面进行的第二次的等待</p><p>意在完成render线程和game线程的同步，即使他们有一帧之差</p><p>在SlateTick完成之后会进行一个渲染命令的调用，之后会等待上一帧的render线程跑完</p><p>但因为game线程本来就比render线程要快一帧，所以基本上这里不怎么需要等待</p><p>如果这里还耗时了就说明render线程跑的不理想，存在瓶颈</p><p><strong>DeferredTickTime</strong></p><p>DeferredTickTime是一次loop的最后阶段，这个阶段以Fticker::tick为主体</p><p>同时也执行TickDeferredCommands，即为所有当前排队的延迟命令</p><p>Fticker::tick做了什么还不清楚，如何理解延迟命令还有哪些命令会排队也是暂未理解的</p><hr><h2 id="WaitFPS"><a href="#WaitFPS" class="headerlink" title="WaitFPS"></a>WaitFPS</h2><p>在收起一些宏（我认为是做引擎的运行状态检查，平台检查，性能测试）之后</p><p>框架大概如下</p><pre><code>void FengineLoop::Tick()&#123;...        FCoreDelegates::OnBeginFrame.Broadcast();...        // exit if frame limit is reached in benchmark mode, or if time limit is reached        if ((FApp::IsBenchmarking() &amp;&amp; MaxFrameCounter &amp;&amp; (GFrameCounter &gt; MaxFrameCounter)) ||            (MaxTickTime &amp;&amp; (TotalTickTime &gt; MaxTickTime)))        &#123;            FPlatformMisc::RequestExit(0);        &#125;        // set FApp::CurrentTime, FApp::DeltaTime and potentially wait to enforce max tick rate        &#123;            QUICK_SCOPE_CYCLE_COUNTER(STAT_FEngineLoop_UpdateTimeAndHandleMaxTickRate);            GEngine-&gt;UpdateTimeAndHandleMaxTickRate();            GEngine-&gt;SetSimulationLatencyMarkerStart(CurrentFrameCounter);        &#125;                ....                // beginning of RHI frame        ENQUEUE_RENDER_COMMAND(BeginFrame)([CurrentFrameCounter](FRHICommandListImmediate&amp; RHICmdList)        &#123;            BeginFrameRenderThread(RHICmdList, CurrentFrameCounter);        &#125;);                ....                    FStats::AdvanceFrame( false, FStats::FOnAdvanceRenderingThreadStats::CreateStatic( &amp;AdvanceRenderingThreadStatsGT ) );                    bool bIdleMode;        &#123;            QUICK_SCOPE_CYCLE_COUNTER(STAT_FEngineLoop_Idle);            // Idle mode prevents ticking and rendering completely            bIdleMode = ShouldUseIdleMode();            if (bIdleMode)            &#123;                // Yield CPU time                FPlatformProcess::Sleep(.1f);            &#125;        &#125;                            &#125;</code></pre><p>我认为的WaitFPS从<code> FCoreDelegates::OnBeginFrame.Broadcast()</code>开始的</p><p>一开始是这点没有什么疑惑，随后去找Sleep操作发生在哪里</p><p>第一眼看见的是FPlatformProcess::Sleep(.1f)，但是发生他在FStats::AdvanceFrame这一标志之后</p><p>也发生在提交BeginFrame的提交渲染命令之后，所以应该不是这句</p><p>随后把注意力锁到了中间的两段语句上</p><pre><code>if ((FApp::IsBenchmarking() &amp;&amp; MaxFrameCounter&amp;&amp; (GFrameCounter &gt; MaxFrameCounter)) ||(MaxTickTime &amp;&amp; (TotalTickTime &gt; MaxTickTime)))&#123;FPlatformMisc::RequestExit(0);&#125;</code></pre><p>这说的应该是当实际的TotalTickTime达到了所能容忍的MaxTickTime</p><p>应该请求退出（稍微看了一下这个exit好像是直接退出引擎而非跳过此次循环）</p><p>接着是这一段：</p><pre><code>        // set FApp::CurrentTime, FApp::DeltaTime and potentially wait to enforce max tick rate        &#123;            QUICK_SCOPE_CYCLE_COUNTER(STAT_FEngineLoop_UpdateTimeAndHandleMaxTickRate);            GEngine-&gt;UpdateTimeAndHandleMaxTickRate();            GEngine-&gt;SetSimulationLatencyMarkerStart(CurrentFrameCounter);        &#125;</code></pre><p>按注释所言这里可能会等待执行的Max tick rate，和我们的MaxFPS应该是同一个东西</p><p>Sleep的操作应该是在<code>GEngine-&gt;UpdateTimeAndHandleMaxTickRate();</code>中完成了</p><p>随后就是以RHICmdList, CurrentFrameCounter发送渲染命令RenderCmd_BeginFrame</p><p>还有FStats::AdvanceFrame将前进的这一帧（我理解这里的Advance是推进，前进）加入到统计数据里面来</p><p>这样WaitFPS的部分就完成了，进入SlateInput的部分。</p><hr><h2 id="Slate-Input"><a href="#Slate-Input" class="headerlink" title="Slate Input"></a>Slate Input</h2><p>整段收集Slate input的代码数量比较少</p><pre><code>        // process accumulated Slate input        if (FSlateApplication::IsInitialized() &amp;&amp; !bIdleMode)        &#123;            CSV_SCOPED_TIMING_STAT_EXCLUSIVE(Input);            SCOPE_TIME_GUARD(TEXT(&quot;SlateInput&quot;));            QUICK_SCOPE_CYCLE_COUNTER(STAT_FEngineLoop_Tick_SlateInput);            LLM_SCOPE(ELLMTag::UI);            FSlateApplication&amp; SlateApp = FSlateApplication::Get();            &#123;                QUICK_SCOPE_CYCLE_COUNTER(STAT_FEngineLoop_Tick_PollGameDeviceState);                SlateApp.PollGameDeviceState();            &#125;            // Gives widgets a chance to process any accumulated input            &#123;                QUICK_SCOPE_CYCLE_COUNTER(STAT_FEngineLoop_Tick_FinishedInputThisFrame);                SlateApp.FinishedInputThisFrame();            &#125;        &#125;</code></pre><p>首先是确认Slate是否初始化完成，且引擎不在Idle模式</p><p>暂时还不清楚这个idle模式是什么含义，但起码能清楚在这里我们不希望引擎是idle模式的</p><p>然后我们get到一个SlateApp，查询游戏设备的状态，</p><p>做完这步就结束这一帧的所有Slateinput储存起来</p><p>这一步也可能将之前累积的输入也一并进行处理</p><hr><h2 id="Engine-Tick"><a href="#Engine-Tick" class="headerlink" title="Engine Tick"></a>Engine Tick</h2><pre><code>GEngine-&gt;Tick(FApp::GetDeltaTime(), bIdleMode);</code></pre><p>在一个Loop里面关于EngineTick的调用就这一行，也就是UGameEngine::Tick</p><p>但这一句调用的内部是十分复杂的，做了很多事情，所有gameplay相关的元素都在里面进行tick</p><p>所以计划之后再分析这个EngineTick的流程</p><hr><h2 id="Slate-Tick"><a href="#Slate-Tick" class="headerlink" title="Slate Tick"></a>Slate Tick</h2><p>在insight中看，Slate Tick分为Slate::Tick (Platform and Input)和Slate::Tick (Time and Widgets)</p><pre><code>FengineLoop::Tick()&#123;        ...           // Tick the platform and input portion of Slate application, we need to do this before we run things        // concurrent with networking.        if (FSlateApplication::IsInitialized() &amp;&amp; !bIdleMode)        &#123;            &#123;                QUICK_SCOPE_CYCLE_COUNTER(STAT_FEngineLoop_ProcessPlayerControllersSlateOperations);                check(!IsRunningDedicatedServer());                // Process slate operations accumulated in the world ticks.                ProcessLocalPlayerSlateOperations();            &#125;            FSlateApplication::Get().Tick(ESlateTickType::PlatformAndInput);        &#125;                ...                // Tick(Advance) Time for the application and then tick and paint slate application widgets.        // We split separate this action from the one above to permit running network replication concurrent with slate widget ticking and painting.        if (FSlateApplication::IsInitialized() &amp;&amp; !bIdleMode)        &#123;            FSlateApplication::Get().Tick(ESlateTickType::TimeAndWidgets);        &#125;&#125;</code></pre><p>两部分Tick的中间的涉及到一些有关处理slate task并发的宏，还是以关注两部分的slate tick流程为主先将宏收起来</p><p>在聊聊tick这两部分的处理之前可以先看看Slate::Tick里面：</p><p>首先在FSlateApplication中有这样一句话：它（指slate::tick）在除了game thread之外的线程是无效的，除非我们只是更新时间</p><p>在insight里面确实如此，slate相关的task没有分到除了game线程之外的任何线程。</p><p>其次是不要在tick中不同的if-语句中添加代码，如果需要添加功能请添加在TickPlatform里面</p><hr><p>Slate的Tick第一部分tick了平台和输入，跳转到了FSlateApplication::TickPlatform中</p><p>在这个函数中我理解的是将之前收集的input，转化为了消息然后pump出去</p><p>会计算一个bSynthesizedCursorMove（是否同步光标移动的值），这在下一部分的Tick将派上用场</p><p>然后会在所有user上GenerateGestures生成一个我们探测到的模拟姿态（还不理解做什么用）</p><p>这一部分主要是为下一步的draw slate的流程做准备，所以在流程图里面被称为PrePass（预先阶段）</p><hr><p>Slate的Tick第二部分tick了时间和控件，TimeAndWidgets实际上在UE定义的枚举里面是包含了Time和Widgets的</p><p>所以将执行FSlateApplication::TickTime()和FSlateApplication::TickAndDrawWidgets(float DeltaTime)</p><p>TickTime里面的源码逻辑很简单</p><pre><code>void FSlateApplication::TickTime()&#123;    LastTickTime = CurrentTime;    CurrentTime = FPlatformTime::Seconds();    // Handle large quantums    const double MaxQuantumBeforeClamp = 1.0 / 8.0;        // 8 FPS    if (GetDeltaTime() &gt; MaxQuantumBeforeClamp)    &#123;        LastTickTime = CurrentTime - MaxQuantumBeforeClamp;    &#125;&#125;</code></pre><p>GetDeltaTime()会计算一个真实的更新时间DeltaTime</p><p>如果超过了最大限制1/ 8秒会将LastTickTime减去1/ 8秒</p><hr><p>从TickAndDrawWidgets的名字就能看出函数做的不仅仅是DrawWidget，也承担了一部分tick的职责</p><p>从后文来看，我们tick了一个一些时间用于后续计算，最主要的是tick了slate的通知（FSlateNotificationManager::Get().Tick()）</p><p>函数内先是Renderer-&gt;ReleaseAccessedResources(/* Flush State */ false)</p><p>释放我们可能缓存和报告的任何临时材质或纹理资源，然后报告防止这些资源被GC，释放最后一帧使用的队列</p><p>然后FSlateInvalidationRoot::ClearAllWidgetUpdatesPending()清除所有上一帧挂起的更新</p><p>看得出来在Draw控件的时候是急需资源来进行渲染的。</p><p>接着一段比较复杂的计算平均更新时间的逻辑，具体实现看的不是很明白：</p><pre><code>    // Update average time between ticks.  This is used to monitor how responsive the application &quot;feels&quot;.    // Note that we calculate this before we apply the max quantum clamping below, because we want to store    // the actual frame rate, even if it is very low.    &#123;        const float RunningAverageScale = 0.1f;        AverageDeltaTime = AverageDeltaTime * ( 1.0f - RunningAverageScale ) + GetDeltaTime() * RunningAverageScale;        if( FSlateThrottleManager::Get().IsAllowingExpensiveTasks() )        &#123;            // Clamp to avoid including huge hitchy frames in our average            const float ClampedDeltaTime = FMath::Clamp( GetDeltaTime(), 0.0f, 1.0f );            AverageDeltaTimeForResponsiveness = AverageDeltaTimeForResponsiveness * ( 1.0f - RunningAverageScale ) + ClampedDeltaTime * RunningAverageScale;        &#125;    &#125;</code></pre><p>但根据注释所言，最后计算出来的是一个真实的平均时间间隔，用于反应UI程序的感受和反应</p><p>这个值并不是为我们接下来渲染widget的流程服务的</p><p>它用于反应帧率是否在我们所理想的状态（FSlateApplication::IsRunningAtTargetFrameRate()）</p><hr><p>接着就是draw widget的部分，先是根据我们在外部上层计算得到的LastTickTime</p><p>计算了两个bool值bIsUserIdle和bAnyActiveTimersPending（是否闲置，是否有活跃的timer在等待）</p><p>来决定在下文是否要跳过我们的draw widget ：</p><pre><code>        const float SleepThreshold = SleepBufferPostInput.GetValueOnGameThread();        const double TimeSinceInput = LastTickTime - LastUserInteractionTime;        const double TimeSinceMouseMove = LastTickTime - LastMouseMoveTime;            const bool bIsUserIdle = (TimeSinceInput &gt; SleepThreshold) &amp;&amp; (TimeSinceMouseMove &gt; SleepThreshold);        const bool bAnyActiveTimersPending = AnyActiveTimersArePending();</code></pre><p>这就很符合直觉，毕竟假如用户没有做任何事情（Idle），那么这个Slate不刷新也是完全合理的</p><p>如果一直执行下去（没有sleep），则最后DrawWindows（）更新所有的窗口</p><hr><h2 id="GetPendingCleanupObjects"><a href="#GetPendingCleanupObjects" class="headerlink" title="GetPendingCleanupObjects"></a>GetPendingCleanupObjects</h2><p>首先我并没有直接看到同步的代码，而是看到了GetPendingCleanupObjects的操作</p><pre><code>        // Find the objects which need to be cleaned up the next frame.        FPendingCleanupObjects* PreviousPendingCleanupObjects = PendingCleanupObjects;        PendingCleanupObjects = GetPendingCleanupObjects();</code></pre><p>注释所言这段是用于获取下一帧用来清理的对象，也就是说这部分的GC是在每一帧都进行的</p><p>每帧获取当前的PendingCleanupObjects准备delete（其实感觉很少在ue里面看见原生的delete）</p><p>然后用GetPendingCleanupObjects将PendingCleanupObjects更新</p><p>点进函数里面看发现这部分是从render线程拿来的东西</p><p>准备被Delete的部分会在最后的tick ticker部分中被delete掉</p><h2 id="Frame-Sync"><a href="#Frame-Sync" class="headerlink" title="Frame Sync"></a>Frame Sync</h2><p>看着这个部分名字望文生义感觉像帧同步（其实根本不是网络那个帧同步）</p><p>但实际上是等待上一帧的render线程执行完成game线程才往下走（也就是渲染指令提交完毕之后）</p><p>因为在UE中允许Game线程比Render线程执行快一帧（也有可能是两帧）</p><p>这样就确保Render拿到的数据是完完全全计算好的了数据，Render线程可以尽情的自由发挥</p><p>（即使是这样做，很多项目的瓶颈也还是在Render上面）</p><p>这部分的代码构造也很简单：</p><pre><code>        &#123;            SCOPE_CYCLE_COUNTER(STAT_FrameSyncTime);            // this could be perhaps moved down to get greater parallelism            // Sync game and render thread. Either total sync or allowing one frame lag.            static FFrameEndSync FrameEndSync;            static auto CVarAllowOneFrameThreadLag =             IConsoleManager::Get().FindTConsoleVariableDataInt(TEXT(&quot;r.OneFrameThreadLag&quot;));             FrameEndSync.Sync( CVarAllowOneFrameThreadLag-&gt;GetValueOnGameThread() != 0 );        &#125;</code></pre><p>所做的是同步Game和Render线程，要么完全同步要么有一帧之差</p><p>通过x函数拿到某个数作为Sync的参数，真正做同步操作的也是FrameEndSync.Sync这一步</p><p>一般来说波动小的情况下，Game线程不用在这里花太多时间等待render线程，除非Render线程的瓶颈太严重了</p><hr><h2 id="Deferred-Tick-Time"><a href="#Deferred-Tick-Time" class="headerlink" title="Deferred Tick Time"></a>Deferred Tick Time</h2><p>这个流程是以FengineLoop为单位的循环中的最后一步流程</p><p>在这个流程中我们tick core ticker，threads，还有一些DeferredCommands</p><p>首先的当务之急是先在前一帧之前排队等待延迟清理的对象：</p><pre><code>delete PreviousPendingCleanupObjects;</code></pre><p>紧接着是三行关键代码分别对应core ticker，threads，DeferredCommands：</p><pre><code>FTicker::GetCoreTicker().Tick(FApp::GetDeltaTime());FThreadManager::Get().Tick();GEngine-&gt;TickDeferredCommands();</code></pre><hr><p>我最关心的是CoreTicker所指的是什么，而FTicker::Tick又做了什么事情</p><pre><code>void FTicker::Tick(float DeltaTime)&#123;    ....        if (!Elements.Num())    &#123;        return;    &#125;    // make sure we scope the &quot;InTick&quot; state    TGuardValue&lt;bool&gt; TickGuard(bInTick, true);    CurrentTime += DeltaTime;    while (Elements.Num())    &#123;                if (Elements.Last().FireTime &gt; CurrentTime)        &#123;            TickedElements.Add(Elements.Pop(false));        &#125;        else        &#123;            CurrentElement = Elements.Pop(false);            bCurrentElementRemoved = false;            bool bRemoveElement = !CurrentElement.Fire(DeltaTime);            if (!bRemoveElement &amp;&amp; !bCurrentElementRemoved)            &#123;                CurrentElement.FireTime = CurrentTime + CurrentElement.DelayTime;                TickedElements.Push(CurrentElement);            &#125;        &#125;    &#125;    Exchange(TickedElements, Elements);    CurrentElement.Delegate.Unbind();&#125;</code></pre><p>首先是检查属性Elements的数量，为空则直接跳过这次tick</p><p>我们发现Elements实际上是个以FElement和TInlineAllocator&lt;1&gt;为索引的二维数组</p><p>指的是未来将被fire（销毁，解雇，炒鱿鱼）的委托</p><p>接着往下看到<code>while(Elements.Num())</code>就知道整个FTicker::Tick都在做与委托相关的事情</p><p>我们会遍历整个Elements数组，挨个将数组内的元素弹出并跟踪他们确保他们的安全更新</p><p>在遍历完成之后会交换Elements和TickedElements，当tick完成时清除CurrentElement委托</p><p>这样一来我明白FTicker::Tick实际上就是用来fire（理解成解雇还挺不错的）所有延迟的委托的</p><p>虽然我此时也还并不是很清楚这么做的目的是什么</p><hr><p>接着是FThreadManager::Tick()，根据他声明和定义中的注释</p><p>猜测这一步做的是tick所有的fake线程还有运行在他们之上的对象</p><hr><p>实际上DeferredCommands是一个Fstring类型的数组，其中的元素一一对应着真正的Commands</p><p>通过ULocalPlayer::Exec( LocalPlayer-&gt;GetWorld(), *DeferredCommands[DeferredCommandsIndex], *GLog )</p><p>来将DeferredCommands一一执行，但哪些命令会在tick里面被延迟也还不清楚</p><hr><p>完成所有流程后，我会广播FCoreDelegates::OnEndFrame.Broadcast()和调用EndFrame的RenderCmd</p><p>然后计算一下CPU的使用情况<code>const FCPUTime CPUTime = FPlatformTime::GetCPUTime();</code></p><p>如果有加入性能分析的代码例如Trace框架，也会在这里打个桩告知Profiler以此为单位结束一个FengineLoop</p><p>这样一来一个单位的FengineLoop流程就走完了，虽有些细节还不了解是怎么做的为什么这么做</p><p>但大体的流程已经摸的差不多了，之后会深入的看下以Gengine和Uworld为单位的tick</p><p>也了解下整个tick的框架和actor的分组tick是怎么联系的</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在印象里面，这篇文章只用了两天时间就完成了&lt;/p&gt;
&lt;p&gt;也就是在入职的第二天，在别人都还在配环境拉项目的时候&lt;/p&gt;
&lt;p&gt;我已经速度拉满的根据profiler和源码弄懂了最外圈的引擎循环！&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>UE4 Gameplay功能小笔记</title>
    <link href="https://aprilnavi.github.io/2022/04/21/UE4%E5%8A%9F%E8%83%BD%E5%B0%8F%E7%AC%94%E8%AE%B0/"/>
    <id>https://aprilnavi.github.io/2022/04/21/UE4%E5%8A%9F%E8%83%BD%E5%B0%8F%E7%AC%94%E8%AE%B0/</id>
    <published>2022-04-21T11:00:58.000Z</published>
    <updated>2022-04-20T17:40:36.085Z</updated>
    
    <content type="html"><![CDATA[<p>test test</p><span id="more"></span><h2 id="转换版本"><a href="#转换版本" class="headerlink" title="转换版本"></a>转换版本</h2><p>对着uproject右键Switch</p><hr><h2 id="添加粒子效果和音效"><a href="#添加粒子效果和音效" class="headerlink" title="添加粒子效果和音效"></a>添加粒子效果和音效</h2><p>UParticleSystem* Explosion；</p><p>UsoundBase* soundBase</p><hr><h2 id="UGamePlayStatic常见api："><a href="#UGamePlayStatic常见api：" class="headerlink" title="UGamePlayStatic常见api："></a>UGamePlayStatic常见api：</h2><p>PlaySound2D，SpawnEmitterAtLocation，GetAllActorsOfClass</p><hr><h2 id="联网相关"><a href="#联网相关" class="headerlink" title="联网相关"></a>联网相关</h2><p>GetWorld()-&gt;GetAuthGameMode()：只在服务端调用有用</p><hr><h2 id="UMG相关"><a href="#UMG相关" class="headerlink" title="UMG相关"></a>UMG相关</h2><ol><li>生成时公开，可编辑实例，可以让widget在生成时将外界的值传入，然后根据这个值来确定返回什么（好用！）</li><li>Widget也可以将文本设为is variable，然后创一个函数（如update text）之类的，供外界使用，其他蓝图就可以在创建后变更它的值</li><li>引用角色身上的那个widget要先get然后再连get user widget object</li></ol><hr><h2 id="做功能相关"><a href="#做功能相关" class="headerlink" title="做功能相关"></a>做功能相关</h2><pre><code>UPROPERTY(EditInstanceOnly,Category=&quot;AI&quot;)bool bIsPatrol;UPROPERTY(EditInstanceOnly,BlueprintReadWrite,meta=(EditCondition=&quot;IsPatroling&quot;),Category=&quot;AI&quot;)TArray&lt;AActor*&gt; PatrolPoints;</code></pre><p>蓝图：</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;test test&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Games202 Lecture5 (Environment Mapping)</title>
    <link href="https://aprilnavi.github.io/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/"/>
    <id>https://aprilnavi.github.io/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/</id>
    <published>2022-04-14T02:06:58.000Z</published>
    <updated>2022-04-14T20:37:58.983Z</updated>
    
    <content type="html"><![CDATA[<p>一个月前的21日我写完了pcss的作业，满怀信心的直接猛冲第五节课</p><p>随后发现自己对于pbr理论还有brdf的理解已经忘光光了，听这节课就像听天书</p><p>于是用了半个多月补了pbr的理论，做了一个pbr的渲染器和一个ibl的场景</p><p>这次轮到我拿下202的ibl啦</p><span id="more"></span><h1 id="Distance-field-soft-shadow-and-SDF"><a href="#Distance-field-soft-shadow-and-SDF" class="headerlink" title="Distance field soft shadow and SDF"></a>Distance field soft shadow and SDF</h1><p>DFS有很不错的效率，速度比传统的shadow map要快，也没有SM中<strong>自遮挡和悬浮</strong>的问题</p><p>因为它的实现完全不同于之前提到的shadow map。但是no free lunch，缺点是需要大<strong>量的存储</strong>。</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220414171957924.png" alt="image-20220414171957924"></p><p>效果比对如上，DFS看起来是相当棒的</p><hr><p>这里的SDF指的是某个点到达物体表面的<strong>最短距离</strong></p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220414175724579.png" alt="image-20220414175724579"></p><p>如图所示上图是直接将颜色进行插值的结果，但我们并不想要这种结果，我想要得到一个在中间的边界</p><p>因此我们就获取两个图像的SDF，并将其进行插值，最后就能得到我们所需要的中间的边界，同时这也能反应阴影的移动</p><p>SDF的好处是可以表示好物体的边界，可以做<strong>任意形状的Blending</strong></p><hr><p><strong>SDF Usage 1 RAY Marching</strong>（sphere tracing）</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220414180250039.png" alt="image-20220414180250039"></p><p>已知整个场景的sdf，在任意一点我都可以算出一个<strong>安全距离</strong>（就例如光标的那一点）</p><p>因为那一点的sdf指的是到达场景内最近的物体的距离，因此我们就可以得出一个安全距离</p><p>在这个安全距离之内不会有其他的任何物体存在（碰不到任何物体）</p><p>假如我们有这么一根光线，我们就可以让光线每次按着他的安全距离前进，然后每次再重新前进新的安全距离</p><p>直到我已经trace了很远的距离或者sdf已经小到了某种程度</p><p>SDF若要在三维场景生成，则需要比较大的存储（毕竟空间中每个点都要储存一个sdf）</p><p>SDF可以比较好的支持<strong>运动的刚体</strong>（得是刚体哦，这也是sdf的好处），但是对于<strong>形变的物体</strong>得重新生成sdf</p><hr><p><strong>SDF Usage 2 Soft Shadow</strong></p><p>这样生成的软阴影实际上是不准的，但是效果是不错的看上去也不违和</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220414182509470.png" alt="image-20220414182509470"></p><p>我们把之前所说的没一点的安全距离往前推一步，得到一个<strong>安全角度</strong></p><p>这个安全角度越小，则意味着能看到的东西越少，那么这个点的阴影就该<strong>越黑</strong></p><p>（我们可以想象如果这个点安全角度很大，这意味着我们看光源基本上没什么遮挡，可见性接近1）</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220414183056119.png" alt="image-20220414183056119"></p><p>那么我们怎么求这个点的安全角度呢，我们可以用ray Marching的方法求出每步的安全距离和安全角度</p><p>去其中安全角度的最小值就是我们最终所需要的安全角度，按照这个安全角度我们转化成阴影的软硬程度</p><p>但其中所需要用到arcsin是我们希望尽量避免的（计算量大），因此有大佬优化了这个计算（其中p-o是长度）</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220414184129846.png" alt="image-20220414184129846"></p><p>完全可以用sdf的值除以走过的距离，这样依然可以表示这个安全角度的大小，而不需要求出准确的角度</p><p>然后我们乘以一个系数k，再和1做一个min（因为我们不希望visibility超过1）</p><p>这个k反应了最终visibility对于安全距离的<strong>敏感程度</strong>，<strong>k越大则最后越敏感</strong></p><p>若k为100，为了保证最终区间为（0,1），sdf/p-o的区间就为（0,0.01），则0.01的变化都能引起visibility从0到1</p><p>0.01的变化都能改变visibility的0和1，则证明最后的阴影是特别硬的</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220414200759280.png" alt="image-20220414200759280"></p><p>sdf场最后的表现就像是描绘了物体的表面（实际上也确实如此，毕竟sdf描述了和物体表面的距离）</p><hr><p>总结一下用sdf生成的dfs的优缺点吧（有那么些绕了）</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220415012626846.png" alt="image-20220415012626846"></p><p><strong>优点：</strong>用sdf生成的dfs阴影对比传统的shadow map是<strong>高质量且快速的</strong></p><p>但这种比较是不公平的，因为没有算入sdf生成的时间（我们都是假设sdf已知）</p><p><strong>缺点：</strong>需要<strong>预计算（生成sdf）</strong>，sdf需要<strong>大量的储存空间</strong>，存在<strong>走样（锯齿）问题</strong></p><p>为了解决sdf的存储问题，会用到一些空间划分的hierarchy数据结构，比如八叉树kd树，离场景中物体都很远的点自然就不需要存sdf</p><hr><p>这里闫神说的很好：实时渲染渲染从头到尾都是近似</p><p>但这些近似不会牺牲很大的质量，同时做的也很聪明，这才是我们要学习的东西</p><hr><h1 id="Shading-from-Environment-lighting"><a href="#Shading-from-Environment-lighting" class="headerlink" title="Shading from Environment lighting"></a>Shading from Environment lighting</h1><p>核心思想是用环境贴图（spherical map，cube map）来记录场景中往任意方向看所看到的的光照</p><p>这意味着所有光照都是无限远的（记得我们之前所说的pbr需要遵循基于物理的光照吗，这里就没那么pbr了）</p><p>根据我的图像来取得各个方向上光照的渲染，工业界上称为<strong>IBL（Image Based Lighting）</strong></p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220415014616688.png" alt="image-20220415014616688"></p><p>我要算一个点的Shading相当于就是算这个点的Lo了，理所当然是的要解渲染方程</p><p>render equation定义内，积分指的是正半球内的所有光照（即和shading point处normal点乘结果大于0的）    </p><p>所以我要根据<strong>图像上给的irradiance</strong>，对于p点正半球内的所有光照，最后<strong>到达我眼睛（Wo也就是出射方向）的radiance</strong>是什么样的</p><p>对于求解积分，我们常用的一个通用解法就是<strong>蒙特卡洛积分</strong>还有<strong>重要性采样</strong>（之前第一次听这节课讲到这里已经懵了）</p><p>这里得好好说明一下，<strong>蒙特卡洛积分就是用来求解积分用的思想，是以高效的离散方式对连续的积分求近似</strong></p><p>我当然不可能采样大量的样本数据来计算，最后来使得结果收敛近正确的值，所以我还需要一种采样方式</p><p><strong>重要性采样是我拿离散数的方式</strong>，指的是不改变统计量，只改变概率分布，可以用来降低方差，是蒙特卡洛积分的一种采样策略</p><p>但可以的话我还是希望可以避免采样，所以我们会先从避免采样的出发点来延伸</p><hr><p>我们首先搬出之前所说的近似方案：</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220415022231722.png" alt="image-20220415022231722"></p><p>还记得这个公式什么时候准确吗？答案是在<strong>g（x）的support比较小</strong>或者<strong>g的值比较smooth</strong>的情况下</p><p>BRDF的式子很满足这个性质，因此我们就有了Split Sum大法</p><hr><h2 id="Pre-filtering-Lighting"><a href="#Pre-filtering-Lighting" class="headerlink" title="Pre-filtering Lighting"></a>Pre-filtering Lighting</h2><p>第一步因此我们可以做一个拆分，我们把光照的那一项拿出来：</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220415022538992.png" alt="image-20220415022538992"></p><p>你可能听说过Epic Games的分割求和近似法，将镜面反射积分拆成两个独立的积分，说的就是这个Split Sum</p><p>我们先看前面那一项，实际上我们是将一个区域的所有光照积分起来，然后再做一个normalize</p><p>求和然后再除以某个数进行normalize，这样求平均的操作你能想到什么呢？没错，那就是filter，卷积！</p><p>也就是我需要将ibl的这张图进行模糊（每个点上取周围的一个范围取一个平均然后再写回这个点）</p><p>因此将light项拆出来这一步本身就定义了模糊的操作，我们称之为生成/预计算<strong>预滤波环境贴图</strong>（irradianceMap）</p><p>（课程里面没有提到这个说法，这个说法是笔者在learnOpenGL中看到的）</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220415024250764.png" alt="image-20220415024250764"></p><p>我们可以提前预计算几张不同尺寸的做好模糊的图，等到需要时我再去取</p><p>比如说我想要一个半径为x的卷积，我需要在哪张图去取呢？这个时候我们就会想起mipmap的概念</p><p>即生成几张不同filter大小的图，要查询时再做三线性插值</p><p>其实最后计算时我需要多大的filter取决于微表面模型用到的一个参数粗糙度</p><p>因为<strong>随着粗糙度的增加，参与环境贴图卷积的采样向量会更分散，导致反射更模糊（微表面模型理论）</strong></p><p>最后我们对于卷积的每个粗糙度级别，我们将按顺序把模糊后的结果存储在预滤波贴图的 mipmap 中</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220415025145837.png" alt="image-20220415025145837"></p><p>左边的图表示我从某个i方向看一个点，最终反射出去的是一个<strong>lobe（波瓣）</strong>区域，我根据材质的glossy roughness分布一些采样点</p><p>我想取最终的结果，相当于对这个波瓣内的这些采样点做一个平均，然后最后得到我shading point的值</p><p>而我也可以直接对于environment lighting直接都做好一个filter，在我镜面反射的那个方向取一个准确的值，最终效果是差不多的</p><p>有这么个预计算的过程，我就可以在shading的时候直接采样所需要的值，<strong>结果合理同时取值也是很效率的√</strong></p><p>多提一些课程没提到的内容，<strong>随着粗糙度的增加，lobe的大小增加；随着入射光方向不同，lobe形状会发生变化。</strong></p><p>大多数光线最终反射到一个基于半程向量向量的lobe内大部分其余的向量都被浪费掉了</p><p>采样时尽量以lobe方向选取采样向量是有意义的，这个过程称为重要性采样。</p><hr><h2 id="Pre-filtering-BRDF"><a href="#Pre-filtering-BRDF" class="headerlink" title="Pre-filtering BRDF"></a>Pre-filtering BRDF</h2><p>我们前面算完了光照的那一项，成功的避免了大量的采样，接下来我们来看看BRDF项该怎么解决</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220415030411332.png" alt="image-20220415030411332"></p><p>这里我们的思想和第一步类似，我们也预生成一个类似的什么东西，但这里的预计算会麻烦一点</p><p>因为我需要考虑所有的参数所有的可能性，假如我们引入微表面的BRDF（带有菲涅尔项和NDF项）</p><p>（之前我写微表面的时候总是下意识的写成pbr，后边改过来了因为实际上微表面是pbr的前提而并非pbr）</p><p>菲涅尔项决定了物体的基础反射率（F0）和随着不同角度反射的颜色各不相同</p><p>NDF决定了微表面的不同法线分布（可以理解成是和roughness相关的一维函数）</p><p>这样一来我们的参数有F0（菲涅尔项），roughness，Wo等变量，想做预计算几乎是不可能的，因此我们还得将式子继续简化</p><p>接下来比较高能不太好理解：</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220415034221825.png" alt="image-20220415034221825"></p><p>我们根据Schlick公式将<strong>菲涅尔项</strong>替换成右边的R0巴拉巴拉巴拉，R0指的是<strong>基础反射率</strong>（也就是平常说的F0）</p><p>而Rθ指的是θ角时的菲涅尔项，在图形学中<strong>角度（入射，出射，半角）</strong>是很容易替换的概念</p><p>你可以看看右上角那张图观察一下他们的相似程度，</p><p>别问公式为什么这样为什么能这样替换，再不行的话直接嗯记能这样子替就是了</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220415035919603.png" alt="image-20220415035919603"></p><p>我们可以把菲涅尔项单独拆出来，然后用一些简单的数学原理（其实左右相加最后还是等于菲涅尔项，看不懂的话底下有一个更简单的推导）</p><p>最后这么一来我成功的将基础反射率（F0啦R0啦）拆到了积分的外面来，F0一般是一个常数，这样积分就不依赖他了</p><p>此时cook torrance式子里边的F已经消去了，brdf里面只剩下D和G，而他们都只依赖roughness和cosθ</p><p>也就是说此时我们现在剩下的参数cosθ和roughness，此时我们可以对 BRDF 方程求卷积，将其结果打印在一张表内</p><p>以cosθ和roughness为坐标轴（也就是我查询的输入）来打印出一张表（纹理），这和之前的卷积环境贴图类似</p><p>这种纹理称之为 2D 查找纹理（Look Up Texture, LUT），这张纹理被称为 BRDF 积分贴图</p><p>稍后我们会将其用于光照着色器中，以获得间接镜面反射的最终卷积结果</p><p>（如何用cosθ和roughness生成最终的卷积结果，也涉及到重要性采样，在202中没有提及）</p><p>这一步完成之后，我们同样通过预计算的方式避免了大量的采样</p><p>（因为没有用到采样大量数据，因此也没有噪声，得出来的结果还相当的不错，可能这就是为什么unreal的pbr做的这么叼了）</p><p>也可以看这个learnOpenGL中给出的具体推导过程（虽然更简短但是我感觉其实看着很易懂而且不劝退）：</p><p><img src="/images/loading.jpg" data-original="/2022/04/14/2022-04-14-Games202-Lecture5-(Environment-Mapping)/image-20220415034341690.png" alt="image-20220415034341690"></p><hr><p>瞄了一眼下节课虽然标题依然还是Environment Mapping，但实际上已经在讲PRT（precomputed radiance transfer）了</p><p>所以202的ibl部分应该到这里就完结了，感觉内容其实并不是那么的全，不过讲的真的很棒</p><p>现在是4/15的4:35，明天就可以开整ibl的作业啦</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;一个月前的21日我写完了pcss的作业，满怀信心的直接猛冲第五节课&lt;/p&gt;
&lt;p&gt;随后发现自己对于pbr理论还有brdf的理解已经忘光光了，听这节课就像听天书&lt;/p&gt;
&lt;p&gt;于是用了半个多月补了pbr的理论，做了一个pbr的渲染器和一个ibl的场景&lt;/p&gt;
&lt;p&gt;这次轮到我拿下202的ibl啦&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>从零开始的PBR渲染</title>
    <link href="https://aprilnavi.github.io/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/"/>
    <id>https://aprilnavi.github.io/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/</id>
    <published>2022-04-13T06:06:58.000Z</published>
    <updated>2022-04-13T14:20:40.080Z</updated>
    
    <content type="html"><![CDATA[<p>本文会梳理在LearnOpenGL学习时使用的IBL以及PBR框架和Shader，这是个很重要的知识点</p><p>在我看来，这意味着渲染知识以及一门Shader语言的入门知识到这里就已经结束了（基本渲染概念，渲染管线，brdf）</p><p>因此这也是个重要的学习节点，因此笔者在这里进行一遍知识梳理，希望可以在这里站稳脚跟</p><span id="more"></span><h1 id="聊聊一些闲话"><a href="#聊聊一些闲话" class="headerlink" title="聊聊一些闲话"></a>聊聊一些闲话</h1><p>算了算从上次发布搓布林冯的模型，已经过去了79天了，再加上一开始的时间</p><p>自己从浑然不知到入门渲染以及稍微掌握ogl做一些好玩的东西，才用了不到一百天</p><p>虽然想说进步确实还可以，没有虚度光阴，但一想到鸭鸭所说的速度快的一星期就能速通</p><p>再加上有些数学公式其实还是蛮囫囵吞枣的，有些api会用但是也不算很知道其原理（经典推导等到面试前再去刷面经吧）</p><p>所以也马马虎虎啦，但是过程中真的很开心，搓出来了不少好玩的玩具，渲染真的是好玩的东西</p><hr><p>学习进度上是这个样子，事业上虽然我很紧张也很焦虑，但是客观上来说应该也会有好的结果的</p><p>我总是愿意相信我人生的所有运气都押在了事业上，而事实上也确实如此</p><p>导师和我说我分到了我们那边投入最大的在研项目，而我实习的内容就是优化引擎和看ue源码</p><p>说实话我以为我这么菜过去可能会做些劳累的边缘活，没什么收益又花时间的那种</p><p>结果分到了类似引擎开发这样的工作，真的感觉会收益很大（不用写逻辑太开心了）</p><p>我实习的内容再加上我所学习的渲染相关的知识，或许秋招真的有机会可以试试看引擎岗</p><p>（虽然我真的很不信，但是按照前辈所说客户端可以扯到图形基本上已经爆杀了）</p><p>这样下去就算我在tx死赖一年半载的实习的话收益应该也会很大，只是从零开始的引擎研究之旅还真的很迷茫</p><p>包括跟不上进度的104还有举步维艰的渲染学习，也让我觉得紧张和焦虑</p><hr><p>好在一路上认识了不少伙伴，他们为我的学习路径提供了很多不错的意见</p><p>也陪伴我度过了很多的时光，我很感激他们，也会带着我们共同的梦想走下去</p><p>虽然前路依然布满荆棘，但好在迷雾已经散去，我会有很好的未来的，我始终这么相信</p><hr><h1 id="PBR部分"><a href="#PBR部分" class="headerlink" title="PBR部分"></a>PBR部分</h1><p><img src="/images/loading.jpg" data-original="/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/image-20220413150414508.png" alt="image-20220413150414508"></p><p>先康康我们的效果图，对比简单用布林冯模型渲染出来的模型，我们PBR看上去有更多的细节也更加逼真了</p><p>那是因为PBR指基于物理的渲染(Physically Based Rendering)，采用的是与物理世界更相符的计算方式和参数</p><p>美术师几乎也是直接以物理参数为依据来编写表面材质的，例如这个初号机的头就是朋友从Blender里面丢出来然后我渲出来的</p><p>要说pbr的话其实也不知道从哪说起，如果从辐射度量学那边开始的话篇幅就太大了</p><p>因此我的想法是和别人相反，打算从代码往理论上回推，然后慢慢引申出pbr多了些什么和以前有什么区别</p><hr><h2 id="PBR多了些什么"><a href="#PBR多了些什么" class="headerlink" title="PBR多了些什么"></a>PBR多了些什么</h2><p>我们来康康pbr的渲染对比以前的布林冯多了什么</p><pre><code>// build and compile shaders// -------------------------Shader ourShader(&quot;pbr.vs&quot;, &quot;pbr.fs&quot;);</code></pre><p>起码shader的部分我们依然是只用了一个shader，也就是说我们目前并没有依靠其他shader来生成什么玩意</p><p>我们的计算还有最终的表现都是在这一个shader里面完成的</p><p>再看看我们的参数都需要用到哪些吧（顶点着色器没什么变化，和往常一样）</p><pre><code>// pbr.fs#version 330 coreout vec4 FragColor;in vec2 TexCoords;in vec3 WorldPos;in vec3 Normal;// material parametersuniform sampler2D albedoMap;uniform sampler2D metallicMap;uniform sampler2D roughnessMap;//uniform sampler2D ao;// lightsuniform vec3 lightPositions[4];uniform vec3 lightColors[4];uniform vec3 camPos;const float PI = 3.14159265359;</code></pre><p>纹理坐标，世界空间的着色点坐标和法线，相机位置，这些都和往常一样区别不大</p><p>而不同的是我们多了几张用来采样的纹理参与计算，他们分别是albedo,normal,metallic,roughness,ao</p><p>而这些就是我们让渲染结果看上去更真实的关键！</p><hr><h2 id="PBR的核心理念"><a href="#PBR的核心理念" class="headerlink" title="PBR的核心理念"></a>PBR的核心理念</h2><p>在浅墨前辈梳理的PBR核心理念中</p><p>PBR遵循以下理论：</p><p><strong>微平面理论（Microfacet Theory）</strong></p><p><strong>能量守恒 （Energy Conservation）</strong></p><p><strong>基于F0建模的菲涅尔反射（Fresnel Reflection）</strong></p><p><strong>线性空间光照（Linear Space Lighting）</strong></p><p><strong>色调映射（Tone Mapping）</strong></p><p><strong>基于真实世界测量的材质参数</strong></p><p><strong>光照与材质解耦（Decoupling of Lighting and Material）</strong></p><p>这里附上原链：<a href="https://zhuanlan.zhihu.com/p/56967462">【基于物理的渲染（PBR）白皮书】（二） PBR核心理论与渲染光学原理总结 - 知乎 (zhihu.com)</a></p><p>不明白上面在说什么？没关系，我们会在代码中一步步的阐述这些理论做了什么</p><hr><h2 id="代码中是怎么处理渲染方程的"><a href="#代码中是怎么处理渲染方程的" class="headerlink" title="代码中是怎么处理渲染方程的"></a>代码中是怎么处理渲染方程的</h2><p>假设我们都知道渲染方程（这里是没加间接光的反射率方程）为何物，那么读者应该也可以理解，布林冯模型也是渲染方程的一种简化形式</p><p>（理解不了也没事你姑且认为是就行了）</p><p><img src="/images/loading.jpg" data-original="/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/image-20220413153200054.png" alt="image-20220413153200054"></p><p>在我的理解内，渲染方程阐述了在p点位置朝着ωo方向（出射方向，也就是我们视线方向）的光线是什么样的（颜色，强弱）</p><p>每一道入射光乘以brdf之后才是他们能为最终结果所做的贡献（乘以n⋅ωi确保我们所获取的光是直射的有效的值）</p><p>将所有的这些结果在半球上做一个积分（其实也就是把无限个光方向给合起来），就得到我们所看到的样子了</p><p><strong>能量守恒 （Energy Conservation）</strong>不就用上了吗，这个公式看起来就很合乎直觉吧</p><p>而我们的PBR就可以理解我们这里的brdf采用了微平面Cook-Torrance模型</p><p>（其实是不太严谨的，真正的pbr是包含了基于物理的材质，基于物理的光照，基于物理适配的摄像机）</p><hr><p>首先很明确的一点我们当然没法真的计算“无限“这个概念，而渲染方程中的积分，它的运算包含了半球Ω内所有入射方向上的dωi</p><p>由于渲染方程和反射率方程都没有解析解，因此我们将会用离散的方法来求得这个积分的数值解</p><pre><code>int steps = 100;float sum = 0.0f;vec3 P    = ...;vec3 Wo   = ...;vec3 N    = ...;float dW  = 1.0f / steps;for(int i = 0; i &lt; steps; ++i) &#123;    vec3 Wi = getNextIncomingLightDir(i);    sum += Fr(p, Wi, Wo) * L(p, Wi) * dot(N, Wi) * dW;&#125;</code></pre><p>不过要记住代码的dW相当于一个离散的步长，而数学上，用来计算积分的dW表示的是一个连续的符号</p><p>现在很明朗了吧，L(p, Wi)是Wi方向打到p点的光（已知），dot(N, Wi)（已知）</p><p>接下来我们要算的就只剩下brdf了</p><hr><h2 id="Cook-Torrance-BRDF做了些什么"><a href="#Cook-Torrance-BRDF做了些什么" class="headerlink" title="Cook-Torrance BRDF做了些什么"></a>Cook-Torrance BRDF做了些什么</h2><p>实际上我们的pbr渲染所做的也就是将Cook-Torrance的公式带进了shader里面</p><p>（接下来的内容几乎是照搬教程的，但是教程说的真的很好，我第一次学时就可以清晰的理解到位）</p><p>附上原链：[理论 - LearnOpenGL CN (learnopengl-cn.github.io)](<a href="https://learnopengl-cn.github.io/07">https://learnopengl-cn.github.io/07</a> PBR/01 Theory/#_4)</p><p><img src="/images/loading.jpg" data-original="/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/image-20220413163826664.png" alt="image-20220413163826664"></p><p>这里的kd是入射光线中<strong>被折射</strong>部分的能量所占的比率，而ks是<strong>被反射</strong>部分的比率。</p><p>BRDF的左侧表示的是漫反射部分，被称为Lambertian漫反射，这和我们之前在漫反射着色中使用的漫反射系数类似，用如下公式表示</p><p><img src="/images/loading.jpg" data-original="/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/image-20220413164005974.png" alt="image-20220413164005974"></p><p>c表示表面颜色（回想一下我们之前所做的采样diffuse纹理）</p><p>除以π是为了对漫反射光进行标准化，因为前面含有BRDF的积分方程是受π影响的（别问为什么你除就对了）</p><p>这个Lambertian漫反射和我们之前经常使用的漫反射其实是差不多的</p><p>之前我们是用表面法向量与光照方向向量进行点乘，然后再将结果与平面颜色相乘得到漫反射的结果</p><p>点乘依然还在，但是却不在BRDF之内，而是转变成为了Lo积分末公式末尾处的n⋅ωi了</p><hr><p>BRDF的镜面反射部分要稍微复杂一些，它的形式如下所示：</p><p><img src="/images/loading.jpg" data-original="/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/image-20220413164758382.png" alt="image-20220413164758382"></p><p>字母D，F与G分别代表着一种类型的函数，各个函数分别用来近似的计算出表面反射特性的一个特定部分。</p><p>他们分别是<strong>法线分布函数(Normal Distribution Function)<strong>，</strong>菲涅尔方程(Fresnel Rquation)<strong>和</strong>几何函数(Geometry Function)</strong></p><hr><h2 id="法线分布函数-Normal-Distribution-Function"><a href="#法线分布函数-Normal-Distribution-Function" class="headerlink" title="法线分布函数(Normal Distribution Function)"></a>法线分布函数(Normal Distribution Function)</h2><p>还记得我们一开始提到的<strong>微表面模型理论</strong>吗</p><p>这是一个将物体表面建模成无数微观尺度上有随机朝向的理想镜面反射的小平面（microfacet）的理论。</p><p>最终的效果是在表面上的不同点处改变微平面的法线，从而改变反射和折射的光方向。</p><p>出于着色的目的，通常会用统计方法处理这种微观几何现象，将表面视为具有微观结构法线的随机分布。</p><p>也就是表面越粗糙，反射越模糊，表面越光滑，反射越集中。（这就是为什么粗糙度是参数之一啦）</p><p>而<strong>法线分布函数D</strong>则近似的表示了与某些半程向量h取向一致的微平面的比率</p><p><img src="/images/loading.jpg" data-original="/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/image-20220413170335847.png" alt="image-20220413170335847"></p><p>其中参数n为法线，h为半程向量，α为粗糙度</p><p>假设我们用不同的粗糙度来渲染同一个球的话（这个时候同一个点的n和h就都是一样的，变量只有粗糙度）</p><p><img src="/images/loading.jpg" data-original="/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/image-20220413170522909.png" alt="image-20220413170522909"></p><p>粗糙度很低（也就是说表面很光滑）的时候，与中间向量取向一致的微平面会高度集中在一个很小的半径范围内，NDF最终会生成一个非常明亮的斑点</p><p>当表面比较粗糙的时候，微平面的取向方向会更加的随机，与h向量取向一致的微平面分布在一个大得多的半径范围内</p><p>pbr shader中的真实函数是这样的：</p><pre><code>//pbr.fsfloat DistributionGGX(vec3 N, vec3 H, float roughness)//法线分布函数D项&#123;    float a      = roughness*roughness;    float a2     = a*a;    float NdotH  = max(dot(N, H), 0.0);    float NdotH2 = NdotH*NdotH;    float nom   = a2;    float denom = (NdotH2 * (a2 - 1.0) + 1.0);    denom = PI * denom * denom;    return nom / denom;&#125;</code></pre><p>可以理解为直接将NDF套公式了，还是很好理解的</p><hr><h2 id="几何函数-Geometry-Function"><a href="#几何函数-Geometry-Function" class="headerlink" title="几何函数(Geometry Function)"></a>几何函数(<strong>G</strong>eometry Function)</h2><p>几何函数从统计学上近似的求得了微平面间相互遮蔽的比率，这种相互遮蔽会损耗光线的能量。</p><p>最后呈现出来的效果就是模型上光照被损耗，变得没有那么亮</p><p>我们将要使用的几何函数是GGX与Schlick-Beckmann近似的结合体，因此又称为Schlick-GGX：</p><p><img src="/images/loading.jpg" data-original="/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/image-20220413171334985.png" alt="image-20220413171334985"></p><p>在开头提到的渲染eva的工程里，shader用的是针对直接光照的k</p><p>与NDF类似，几何函数采用一个材料的粗糙度参数作为输入参数，越粗糙不平的的表面其微平面间相互遮蔽的概率就越高。</p><p>其余两个参数是法线n和光线方向v，这同样是涉及到了开始提到的微表面理论模型。</p><p>为了有效的估算几何部分，需要将观察方向（几何遮蔽(Geometry Obstruction)）和光线方向向量（几何阴影(Geometry Shadowing)）都考虑进去</p><p>我们可以使用史密斯法(Smith’s method)来把两者都纳入其中：即G(n,v,l,k)=Gsub(n,v,k)Gsub(n,l,k)</p><p><img src="/images/loading.jpg" data-original="/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/image-20220413171810764.png" alt="image-20220413171810764"></p><p>看看我们的shader是怎么写的：</p><pre><code>//pbr.fsfloat GeometrySchlickGGX(float NdotV, float roughness)//几何函数G项&#123;    float r = (roughness + 1.0);    float k = (r*r) / 8.0;    float nom   = NdotV;    float denom = NdotV * (1.0 - k) + k;    return nom / denom;&#125;float GeometrySmith(vec3 N, vec3 V, vec3 L, float roughness)//史密斯法&#123;    float NdotV = max(dot(N, V), 0.0);    float NdotL = max(dot(N, L), 0.0);    float ggx2  = GeometrySchlickGGX(NdotV, roughness);    float ggx1  = GeometrySchlickGGX(NdotL, roughness);    return ggx1 * ggx2;&#125;</code></pre><p>同样是很好理解的套公式</p><hr><h2 id="菲涅尔方程-Fresnel-Rquation"><a href="#菲涅尔方程-Fresnel-Rquation" class="headerlink" title="菲涅尔方程(Fresnel Rquation)"></a>菲涅尔方程(Fresnel Rquation)</h2><p><strong>菲涅尔方程</strong>是用来描述光在不同折射率的介质之间的行为的方程，定义了被反射的光线对比光线被折射的部分所占的比率</p><p>公式如下：</p><p><img src="/images/loading.jpg" data-original="/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/image-20220413213554395.png" alt="image-20220413213554395"></p><p>在菲涅尔方程中我们拿<strong>F0（即0度角入射时的菲涅尔反射率）</strong>作为材质的<strong>基本反射率</strong>参与运算</p><p>对于一般仅有实数折射率的非金属而言，可以通过查询到的物质的折射率和上面的公式，计算出F0</p><p>而我们的机甲里边用的都是金属对吧，所以我们一般还会对基础反射率添加它的表面色彩</p><pre><code>vec3 F0 = vec3(0.04);F0      = mix(F0, albedo.rgb, metalness);</code></pre><p>因为金属表面会吸收所有折射光线而没有漫反射，所以我们也可以<strong>直接使用表面颜色纹理</strong>来作为它们的基础反射率。</p><p>其他两个参数h（半程向量）和v（这里是观察方向）我们当然是已知的</p><p>看看菲涅尔项的shader是什么样的：</p><pre><code>vec3 fresnelSchlick(float cosTheta, vec3 F0)//菲涅尔项F&#123;    return F0 + (1.0 - F0) * pow(1.0 - cosTheta, 5.0);&#125;  </code></pre><p>同样是精彩的套公式环节</p><hr><h2 id="从Cook-Torrance反射率方程回到shader"><a href="#从Cook-Torrance反射率方程回到shader" class="headerlink" title="从Cook-Torrance反射率方程回到shader"></a>从Cook-Torrance反射率方程回到shader</h2><p>对于我们的每个shading point来说，我们最终的结果是依照反射率方程来进行的</p><p><img src="/images/loading.jpg" data-original="/2022/04/13/2022-04-13-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84PBR%E5%92%8CIBL%E6%B8%B2%E6%9F%93/image-20220413214925496.png" alt="image-20220413214925496"></p><p>整体的流程是怎么做的呢？</p><pre><code>void main()&#123;    vec3 albedo     = pow(texture(albedoMap, TexCoords).rgb, vec3(2.2));    float metallic  = texture(metallicMap, TexCoords).r;    float roughness = texture(roughnessMap, TexCoords).r;    float ao        = texture(aoMap, TexCoords).r;        vec3 N = normalize(Normal); //法线    vec3 V = normalize(camPos - WorldPos);//观察方向        vec3 F0 = vec3(0.04);     F0      = mix(F0, albedo, metallic);&#125;</code></pre><p>我们先将所需要的数据进行采样，同时预计算出了F0以及其他我们所需要的向量的值。</p><pre><code>    vec3 Lo = vec3(0.0);    for(int i = 0; i &lt; 4; ++i)     &#123;        vec3 L = normalize(lightPositions[i] - WorldPos);//入射光        vec3 H = normalize(V + L);//半程向量        float distance    = length(lightPositions[i] - WorldPos);        float attenuation = 1.0 / (distance * distance);        vec3 radiance     = lightColors[i] * attenuation;         vec3 F  = fresnelSchlick(max(dot(H, V), 0.0), F0);        float NDF = DistributionGGX(N, H, roughness);               float G   = GeometrySmith(N, V, L, roughness);          vec3 nominator    = NDF * G * F;//cook torrance的分子        float denominator = 4.0 * max(dot(N, V), 0.0) * max(dot(N, L), 0.0) + 0.001;         vec3 specular     = nominator / denominator;          vec3 kS = F;//镜面反射系数等于菲涅尔项        vec3 kD = vec3(1.0) - kS;        kD *= 1.0 - metallic;          float NdotL = max(dot(N, L), 0.0);         Lo += (kD * albedo / PI + specular) * radiance * NdotL;    &#125;</code></pre><p>我们在场景中的不同位置放置了四个点光源，他们都参与运算并且最后将贡献相加，对于不同的光源来说他们的入射光和半程向量当然是不同的</p><p>接着我们会计算点光源的和shading point的距离，根据衰减公式算出他们最终的radiance（也就是原公式中的Li(p,ωi)）</p><p>这也诠释了PBR中基于物理的光照理念（我们的衰减不一定准确，但一定要体现这点）</p><p>因为菲涅尔方程直接给出了kS， 因此可以直接使用F表示kS（镜面反射在所有打在物体表面上的光线的贡献）</p><p>接着剩下的所有部分就都是精准的套公式了（注意我们在分母项中加了一个0.001为了避免出现除零错误）</p><p>这样所求得的最终的结果Lo（<strong>出射光线的Radiance</strong>）实际上已经是反射率方程的在半球领域Ω的积分的结果了</p><p>因为在这个简单场景中我们只有四个点光源参与真正的运算，只有它们四个入射光线会影响最终的着色</p><pre><code>vec3 ambient = vec3(0.03) * albedo * ao;vec3 color   = ambient + Lo;  </code></pre><p>剩下的工作就是加一个环境光照项给Lo，乘上环境光遮蔽，然后我们就拥有了片段的最后颜色</p><p>但我们的工作依然没有做完，因为所有光照的输入都接近他们在物理上的取值，因此先采用色调映射使Lo从LDR的值映射为HDR的值</p><p>因为我们的计算都是在线性空间中计算的，所以还要进行伽马校正，这样输出的才是最终片元的值</p><pre><code>color = color / (color + vec3(1.0));color = pow(color, vec3(1.0/2.2)); FragColor = vec4(color, 1.0);</code></pre><p>在上述的计算过程中，光照和材质不存在什么依赖关系，光可以自由自在的变化和材质产生互动</p><p>这也对应了<strong>光照与材质解耦（Decoupling of Lighting and Material）</strong></p><hr><p>PBR的渲染考虑到了我们对于render equation和brdf的理解，是一个很关键的分水岭</p><p>过程中自己半抄半改网上的教程，最终也做出了自己满意的玩具渲染器</p><p>现在熟悉的敲下这些文字应该也意味着自己真正的将渲染入门啦，恭喜恭喜</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文会梳理在LearnOpenGL学习时使用的IBL以及PBR框架和Shader，这是个很重要的知识点&lt;/p&gt;
&lt;p&gt;在我看来，这意味着渲染知识以及一门Shader语言的入门知识到这里就已经结束了（基本渲染概念，渲染管线，brdf）&lt;/p&gt;
&lt;p&gt;因此这也是个重要的学习节点，因此笔者在这里进行一遍知识梳理，希望可以在这里站稳脚跟&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>第六周学习日志</title>
    <link href="https://aprilnavi.github.io/2022/03/28/2022-03-28-%E7%AC%AC%E5%85%AD%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/"/>
    <id>https://aprilnavi.github.io/2022/03/28/2022-03-28-%E7%AC%AC%E5%85%AD%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/</id>
    <published>2022-03-28T00:59:56.000Z</published>
    <updated>2022-03-30T13:17:18.479Z</updated>
    
    <content type="html"><![CDATA[<p>不能说有什么进展，但好在我已经渡过了焦虑危机</p><p>起码我春招再投网易的想法是寄掉了，不想给自己太大压力</p><p>现在这样很快乐，这样就好。就算未来的自己审视起这段春招，我也会觉得是有在努力的</p><p>至少我觉得赶工一两个星期并不能改变很多东西，但是会把我心态搞崩hhhh</p><span id="more"></span><h1 id="Monday"><a href="#Monday" class="headerlink" title="Monday"></a>Monday</h1><p>昨夜今日是比较难忘的一天，我通宵到了几乎早上七点才睡</p><p>原因是在一位特别特殊的友人的追问下，我向她袒露了自己的心声</p><p>也表达了我的惋惜和遗憾，毕竟保护我的朋友和不让人困扰我一直都很擅长</p><p>但昨天的自己很勇敢，面对那个问题直接就说了“有”，现在想想还是挺厉害的233333</p><p>令我没想到的是，她居然会说“身边如果有你这样的人，会好好把握的吧”，“你也是我很珍惜的人”</p><p>我哭死，完全没想到这样的回答，不过我也不会困扰对方的，把这份喜悦珍藏在心里吧</p><hr><p>今天把OpenGL往下推进一节吧，晚上104，感觉应该没什么机会看引擎架构了</p><hr><h1 id="Tuesday"><a href="#Tuesday" class="headerlink" title="Tuesday"></a>Tuesday</h1><p>摆大烂 零提升</p><h1 id="Wednesday"><a href="#Wednesday" class="headerlink" title="Wednesday"></a>Wednesday</h1><p>摆大烂 零提升 烦躁</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;不能说有什么进展，但好在我已经渡过了焦虑危机&lt;/p&gt;
&lt;p&gt;起码我春招再投网易的想法是寄掉了，不想给自己太大压力&lt;/p&gt;
&lt;p&gt;现在这样很快乐，这样就好。就算未来的自己审视起这段春招，我也会觉得是有在努力的&lt;/p&gt;
&lt;p&gt;至少我觉得赶工一两个星期并不能改变很多东西，但是会把我心态搞崩hhhh&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>游戏引擎架构精要（才怪）⑤</title>
    <link href="https://aprilnavi.github.io/2022/03/21/2022-03-21-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A4/"/>
    <id>https://aprilnavi.github.io/2022/03/21/2022-03-21-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A4/</id>
    <published>2022-03-21T09:17:58.000Z</published>
    <updated>2022-03-25T12:32:48.531Z</updated>
    
    <content type="html"><![CDATA[<p>《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。</p><p>但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，</p><p>以及n个自己给自己找的理由，让这个阅读计划一直搁置。</p><p>但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多</p><p>再加上自己有意往引擎方向发展，阅读这本书就提上了日程。</p><span id="more"></span><p>上次翻书还是在15号，然后上周的日志还是空的。我更加好奇上星期我都做了些什么</p><p>看到这个标题我想起很久以前看的《编程模式》里面提及的游戏循环的更新方式</p><p>即unity的Update函数和ue4中的Tick函数，不过这一章节好像不是说这些的</p><hr><h1 id="游戏循环及实时模拟"><a href="#游戏循环及实时模拟" class="headerlink" title="游戏循环及实时模拟"></a>游戏循环及实时模拟</h1><p>这一章我们会探讨时间和引擎的关系，以及在引擎中运用时间的常见方法</p><h2 id="7-1-渲染循环"><a href="#7-1-渲染循环" class="headerlink" title="7.1 渲染循环"></a>7.1 渲染循环</h2><p>在实时渲染的应用中，我们的大部分程序体都运行在渲染循环里面</p><p>渲染循环的结构一般如下,写过OpenGL应该很熟悉了：</p><pre><code>while(!quit)&#123;//更新相机，在光栅化里面我们会更新view矩阵UpdateCamera();//更新场景中所有动态元素的位置，方向，以及其他相关视觉信息UpdateSceneElements();//把静止的场景渲染到离屏的帧缓冲RenderScene()//交换帧缓冲SwapBuffers&#125;</code></pre><h2 id="7-2-游戏循环"><a href="#7-2-游戏循环" class="headerlink" title="7.2 游戏循环"></a>7.2 游戏循环</h2><p>游戏由很多种子系统组成，包括IO，渲染，动画，物理。网络同步等</p><p>其中每个子系统的循环频率可能不同，例如动画往往和渲染有着同样的刷新率</p><p>而物理可能需要更高的刷新率（可能是120hz？）而AI往往是30帧</p><p>我们先以最简单的方法来更新引擎的所有子系统，即采用单一循环</p><p>这种循环称为游戏循环，是整个游戏的主循环</p><p>底下的伪代码个人感觉和自己写的OpenGL程序也有相似之处</p><p>毕竟我们的OpenGL代码也是跑在glfw窗口库里面的嘛</p><pre><code>void Main()&#123;   Init();   While(true)  &#123;    ReadHumanInterFaceDevices();        if(QuitButtonPressed())    &#123;      break;//离开循环    &#125;        //移动手柄更新输入    //更新球的位置    //碰撞检测和球的弹射逻辑    //球是否碰壁，碰壁则加分，重置球的位置        Render();      &#125;&#125;</code></pre><hr><h2 id="7-3-游戏循环的架构风格"><a href="#7-3-游戏循环的架构风格" class="headerlink" title="7.3 游戏循环的架构风格"></a>7.3 游戏循环的架构风格</h2><p><strong>视窗消息泵：</strong></p><p>没什么卵用，鼠标移动视窗大小的话游戏会愣住不动</p><p><strong>回调框架驱动：</strong></p><p>有些引擎和中间套件以框架构成，我们只需要填补框架中空缺的自定义实现部分（或者override预设行为）</p><p>例如OGRE渲染引擎就是用OGRE框架实现，程序员需要从Ogre:FrameListener派生一个类</p><p>并Override两个虚函数FrameStart和FrameEnd，OGRE在渲染三维场景时会调用这两个虚函数</p><p>因此就可以在渲染前处理一些输入，更新相机，更新物理等工作，在帧结束时也做一些工作</p><p><strong>基于事件更新：</strong></p><p>有些游戏引擎使用事件系统来更新，游戏在实现更新时只需要加入这个事件进入队列</p><p>在处理这个事件时可以以我们想要的周期进行更新，接着这串代码会发送一个新事件进入队列</p><p>周而复始的完成游戏的周期循环</p><h2 id="7-4-抽象时间线"><a href="#7-4-抽象时间线" class="headerlink" title="7.4 抽象时间线"></a>7.4 抽象时间线</h2><p><strong>真实时间：</strong></p><p>通过CPU的高分辨率计时寄存器获取的真实的时间</p><p><strong>游戏时间：</strong></p><p>只使用一条时间线的限制很大，我们可以独立出另一条时间线。</p><p>在正常情况下这条时间线和真实时间线是一样的，但暂停游戏时可以停止这条时间线</p><p>我们此刻可以通过基于另一条正常时间线的飞行摄像机在场景中游览</p><p>为了实现慢动作，可以把这条时间线放慢，以此实现很多效果</p><p>要谨记暂停游戏时，我们的游戏循环依然在运行，只是时钟停止了</p><p><strong>局部时间：</strong></p><p>在ue里面我们播的动画，音频，timeline都是局部的时间线，很好理解</p><hr><h2 id="7-5-测量以及处理时间"><a href="#7-5-测量以及处理时间" class="headerlink" title="7.5 测量以及处理时间"></a>7.5 测量以及处理时间</h2><p>我们平时所说的帧率是屏幕一秒钟刷新的次数，通常以FPS（frame per second）来度量</p><p>可以简单理解为我们把一秒钟分成了多少个周期，恰巧我们经常以每帧为一个更新周期</p><p>两帧之间间隔的时间△t称之为时间增量，这个增量对于我们的游戏逻辑运算有着很重要的意义</p><hr><p><strong>随性能进行更新</strong></p><p>假设我们的飞船以恒定速来40m/s飞行，则飞船的速率v乘以△t，就能得到△x＝v△t，下一帧的位移x2就=x1+△x</p><p>但早期游戏开发中，并不会过于在意恒定的帧率，程序员可能完全忽略△t</p><p>因此物体的速度可能依赖于机器的帧率，而这个帧率是不稳定的。</p><p>记得我们玩过的早期宝可梦吗，按住快进按钮人物和动画音乐以及整个游戏的一切都会以数倍速度运行</p><hr><p><strong>使用固定步长更新</strong></p><p>若不希望△t与CPU的运行速度不挂钩，我们可以读取一个特定某帧的△t，存下来作为全局变量之后使用</p><p>许多引擎用的也是这种方式，但使用某次的帧率来代表接下来所有的帧率可能会带来不好的后果</p><p>例如当前帧率为30fps，即33.3ms更新一次，假如有一帧特别慢花了更久的时间，例如66.6ms</p><p>那我们下一帧就要对系统更新两次来追上刚刚错失的速率，就好比我们今天摸鱼了明天就得加倍</p><p>这样可能造成恶性循环导致下一帧变成像这一帧那么慢甚至更慢</p><hr><p><strong>使用平均帧数更新</strong></p><p>一个合理的方式是连续计算几帧所耗时的平均时间，用来估计下一帧的△t</p><p>此方法可以使游戏适应转变中的帧率。平均帧数越多，对帧率急速转变的应变能力越小，但是受影响越小</p><hr><p><strong>限制帧率</strong></p><p>我们可以将帧数限定在例如60fps，当这一帧耗时很短时，我们就让主线程休眠，直到达到休眠时间</p><p>但只有当游戏的平均帧率接近目标帧率时，此方法才有效，若经常遇到慢帧，游戏就会不断的在45到60跳动</p><p>为了应对不稳定的帧率，也得将引擎系统设计成接受任意的△t。维持稳定的帧率，对游戏很多方面都很重要</p><p>例如物理模拟中的数值积分，以固定时间运作是最好的。稳定的帧率使画面看上去也更流畅</p><hr><p><strong>画面撕裂</strong></p><p>这种现象出现在背景缓冲区和前景缓冲区交换时，显示硬件只绘制了部分屏幕，旧的部分和新的部分就衔接在了一起就造成了画面撕裂。</p><p>为了避免画面撕裂，许多渲染引擎会在交换缓冲区之前等待显示器的垂直消隐区间。</p><p>等待垂直消隐区间的行为被称为垂直同步，它也是一种调控帧率的方法。</p><p>实际上他可以限制住游戏主循环的帧率，使其必然为屏幕刷新率的倍数，若两帧之间的时间超过了1/60s</p><p>则必须等待下一次消隐区间，即该帧花了2/60s</p><hr><p>大多数操作系统都提供获取系统时间的函数，但这类函数的分辨率一般为秒</p><p>并不适合用于度量游戏中的时间，因为游戏中每一帧仅耗时数毫秒</p><p>但好在所有现代CPU都有高分辨率计时器和相应的硬件寄存器，计算启动之后经过的CPU周期数</p><p>倘若用64位的整数来储存时间，则能支持非常高的精度，但相应的空间耗费也不小</p><p>要测量高精度但较短的时间的话，32位整数也是个不错的选择</p><p>浮点数的话，只适合存储相对较短的持续时间，通常用于储存帧</p><hr><p>假如游戏在调试时遇到断点，而碰巧游戏和调试器都是在同一台机器上运行</p><p>当我们在查看断点处的代码时，时间会一直流逝，如果我们在计算平均帧率来确定时间增量</p><p>那么下一帧就会受到非常大的影响，甚至可能导致游戏崩溃，因此可以添加类似的代码段</p><pre><code>while(true)&#123;updateA();updateB();//...//估算下一帧的时间增量U64 end_ticks=readHiResTimes();dt=(F32)(begin_ticks-end_ticks)/(F32)getHiRestTimerFrequency();if(dt&gt;1.0f)&#123;dt=1.0/30.0;&#125;//把endbegin_tickS=end_ticks;&#125;</code></pre><p>有些引擎会把时间封装成一个时间类，引擎包含数个这个类的实例，用于表示真实挂钟时间</p><p>另一些用于表示游戏时间（可以暂停，可以缩放，来完成一些常见的trick）</p><hr><h2 id="7-6-多处理器的游戏循环"><a href="#7-6-多处理器的游戏循环" class="headerlink" title="7.6 多处理器的游戏循环"></a>7.6 多处理器的游戏循环</h2><p>这一内容来讨论如何让游戏运行在多核系统来取代复古的单游戏主循环去服务其多个子系统</p><p>多线程游戏的设计比单线程游戏要难得多，通常做法是让几个引擎的子系统做并行化</p><p>我们这个时候就得关注不同平台上的不同架构是怎么样的了（什么xbox360 ps3架构看着挺头晕的）</p><p>PS4上有着双总线，统一内存架构（异构统一内存架构）为程序员在灵活性和原始性能之间提供了不错的权衡</p><p>这类架构也适合大部分游戏常见的内存访问形式，即渲染数据有两种形式：</p><p>数据在CPU和GPU共享（物体变换的矩阵，光照参数，以及其他着色器参数）；数据几乎由GPU独占生产和管理；</p><p>GPU本质上是大型并行高性能微处理器集群，可以执行成百上千个并行执行的运算</p><p>我们也能利用GPU做一些非图形运算的任务，被称为GPU通用计算。</p><p>PS4上引入的比较新的异构统一内存架构是为了消除各个计算机系统各个处理中心之间的瓶颈</p><p>在此之前CPU和GPU是两个完全分离的设备，各自具有各自的内存，两者之间传输需要累赘以及高延迟的专门总线</p><hr><p>多数的现代CPU会提供单指令多数据（SIMD）指令集，这类指令能让一个运算同时执行在多个数据之上</p><p>游戏中最常用的是并行操作4个32位浮点数的指令，因为这种SIMD指令可以使三维矩阵矢量和其他矩阵运算速度提升四倍</p><hr><p>也可以采用分治然后汇合的算法，将一个单位的工作分割成更小的子任务，分配到多个线程，所有工作完成后再汇合结果</p><p>假如我们要进行动画混合，此时有五个角色，每份角色骨骼有一百个关节，我们需要处理五百对关节姿势</p><p>这五百个任务可以被切个到N个批次进行并行化，此时N的数目由可用的核心来决定</p><p>但因为每个骨骼单独计算全局姿势时，需用上他所有关节的局部姿势（有依赖关系），对单份骨骼运算只能串行计算</p><hr><p>另一个多任务方法是把子系统置于独立线程上运行，主控线程负责控制和同步这些子系统和刺激子系统</p><p>并继续处理游戏的大部分高级系统。此时的子系统一般是重复性运行且隔离度较高的，例如物理，渲染，动画，音频</p><p>多线程架构需要目标硬件平台上的线程库支持，例如win32的线程api</p><hr><p>使用多线程会带来一些问题，例如我们将物理放一个线程，渲染放一个线程，这会限制其他系统中多个处理器的利用率</p><p>若某个子系统线程未完成工作，可能就会阻塞主线程和其他线程，我们可能得将粒度再切割一点</p><p>为了充分利用并行硬件架构，另一种方式是让游戏引擎把工作分成很多细小的作业</p><p>作业可以理解为一组数据和操作该组的代码结合成对，准备就绪后就可以加入队列。</p><p>在作业模型里面，工作被拆分成细粒度的作业，可以在任何闲置的处理器中运行，可以最大化处理器的利用率</p><hr><p>为了利用多处理器硬件，我们必须小心使用异步方法（发出操作请求通常不能立刻得到结果）</p><p>而平时的同步方法是程序得到结果之后才能继续运行。许多时候可以在次帧启动异步请求，而在下一帧得到结果</p><hr><h2 id="7-7-网络游戏多人循环"><a href="#7-7-网络游戏多人循环" class="headerlink" title="7.7 网络游戏多人循环"></a>7.7 网络游戏多人循环</h2><h3 id="主从式模型-CS"><a href="#主从式模型-CS" class="headerlink" title="主从式模型 CS"></a>主从式模型 CS</h3><p>大部分逻辑运行在服务器上，服务器的代码和非网络的单人游戏很相似，多个客户端连接到服务器一起参与游戏</p><p>客户端相当于一个不智能的”渲染引擎“，拙劣的模仿服务器上发生的事情</p><p>客户端会接收输入，以控制本地的玩家角色，除此之外客户端渲染什么都由服务器告知</p><p>但这样一来延迟可能不小，因此客户端代码也得将玩家输入即时转换成屏幕上的动作，这被称为玩家预测</p><p>服务器单独运行于一台机器上，这种运行方式被称为专属服务模式（dedicated server mode）</p><p>也可以客户端机器同时运行服务器，被称为客户端于服务器之上模式（client on top of server mode）</p><h3 id="点对点模型-P2P"><a href="#点对点模型-P2P" class="headerlink" title="点对点模型 P2P"></a>点对点模型 P2P</h3><p>没啥用没啥意思，不谈</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。&lt;/p&gt;
&lt;p&gt;但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，&lt;/p&gt;
&lt;p&gt;以及n个自己给自己找的理由，让这个阅读计划一直搁置。&lt;/p&gt;
&lt;p&gt;但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多&lt;/p&gt;
&lt;p&gt;再加上自己有意往引擎方向发展，阅读这本书就提上了日程。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Games202 Lecture4 (Shadow 2)</title>
    <link href="https://aprilnavi.github.io/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/"/>
    <id>https://aprilnavi.github.io/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/</id>
    <published>2022-03-21T02:06:58.000Z</published>
    <updated>2022-03-21T04:59:15.279Z</updated>
    
    <content type="html"><![CDATA[<p>呜呜呜这段时间真的太忙了，感觉自己做什么都进度缓慢</p><p>希望渲染这方面可以不要忘掉放掉吧</p><p>今天的内容是202的阴影部分，希望听完课就会做作业了555</p><p>这样做一个记录也不知道是不是有效果的，但总比什么都没留下</p><p>ps：文章是15开的，21才写完，笑死</p><span id="more"></span><h1 id="More-On-PCSS"><a href="#More-On-PCSS" class="headerlink" title="More On PCSS"></a>More On PCSS</h1><p>让我们回顾一下之前PCSS（一星期没看了我自己回顾一下）</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321091523016.png" alt="image-20220321091523016"></p><p>图中等号右边的算式中，以·为分界线，左边是权右边是值</p><p>我们看向值的部分，其中X被称为chi，是一个符号函数，算式的值大于0函数值就为1，小于零结果就是0</p><p>这同时也是我们阴影比较的结果，即用SM中的所有点q的depth值和场景中x的depth值比大小得到非零即一的值</p><p>随后在一个区域内对所有的值做一个卷积最后加入到结果中</p><p>所以我们很清楚的是，我们做卷积的是<strong>SM和场景Shading point深度值比较的结果</strong></p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321092902960.png" alt="image-20220321092902960"></p><p>因此我们也能重新好好的解释为什么不是在Shadow Map上做的卷积（这个内容在之前第一章的部分有重新换了个更好的说明方式）</p><p>因为我即使对Shadow Map做了模糊最后得到的值还是非零即一的，这显然没什么意义</p><p>同时我当然也不是在图像空间上做的卷积（我在已经生成好的有锯齿的图像上做一个模糊那会让图形更糊）</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321094426193.png" alt="image-20220321094426193"></p><p>我们看看PCSS的完整算法步骤</p><ol><li><strong>在一个确切的区域（Blocker Search Region）计算区域内遮挡物的平均深度</strong></li><li><strong>根据这个平均距离去决定卷积域的大小</strong></li><li><strong>用这个卷积去做PCF</strong></li></ol><p>很显然第一步和第三步的开销最大，第一步得遍历区域内所有点的深度取平均，第三步遍历每个点的深度做比较</p><p>为了加速这个过程我们一般会在区域内随机取一些样本以减少计算量，这样的结果是噪声会较多</p><p>工业界的做法偏向于随机采样，对于生成的噪声多的结果在图像空间上做一个降噪处理（这是比较容易的）</p><hr><h1 id="VSSM"><a href="#VSSM" class="headerlink" title="VSSM"></a>VSSM</h1><p>为了解决PCSS这两个较慢的步骤，我们引出了VSSM（Variance Soft Shadow Mapping）的概念</p><p>PCF中percentage的意义在于，我们想知道一个区域内有多少的像素是比较成功的（即比较结果为有阴影）</p><p>通常来说我们为了知道这个百分比，会把所有像素都遍历计算一遍</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321101541364.png" alt="image-20220321101541364"></p><p>闫神这里打了个比方，即我想知道考试分数符合条件的同学，在班里面有多少个，我会把所有同学的成绩都看一遍</p><p>我们假如知道成绩的直方图，我们就能估算出我们所要的百分比，那如果我们再大胆一点呢？</p><p>我们直接把这个直方图视作为一个正态分布，我们甚至都不需要得知正确的直方图了</p><hr><p>为了定义一个正态分布我们需要<strong>均值</strong>（决定了中间的尖尖在什么位置）和<strong>方差</strong>（决定正态分布的胖瘦23333）</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321103257378.png" alt="image-20220321103257378"></p><p><strong>平均值部分：</strong></p><p>所以我们的关键思想就是， 我们想快速得知这个区域内深度的平均值是多少</p><p>一张图，区域，平均值，我们能回忆起什么？没错！Mipmap！（我第一次也没想起来，滚回去补基础吧QAQ）</p><p>但是mipmap的结果不太准，而且只能查询方形的区域，所以我们还引入了SAT的概念（Summed Area Tables）</p><p><strong>方差部分：</strong></p><p>用了一个很经典的公式，即方差=平方的期望-期望的平方，在这里期望和平均具有同等概念</p><p>期望的平方好说，我们有一个区域那就可以很快的得到这个区域的深度值的平均值</p><p>我还想快速的得到平方的期望，那怎么做呢，我们再生成一张Shadow mapping来记录信息吧</p><p>用新SM的某个像素值来记录深度值的平方（经典空间换时间）</p><p>这里提一嘴，在Opengl里面我们写入SM一般是写在一个通道里面（例如r通道）</p><p>那么我们将深度值的平方也写入另外一个通道的话，甚至不需要更多的空间（好耶）</p><hr><p>得到了均值和方差之后，我们就要来生成正态分布了，我想知道有多少深度值大于某某某</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321103550098.png" alt="image-20220321103550098"></p><p>PDF（概率密度函数）指的是上面那条曲线，我们想计算的则是CDF，即曲线之下的面积</p><p>怎么算曲线之下的面积捏，对于一个较为通用的高斯分布的曲线来说，我们往往会把f(x)直接打印成一张表去查询</p><p>这个f(x)被称为error function（误差函数），只有数值解没有解析解，在Cpp中用erf函数就能查到对应的值</p><p>我们依然觉得这样查这样算是件很麻烦的事情，所以我们找来了切比雪夫不等式</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321104834653.png" alt="image-20220321104834653"></p><p>切比雪夫不等式可以告诉我们随机变量超过某个值的概率大概是什么样的，但却不需要知道随机变量满足什么样的分布</p><p>我们只需要期望和方差就够啦，我们甚至不需要知道分布是不是一个正态分布或者其他牛鬼蛇神的函数曲线</p><p>因此就可以知道大于t的面积（概率）不会超过（小于等于）多少，而我们只需要期望和方差</p><p>另一边也很好算直接用1去减就能得到，相当于我两边都可以直接快速计算获取</p><p>看到≤号直接很理所当然的在脑海里面把他替换成了≈</p><p>因此，最后我们有了均值和方差就可以很快的计算出我们所需要的CDF（概率）</p><p>切比雪夫不等式必须得满足t在均值的右边，否则就不准了，t只对半边是管用的，但是够了</p><hr><p>PS：这就是图形学吗，一次又一次的近似得到一个蒙骗人眼的理想效果，太有趣了（Trick这个词用的很妙）</p><hr><p>最后的表现如何呢？</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321110328534.png" alt="image-20220321110328534"></p><ul><li>我们生成了square depth map（深度平方值map），和shadow map一起生成的</li><li>在shadow map上想去一个范围的平均，直接就能查到（借助mipmap或者sat）</li><li>想要范围内深度平方值的期望，深度平方值也是一张图我们也能很快查到</li><li>均值方差都知道我们直接就把切比雪夫不等式代入，这也是很快的</li></ul><p>我们直接就可以很快速的回答：在这个范围内有百分之几的像素深度大于shading point（不可见区域的百分比）</p><p>不需要进行额外的采样或者循环，我们的第三步就直接圆满解决了（好耶）</p><p>（提醒一下第三步做的是PCF，我们在这一步做的是给定卷积域我想知道不可见区域的百分比是多少）</p><p>但很显然，我们如果有物体或者光源移动，我们就得重新生成mipmap，但在GPU上做这些非常的快（快到可以忽略 ）</p><hr><p>记得我们在PCSS第一步做的什么吗，我们要在一个所谓“ A Certain Blocker Search Area，确切的阻挡检测区域 ” 获得<strong>遮挡物的平均深度</strong></p><p>（<strong>注意是遮挡物的平均深度哦，是深度值大于Shading Point的pixel平均深度哦，不是区域所有pixel的平均深度哦</strong>）</p><p>我用mipmap可以快速得到这整个区域的平均深度，但我怎么获得遮挡区域的平均深度呢</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321114259114.png" alt="image-20220321114259114"></p><p>遮挡物部分的N1/N我们用切比雪夫不等式去计算，非遮挡物的部分就（1-N1/N）</p><p>但我们依然是不知道遮挡物的深度和非遮挡物的深度捏</p><p>我们再次做出大胆假设：非遮挡物的深度都和shading point的深度一模一样（阴影照射的地方很多是平面，所以这么假设也情有可原吧）</p><p>所以已知Zavg，Zunocc，N1/N，N2/N，直接代入计算就能得到Zocc，即遮挡物的平均深度</p><p>至此，第一步我们用几乎可以忽略的额外开销直接也解决了，VSSM的所有要点到这里也就结束了</p><hr><p>VSSM包含了很多很大胆却又有那么一点河里的假设，让人直呼一声妙</p><p>VSSM可以理解为PCSS的快速版本，<strong>没有噪声，速度更快</strong></p><p>但随着现代降噪手段越来越高明，而VSSM也会出现一些不合理的结果，PCSS逐渐盖过了VSSM</p><p>但VSSM解决问题的思路是大胆而精巧的，完全值得我们学习</p><hr><h1 id="MIPMAP-and-Summed-Area-Variance-Shadow-Maps"><a href="#MIPMAP-and-Summed-Area-Variance-Shadow-Maps" class="headerlink" title="MIPMAP and  Summed-Area Variance Shadow Maps"></a>MIPMAP and  Summed-Area Variance Shadow Maps</h1><p>mipmap关键：<strong>快速，近似，方形区域的快速查询</strong></p><p>但只能做方形，而且不准确，若查询范围不是2的次方，我们还需要做三线性插值，那就更加不准确了</p><p>但我们的SAT却是绝对准的，他紧密的和前缀和结构联系在一起</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321120710542.png" alt="image-20220321120710542"></p><p>还记得我们要做的是范围查询吗，给定一个区域能马上获得那个区域的平均。</p><p>一维的数组花O(n)的时间做一个预处理，就能得到这个SAT</p><p>接着我们对于任意范围都能很快的获得那个区域的总和，平均值也做个除法直接呼之欲出</p><p>那么在二维上我们怎么做SAT呢</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321122613383.png" alt="image-20220321122613383"></p><p>我们可以生成一张表，表里面每个元素都是从左上角加到此元素的值</p><p>我们生成的每个SAT都是从左上角为起点开始的，因此我们只需要查四次表就能快速获得方形内的求和</p><p>生成这个SAT可以理解成对于每一行做一遍生成，然后也对每一列做一个生成（这部分其实有一点抽象）</p><p>生成STA的时间复杂度为O(n)，这里的n认为是个数</p><p>行与行之间的SAT生成是可以并行的，因此就可以通过GPU进行并行，但开销依然是有的</p><p>PS：SAT这方面感觉不太像适合初学者手撕的内容，感觉写VSSM直接用mipmap好一点</p><hr><h1 id="Moment-Shadow-Mapping"><a href="#Moment-Shadow-Mapping" class="headerlink" title="Moment Shadow Mapping"></a>Moment Shadow Mapping</h1><p>VSSM的问题，结果不准确，在一些情况下，阴影内有突然变白变亮的现象（Light Leaking），这是不能忍受的</p><p>为了避免VSSM中描述分布不准确的问题，Moment SM采用更高阶的矩来描述分布</p><p>矩可以简单理解为次方数，像我们的VSSM就只用了一阶矩和二阶矩</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321125226388.png" alt="image-20220321125226388"></p><p>Moment SM用四阶的矩刚好可以得到足够近似的分布结果</p><p>而且也对应RGBA四个通道，不太需要考虑额外的存储问题</p><p><img src="/images/loading.jpg" data-original="/2022/03/21/2022-03-15-Games202-Lecture4-(Shadow-2)/image-20220321125501665.png" alt="image-20220321125501665"></p><p>如图所示Moment SM的开销大一些，但是效果显然好了很多</p><p>具体怎么做emmmm，就不细究了。</p><hr><p>我们从这次的学习历程也能看出图形算法更迭的思路，这对于其他领域也同样适用</p><p>我们为了得到一个好的结果，开发出一个好的方案，但对于美中不足的点我们再单独去想办法改进他们</p><p>为了获取实时动态阴影我们有了Shadow map，为了这个阴影可以更软更真实更高质量我们有了PCF和PCSS</p><p>为了PCF可以计算得更快，我们又有了VSSM来改进PCSS的第一步和第三步</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;呜呜呜这段时间真的太忙了，感觉自己做什么都进度缓慢&lt;/p&gt;
&lt;p&gt;希望渲染这方面可以不要忘掉放掉吧&lt;/p&gt;
&lt;p&gt;今天的内容是202的阴影部分，希望听完课就会做作业了555&lt;/p&gt;
&lt;p&gt;这样做一个记录也不知道是不是有效果的，但总比什么都没留下&lt;/p&gt;
&lt;p&gt;ps：文章是15开的，21才写完，笑死&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>第五周学习日志</title>
    <link href="https://aprilnavi.github.io/2022/03/21/%E7%AC%AC%E4%BA%94%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/"/>
    <id>https://aprilnavi.github.io/2022/03/21/%E7%AC%AC%E4%BA%94%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/</id>
    <published>2022-03-21T00:59:56.000Z</published>
    <updated>2022-03-25T05:56:23.346Z</updated>
    
    <content type="html"><![CDATA[<p>上星期我的表现就更烂了（烂的好！铿锵有力掷地有声）</p><p>总体表现在3.15就开搞的202第二节（VSSM）的部分到现在都是0进度</p><p>也不知道上星期都做什么去了，卷没好好卷玩没好好玩</p><p>想准备一下网易的秋招但是感觉自己渲染水平也是实在有限（没写过path tracing不会pbr）</p><p>有人觉得我是不是对自己太过于严格了，我经常也这样问自己</p><p>但人如果什么都不舍弃的话，那也注定什么都无法得到吧，我想在这条路上和认识的大家一起走下去</p><p>有着鹅的offer在我也可以直接姑且把自己当成春招的胜利者了（如果有其他佬看到这个就给佬跪了）</p><p>而且我也乐观的觉得按照自己的进度，等到秋招的时候应该还算是蛮有竞争力的（希望别打自己脸555）</p><p>上个星期就当做是摸鱼周了，起码我过得很开心，这周要DDL拉满支棱起来了！</p><span id="more"></span><h1 id="Monday"><a href="#Monday" class="headerlink" title="Monday"></a>Monday</h1><p>上午起床就在宿舍门口做的核酸，昨天晚睡了感觉眼睛疼疼的</p><p>但写下这些的时候是九点，打算花一个上午搞定202的vssm的博客记录</p><p>有时间的话再看看202的作业代码吧，衷心希望早上的效率能靠得住</p><hr><p>事实上昨天单单202的博客我就写到了下午一两点，有在做事但是效率真的不高</p><p>后边太累了直接上床摆烂，摆到下午五点淋雨去图书馆（哦对淋雨！所以第二天不舒服了）把我的书都拿回来了</p><p>然后又补理论补到晚上，晚上搞了一晚上的引擎架构搞到八点也没能把第七章看完（慢！）</p><p>然后就一边散步一边看104搞到了九点多就摆大烂了hhh</p><p>这周五会把mini engine放出来，期待捏</p><hr><h1 id="Tuesday"><a href="#Tuesday" class="headerlink" title="Tuesday"></a>Tuesday</h1><p>上午感觉身体不太舒服，前夜打崩三熬到了四点睡到了十点半才起来</p><p>中午把202作业0做了想复习一下框架（然而我对框架还是一知半解完全没有卵用）</p><p>又把文章搬到知乎然后就去好好睡了个大觉，心情一整天蛮压抑的</p><p>下午睡到了五点起来，心情状态都好了很多，不用担心发烧了，看来是没休息好</p><hr><p>晚上开始尝试202的作业1，然后被框架（框架写挺好的主要是vsc太垃圾了）搞了波心态</p><p>好在最后至少把Shadowmapping还有PCF搞出来了，最后看到结果心情还是很好的嘿嘿</p><hr><h1 id="Wednesday"><a href="#Wednesday" class="headerlink" title="Wednesday"></a>Wednesday</h1><p>对不起，我又忘记了，我只记得我写完了PCSS（可以说是抄完）</p><p>然后不出效果，然后我就狂改改了一天最后气晕了</p><hr><h1 id="Thursday"><a href="#Thursday" class="headerlink" title="Thursday"></a>Thursday</h1><p>今天是周五（写的时候），至少让我回忆一下昨天都发生了什么</p><p>昨天睡到了中午，早上做了核酸爽喝了杯咖啡</p><p>然后抄了七八个pcss终于有一个能出效果了（破拉不堪）</p><p>发现核心算法基本上和直接写差不多，找遮挡物的平均深度然后算个比例决定卷积域大小</p><p>可能有些值传错了，但我想我是理解了（大概）</p><p>然后昨天群里的老哥说我在23届实习生里面已经爆杀了（虽然我没信）</p><p>但极大的延缓了我的焦虑，所以我睡到了晚上做了一个点光源透视（跑不动算了）</p><p>然后耍手机刷到了四五点，嘿嘿，真好</p><hr><h1 id="Friday"><a href="#Friday" class="headerlink" title="Friday"></a>Friday</h1><p>我发现自己还真是贪心啊，又想学好gameplay，又想学好render</p><p>我想碰虚幻引擎源码，想学ue渲染编程，想学ECS</p><p>想拿图形api把各种牛逼的real time render全做一遍，死了算了23333</p><p>今天pilot引擎跳票了，原因是感觉新手摸多线程和ecs感觉很吃力，所以换了传统架构</p><p>真的，他们甚至又重新用传统架构写引擎，我哭死</p><p>今天目标吧Normal Mapping做出来，然后把引擎架构第七章看完吧</p><p>然后接下来都摆大烂！</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;上星期我的表现就更烂了（烂的好！铿锵有力掷地有声）&lt;/p&gt;
&lt;p&gt;总体表现在3.15就开搞的202第二节（VSSM）的部分到现在都是0进度&lt;/p&gt;
&lt;p&gt;也不知道上星期都做什么去了，卷没好好卷玩没好好玩&lt;/p&gt;
&lt;p&gt;想准备一下网易的秋招但是感觉自己渲染水平也是实在有限（没写过path tracing不会pbr）&lt;/p&gt;
&lt;p&gt;有人觉得我是不是对自己太过于严格了，我经常也这样问自己&lt;/p&gt;
&lt;p&gt;但人如果什么都不舍弃的话，那也注定什么都无法得到吧，我想在这条路上和认识的大家一起走下去&lt;/p&gt;
&lt;p&gt;有着鹅的offer在我也可以直接姑且把自己当成春招的胜利者了（如果有其他佬看到这个就给佬跪了）&lt;/p&gt;
&lt;p&gt;而且我也乐观的觉得按照自己的进度，等到秋招的时候应该还算是蛮有竞争力的（希望别打自己脸555）&lt;/p&gt;
&lt;p&gt;上个星期就当做是摸鱼周了，起码我过得很开心，这周要DDL拉满支棱起来了！&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>游戏引擎架构精要（才怪）④</title>
    <link href="https://aprilnavi.github.io/2022/03/15/2022-03-14-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A3/"/>
    <id>https://aprilnavi.github.io/2022/03/15/2022-03-14-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A3/</id>
    <published>2022-03-14T16:17:58.000Z</published>
    <updated>2022-03-14T16:19:27.211Z</updated>
    
    <content type="html"><![CDATA[<p>《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。</p><p>但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，</p><p>以及n个自己给自己找的理由，让这个阅读计划一直搁置。</p><p>但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多</p><p>再加上自己有意往引擎方向发展，阅读这本书就提上了日程。</p><span id="more"></span><p>今天进104官网看，发现引擎架构理所当然成为了这门课的官方教科书</p><p>这本书确实聊的蛮浅，但本人毕竟也才疏学浅看完这本书也需要些精力</p><p>今天晚上104就开课了，感觉自己进度好慢什么都跟不上</p><p>虽然是有点急了但是我菜的离谱也是当务之急，赶紧多肝吧</p><p>今天保底把第六章搞完，有机会的话肝肝第七章</p><hr><h1 id="资源及文件系统"><a href="#资源及文件系统" class="headerlink" title="资源及文件系统"></a>资源及文件系统</h1><p>游戏引擎必须有载入和管理多种媒体的能力，包括texture，mesh，animation，sound，collision，physics，scene</p><p>这涉及到如何同步或者异步IO（串流载入）的问题，涉及到如何跨平台编写文件系统，</p><p>涉及到如何管理runtime的资产占用的内存，涉及到怎么保存交叉引用的复合对象</p><p>（今天就只记得看了这么多了，真的很摸鱼）</p><hr><h2 id="6-1-文件系统"><a href="#6-1-文件系统" class="headerlink" title="6.1 文件系统"></a>6.1 文件系统</h2><h3 id="6-1-1-文件名和路径"><a href="#6-1-1-文件名和路径" class="headerlink" title="6.1.1 文件名和路径"></a>6.1.1 文件名和路径</h3><p>路径是描述了文件系统层次中文件或目录位置的字符串</p><p>在windows上（不讨论其他平台了），路径是一般是c:\Windows\System32这样的</p><p>路径分为绝对路径和相对路径，（有机会可以提提在UE里面导资产的事情）</p><p>在运行时寻找资产是十分费时的，最好在运气前就搜寻完所有的资产</p><p>若想开发跨平台的游戏引擎，则需要实现一个轻量化的路径处理API而非直接使用平台API</p><hr><h3 id="6-1-2-文件I-O"><a href="#6-1-2-文件I-O" class="headerlink" title="6.1.2 文件I/O"></a>6.1.2 文件I/O</h3><p>一般会建议引擎将文件IO的API封装成自己的API，</p><p>好处是可以保证所有平台上都有相同的表现，可以降低维护量同时也能满足拓展的需求</p><p>我们一般会<strong>推荐使用异步文件IO API</strong>，因为如果使用同步的IO API</p><p>那么这意味着在所有数据读取完之前程序会进入<strong>阻塞</strong>，这明显是十分蛋疼的</p><p>我们希望游戏都<strong>有串流（背后加载数据，主程序继续持续运行）</strong>的功能</p><p>说起来圣莫尼卡的《战神》就把这一块玩的很好，全程基本不会黑屏读图</p><p>为了支持串流就必须使用异步的IO API，具体伪代码详见原书p278</p><p>多数异步IO库允许主程序在请求发出一段时间后，等待IO完成才继续允许</p><p>如果需要在等待IO时做些有限的工作，则这种方式十分适用。</p><p>有些IO库允许程序员取得某些异步操作的时间估计，并设置时限</p><p>以及超出时限的安排（取消请求，通知程序，继续尝试）</p><hr><h2 id="6-2-资源管理器"><a href="#6-2-资源管理器" class="headerlink" title="6.2 资源管理器"></a>6.2 资源管理器</h2><p>游戏资源必须被妥善处理，包括离线时将资产转化为引擎适用资产的离线工具</p><p>还有在runtime时载入，卸下，以及操作资源的工具。</p><h3 id="6-2-1-离线资源管理以及工具链"><a href="#6-2-1-离线资源管理以及工具链" class="headerlink" title="6.2.1 离线资源管理以及工具链"></a>6.2.1 离线资源管理以及工具链</h3><p>资产的版本控制这方面因为没有和别人协同开发过</p><p>因此更不了解如何做好一个版本控制了，这对自己搓的玩具来说也不算大事，略过</p><p>对于大部分资产来说，游戏引擎不会使用原来的格式（就好像虚幻的uasset）</p><p>每个资产会流经资产调节管道（asset Conditioning Pipeline）</p><p>此时需要一些<strong>元数据（metadata，我悟了什么是元数据）</strong>来描述如何处理资产</p><p><strong>元数据就是描述数据的数据，例如要压缩位图使用哪一种压缩方式</strong></p><p>为了管理这些metadata以及资产，我们需要某种数据库。</p><p>数据库（也可以说是资产编辑器了）一般满足如下功能：</p><p>能处理多个资产，创建，删除，查看，修改，移动（磁盘上的位置）</p><p>交叉引用，维持交叉引用完整性，保存历史版本，多种搜索方式</p><hr><p>UE4的unreal editor就是个很棒的例子，editor几乎负责一切事物</p><p>包括元数据管理，资产创建，关卡布局，</p><p>可以在创建资产时直接看到资产在游戏世界的样子（所见即所得）</p><p>还可以在Editor中直接运行游戏，以便观察其如何在游戏中运作</p><p>同时UE的引用完整性做的也相当好（读的知识越多越感觉ue做的叼）</p><p>顽皮狗和ogre的离线资产管理方案这里就不做总结了</p><hr><p>资产调节管道也称（resource conditioning pipeline，名字不重要）</p><p>每个资产管道的始端都是原生格式的源资产，通常会经过三个处理阶段到达引擎</p><ol><li><p><strong>导出器（expoter）</strong>将原生格式的资产中的数据导出为中间格式供后续管道使用</p></li><li><p><strong>编译器（compiler）</strong>将第一阶段的数据进行小改动，例如重新压缩纹理，并非所有资产都需要重新编译</p></li><li><p><strong>链接器（linker）</strong>将多个文件结合成一个包再一起导入引擎，类比cpp的链接过程</p></li></ol><hr><h3 id="6-2-2-运行时资产管理"><a href="#6-2-2-运行时资产管理" class="headerlink" title="6.2.2 运行时资产管理"></a>6.2.2 运行时资产管理</h3><p>runtime管理的许多责任和功能都和其主要功能（载入资源到内存）有关：</p><p>确保任何时候同一份资源只有一份副本，管理资源生命周期（需要时载入不需要时卸载）</p><p>处理符合资源（多个资源组成的资源），维护引用完整性，管理资源载入后的内存</p><p>载入资源后初始化资源，提供较为统一的api，尽可能支持异步</p><p>资源文件及目录组织，一般是树状的不太关心（没啥好写的）</p><hr><p>游戏中所有资源必须有某种<strong>全局唯一标识符（GUID）</strong>常见的GUID就是资源的文件系统路径</p><p>这能很直观的反应他们硬盘上的物理路径且GUID因此不会重复</p><p>为了保证在任何时间载入内存的都只有一份副本</p><p>大部分资源管理器会使用某种形式的资源注册表记录已载入的资源</p><p>以键值对的集合（键为GUID值为指针）的方法则非常经典</p><p>资源被载入内存时限以其GUID为键，加载资源注册表字典，卸载资源时删除记录</p><p>游戏请求资源时就会用GUID寻找资源注册表，找得到就传指针</p><p>找不到就自动载入一个新的资源或者返回错误码</p><p>在runtime载入资源会对游戏的帧率造成非常大的影响，甚至是停顿</p><p>因此引擎可以采用串流（异步加载）或者是在游戏进行时完全禁止加载</p><hr><p>每个资产对生命周期有不同的要求：</p><ul><li>有些资产在游戏开始时必须被载入，驻留在内存一直到整个游戏结束，或者说其生命周期是无限的。典型例子有角色网格，材质，纹理以及核心动画，HUD，以及其他全程可以听到看到的资源</li><li>有些资产的生命周期则对应某个关卡，在玩家离开关卡时资源才被弃置（就好像ue的level资产，假设我们这里所说的关卡是一个实体而非逻辑概念的话）</li><li>有些资产的生命周期短于一个关卡的时间，例如过场动画，一小段BGM</li><li>有些资产的生命周期如很难定义，例如一些音乐和音效，因为每字节只短暂停留在内存中，这类资源通常以特定大小区块为单位载入。</li></ul><hr><p>在何时载入资源是已知的好解决的，但我们应该在何时卸载资源归还内存呢</p><p>许多资源依然会在之后的关卡继续共享，我们当然不希望将某些资源卸载后马上又加载他们</p><p>一个很好的方案就是使用引用计数（提到引用计数你应该想起智能指针类）</p><p>载入新的关卡时先遍历这些关卡所需的资源，并将其引用计数加1</p><p>然后再遍历即将卸载的资源将其引用计数减一，引用计数跌到0的就应该卸载掉。</p><hr><p>载入资源是不可避免的问题是考虑资源加载到哪一块内存，之前所述的内存分配系统通常与资源管理系统有很大的关系</p><p>要么利用已有的内存分配器设计系统资源，要么就设计内存分配器以配合资源管理所需。</p><p><strong>基于堆</strong>：若目标平台为PC，则由于操作系统支持高级的虚拟内存分配，这个方法还算勉强可以接受</p><p>但如果游戏运行在一个物理内存有限的游戏机上，只配上了最基础的虚拟内存管理器（可能还没有）</p><p>那么内存碎片就会是一个较为严重的问题，可以回顾之前所说的定期整理内存碎片的方案。</p><p><strong>基于栈：</strong>因为栈的内存分配是连续的，因此不会有内存碎片的问题。若能确保游戏是线性以及以关卡为中心</p><p>且一次内存足够容纳一整个关卡，那么就可以用这个方法。我们甚至可以用堆载入资源</p><p>标记栈的堆顶位置，每次完成关卡后都重新将栈顶指针重新指回到开始标记的位置，这样就可以迅速的释放关卡的所有资源</p><p>而且永远不会导致内存碎片</p><p><strong>基于池：</strong>在支持串流（异步加载）的游戏引擎中，一个常见分配技巧是将数据转化为同等大小的区块（chunk）。</p><p>因为chunk大小一致，因此就可以使用池分配器。但与此同时就得考虑分块的空间浪费问题</p><p>同时也要避免大型数据结构的使用，取而代之使用小于单个组块的数据结构</p><hr><p>游戏的复合资源通常包含着大量交叉引用：A引用B，B引用CD，ABCD必须同时在内存才能运行</p><p>要完整的载入复合资源，就得载入其依赖的所有资源。在Cpp中交叉引用一般以指针实现。</p><p>一个好的方式是使用GUID做交叉引用，资源管理器维护一个全局资源查找表</p><p>每次将资源对象载入内存后，都要把其指针以GUID为键加入查找表中。</p><p>当所有资源对象都载入内存后，扫描一次所有对象，将其交叉引用资源对象的GUID通过查找表换成指针</p><hr><p>有的资源在载入后还需要进行初始化，例如定义mesh的顶点和索引值，这些数据在渲染前得传送到缓存</p><p>而初始化的步骤又只能在runtime进行，包括建立顶点和索引缓冲，锁定缓冲读入缓冲以及解锁缓冲</p><p>在Cpp中许多开发者更喜欢把载入后初始化和卸载置于Init（）Destory（）这样的虚函数中</p><hr><p>肝到了0点18分，没想到这一章节感觉东西不多但是居然肝了有3k字，太难以置信了</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。&lt;/p&gt;
&lt;p&gt;但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，&lt;/p&gt;
&lt;p&gt;以及n个自己给自己找的理由，让这个阅读计划一直搁置。&lt;/p&gt;
&lt;p&gt;但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多&lt;/p&gt;
&lt;p&gt;再加上自己有意往引擎方向发展，阅读这本书就提上了日程。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>第四周学习日志</title>
    <link href="https://aprilnavi.github.io/2022/03/14/2022-03-14-%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/"/>
    <id>https://aprilnavi.github.io/2022/03/14/2022-03-14-%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/</id>
    <published>2022-03-14T09:17:58.000Z</published>
    <updated>2022-03-14T09:09:10.480Z</updated>
    
    <content type="html"><![CDATA[<p>这周恰逢games104开课，最近又流出了很多tx裁员的消息</p><p>压力大起来了，看来得再支棱一点了</p><span id="more"></span><hr><h1 id="Monday"><a href="#Monday" class="headerlink" title="Monday"></a>Monday</h1><p>上周周末过的挺一般的（不好不坏又好又坏）</p><p>不知为什么的就很不淡定，玩游戏的负罪感也变得比之前强了</p><p>大概周五晚上产出了一篇写PCF的博客之后就再也没动过书了</p><p>好多书没看时间根本不够用，有好多想玩的时间也不够用</p><p>再加上裁员内卷的恐慌情绪以及各路小道消息一直蔓延</p><p>一直节奏不错的我也有点乱了阵脚，一晚上都没有睡好觉</p><p>以至于今天早上抱了本书来看，结果闷头睡了一早上</p><p>十一点tx那边把我资料打回来了让我重新提交搞得我也有点怕怕的</p><hr><p>中午饱饱的睡了一觉之后压力没那么大了</p><p>但是下午一边摸鱼一边看书效率真的挺堪忧的</p><p>一想到自己UE引擎渲染三修，晚上又开104的课要听</p><p>瞬间就觉得压力好大，一堆想学一堆在学一堆没时间学</p><p>今天下午看引擎架构关于资源管理的那一章节就看了两个多小时</p><p>确实是感觉深度没有很深，看着也不痛不痒的感觉没学到什么</p><p>更大原因应该还是自己动手能力不足没法直接跟着敲一个出来</p><p>不过既然看了还是好好产出吧。</p><p>晚上争取八点前吧引擎架构的第六章和第七章搞完然后去看104！</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;这周恰逢games104开课，最近又流出了很多tx裁员的消息&lt;/p&gt;
&lt;p&gt;压力大起来了，看来得再支棱一点了&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>Games202 Lecture3 (Shadow 1)</title>
    <link href="https://aprilnavi.github.io/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/"/>
    <id>https://aprilnavi.github.io/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/</id>
    <published>2022-03-11T02:06:58.000Z</published>
    <updated>2022-03-15T02:40:18.397Z</updated>
    
    <content type="html"><![CDATA[<p>在做opengl的时候做到了shadowmapping，效果做出来了但其实并不能算吃的很透</p><p>刚巧想起之前在202已结搭建好了框架环境，可以成功把202娘跑起来</p><p>所以会跟着202好好的把课听一遍</p><p>这次开坑的任务：</p><p>总结202课上精要内容，加入自己理解作为输出</p><p>在作业1的框架上完成shadowmapping的硬阴影</p><p>开始吧 Let ‘s go!</p><span id="more"></span><hr><h1 id="Recap-Shadow-Mapping"><a href="#Recap-Shadow-Mapping" class="headerlink" title="Recap Shadow Mapping"></a>Recap Shadow Mapping</h1><p>做两次光栅化（pass）</p><p>第一次从<strong>光的视角（light space）</strong>做一次pass，得到光看到的更近的更浅的深度值</p><p>将其渲染到一个texture上记录下来，作为ShadowMap</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220311104355661.png" alt="image-20220311104355661"></p><p>第二次从<strong>观察视角（camera）</strong>做一次pass，得到物体更远的深度值</p><p>取一阶段的ShadowMap深度进行比较</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220311104321858.png" alt="image-20220311104321858"></p><p>若第二次的深度值小于第一次的深度值，则生成硬阴影</p><hr><p>优势：不需要场景的几何信息，一旦shadowmap已经生成，shadowmap就能作为场景的几何表示</p><p>缺陷：会发生自遮挡和比较严重的走样（锯齿）</p><hr><p>备注：生成z值时用的矩阵如果是用正交的，第二个阶段也要拿正交的去比</p><p>同理用透视生成的z也一样，两者只要对应上都能生成正确结果</p><p>但大佬提醒，平行光用正交投影，点光源和聚光灯用透视。</p><hr><h2 id="self-occlusion"><a href="#self-occlusion" class="headerlink" title="self-occlusion"></a>self-occlusion</h2><p>如果没有在做深度对比的时候进行bias（偏移）出来的图大概率是像这样的：</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/QQ%E5%9B%BE%E7%89%8720220311110853.jpg" alt="(QQ图片20220311110853.jpg"></p><p>原因是这样的：</p><p>我们在第一阶段用一个像素来记录深度值，但此时如果光对于平面来说是斜照的</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220311111336669.png" alt="image-20220311111336669"></p><p>那一块区域就都只能取小红线这个深度值（即小红线就是像素记录的深度值）</p><p>当从上往下垂直照射（光线和平面法线重合）的时候，自遮挡的现象最不明显</p><p>为了尽量缩小影响bias带来的计算偏差</p><p>因此我们会根据光照和法线的夹角来计算一个bias在比较深度的时候使用：</p><pre><code>float bias = max(0.05 * (1.0 - dot(fs_in.Normal, lightDir)), 0.005);</code></pre><p>这样做也会带来一些问题，例如我们看上去物体就像浮在表面上一样</p><p>阴影并不是贴合着物体的轮廓的，我们称这种现象为悬浮(Peter Panning)</p><p>（这个概念在Learnopengl Shadowmapping有不错的解释：[阴影映射 - LearnOpenGL CN (learnopengl-cn.github.io)](<a href="https://learnopengl-cn.github.io/05">https://learnopengl-cn.github.io/05</a> Advanced Lighting/03 Shadows/01 Shadow Mapping/#_6)）</p><hr><p>RTR doesn’t trust in complexity（实时渲染不相信复杂度）就像电子竞技不相信眼泪哈哈哈</p><hr><p>晚上玩了下原神观察了下阴影，听大佬说人物的阴影用的CSM（Cascaded Shadow Mapping 级联阴影映射）</p><p>即给不同位置的shadowmap不同的分辨率，降低开销同时也能提升细节</p><p>动态阴影基本上都是用各种改进的Shadowmap做的，还有就是光追阴影</p><p>因此Shadowmap需要解决改进的就是锯齿问题</p><hr><h1 id="The-Math-Behind-Shadow-Map"><a href="#The-Math-Behind-Shadow-Map" class="headerlink" title="The Math Behind Shadow Map"></a>The Math Behind Shadow Map</h1><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220311230849772.png" alt="image-20220311230849772"></p><p>将两个函数乘积再积分近似等于积分再乘积（分母相当于做归一化）</p><p>当g(x)的support（支撑集）很小,或者g(x)的函数曲线足够光滑（smooth）</p><hr><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312000423444.png" alt="image-20220312000423444"></p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312001718439.png" alt="image-20220312001718439"></p><p>左边是visibility，右边是纯Shader的结果</p><p>对于点光源和方向光源来说，相当于是Small Support满足了第一条件</p><p>所以是可以近似认为，可以用约等式将shader和visibility的部分拆开分别计算再叠加</p><p>对于面光源来说，面光源内的radiance认为是相等各处不变的，即L是smooth的，也可以满足第一条件</p><p>而对于shading point来说diffuse的表面我们认为变化是比较小的</p><p>而glossy的表面（被打磨的铜镜之类的材质效果，是较为模糊的镜面）是较为剧变的，结果就比较不准确</p><hr><h1 id="Percentage-Closer-Soft-Shadow-PCSS"><a href="#Percentage-Closer-Soft-Shadow-PCSS" class="headerlink" title="Percentage Closer Soft Shadow (PCSS)"></a>Percentage Closer Soft Shadow (PCSS)</h1><p>对于硬阴影来说，阴影在边界上没有从无到有的过渡，看上去很不自然</p><p>在生活中，光源基本上都是理想的面光源，看到的阴影都更倾向于软阴影，有一个良好的过渡。</p><p>PCSS是用来生成软阴影的技术，建立在PCF（percentage Closer Filter）之上</p><p>PCF是起初用于解决阴影边界的抗锯齿而非计算软阴影。</p><p><strong>PCF不是对最后生成的结果的锯齿做模糊</strong>，而是在做阴影的判断时做的Filter</p><p>同样是因为不能先得到一个走样的结果，然后再做一个模糊（和做反走样的概念是一样的）</p><p><strong>PCF同样不是对生成的ShadowMap做了模糊</strong>，因为对Shadowmap和z值比较的结果也就是我们最后的</p><p>shadow值是一个非零即一的结果，即使对shadowmap做比较最后的shadow值依然是非零即一的，</p><p>这没有意义，无法达到抗锯齿的效果</p><p>PCF的做法是在投影到light space找对应像素时，不单单只找那一个像素，而是找周围一圈的像素做一个平均（Filter）</p><p>![image-20220312005309957]image-20220312005309957.png)</p><hr><p>借用learnOpenGL的对此的解释：（个人感觉很到位而且给出了具体的代码演示）</p><p>核心思想是从深度贴图中多次采样，每一次采样的纹理坐标都稍有不同。</p><p>每个独立的样本可能在也可能不再阴影中。所有的次生结果接着结合在一起，进行平均化，我们就得到了柔和阴影。</p><pre><code>float shadow = 0.0;vec2 texelSize = 1.0 / textureSize(shadowMap, 0);for(int x = -1; x &lt;= 1; ++x)&#123;    for(int y = -1; y &lt;= 1; ++y)    &#123;        float pcfDepth = texture(shadowMap, projCoords.xy + vec2(x, y) * texelSize).r;         shadow += currentDepth - bias &gt; pcfDepth ? 1.0 : 0.0;            &#125;    &#125;shadow /= 9.0;</code></pre><p>这个textureSize返回一个给定采样器纹理的0级mipmap的vec2类型的宽和高。</p><p>用1除以它返回一个单独纹理像素的大小，我们用以对纹理坐标进行偏移，确保每个新样本，来自不同的深度值。</p><p>这里我们采样得到9个值，它们在投影坐标的x和y值的周围，为阴影阻挡进行测试，并最终通过样本的总数目将结果平均化。</p><p>使用更多的样本，更改texelSize变量，就可以增加阴影的柔和程度。</p><p>效果可行，但对于一个shading point要做更多次的计算，所以会变得很慢</p><hr><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312010426704.png" alt="image-20220312010426704"></p><p>课程中的对比图</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312005843526.png" alt="image-20220312005843526"></p><p>这是自己手搓的3x3的卷积，Filter越大则阴影越软，因此软阴影就是因此计算而来的</p><p>而一般来说，离物体越近的地方阴影就越硬越明显，因此就有了Percentage Closer Soft Shadow的概念</p><p>即根据阴影与遮挡物的距离给定不同大小的filter size</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312020418634.png" alt="image-20220312020418634"></p><p>这张图很好的说明了Light面越大则软阴影的区域就越大（图中相似三角形的关系）</p><p>我们可以想象，若遮挡物Blocker的离接收物Receiver越近，相似三角形就会更小</p><p>这就很好的解释了为什么有“离物体越近的地方阴影就越硬”的这个现象</p><p><img src="/images/loading.jpg" data-original="/2022/03/11/2022-03-11-Games202-Lecture3-(Shadow-1)/image-20220312021607801.png" alt="image-20220312021607801"></p><p>恰巧笔者最近也在玩消光，有机会的话去游戏里好好观察一番</p><hr><p>打异度之刃2去咯  2022/3/12 2:20</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在做opengl的时候做到了shadowmapping，效果做出来了但其实并不能算吃的很透&lt;/p&gt;
&lt;p&gt;刚巧想起之前在202已结搭建好了框架环境，可以成功把202娘跑起来&lt;/p&gt;
&lt;p&gt;所以会跟着202好好的把课听一遍&lt;/p&gt;
&lt;p&gt;这次开坑的任务：&lt;/p&gt;
&lt;p&gt;总结202课上精要内容，加入自己理解作为输出&lt;/p&gt;
&lt;p&gt;在作业1的框架上完成shadowmapping的硬阴影&lt;/p&gt;
&lt;p&gt;开始吧 Let ‘s go!&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>游戏引擎架构精要（才怪）③</title>
    <link href="https://aprilnavi.github.io/2022/03/08/2022-03-08-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A2/"/>
    <id>https://aprilnavi.github.io/2022/03/08/2022-03-08-%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E%E6%9E%B6%E6%9E%84%E7%B2%BE%E8%A6%81%EF%BC%88%E6%89%8D%E6%80%AA%EF%BC%89%E2%91%A2/</id>
    <published>2022-03-08T09:17:58.000Z</published>
    <updated>2022-03-09T10:05:00.150Z</updated>
    
    <content type="html"><![CDATA[<p>《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。</p><p>但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，</p><p>以及n个自己给自己找的理由，让这个阅读计划一直搁置。</p><p>但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多</p><p>再加上自己有意往引擎方向发展，阅读这本书就提上了日程。</p><span id="more"></span><p>今天把第五章的东西看完，看的内容不多但是感觉有收获，</p><p>书上讲的东西很干货，特别是谈及链表那个地方确实给了人很大的启发</p><hr><h1 id="第五章"><a href="#第五章" class="headerlink" title="第五章"></a>第五章</h1><h2 id="5-3-容器"><a href="#5-3-容器" class="headerlink" title="5.3 容器"></a>5.3 容器</h2><p>这个章节讲了一些基本上常用的数据结构，比较详细的分析了他们适用的场景</p><p>并且为我们自己亲自编写他们也提供了很不错的方案，是我觉得很有用很精华的内容</p><hr><h3 id="5-3-2-迭代器"><a href="#5-3-2-迭代器" class="headerlink" title="5.3.2 迭代器"></a>5.3.2 迭代器</h3><p>问题c++的迭代器在我第一次学习的时候，我不知道他和直接i++的区别是什么</p><p>书中所说，迭代器像是数组索引或指针，可以移至下一个元素（我也知道）</p><p>但是！迭代器通常是容器类的<strong>友元</strong>，因此可以高效迭代访问容器，不向外面暴露容器类的实现细节</p><p>其次，迭代器简化了迭代过程，无论数据结构多复杂，我都可以<code> iterator++</code></p><p>这个又涉及到前置递增++i和后置递增i++的问题</p><p>原文：在深度流水线CPU上，前置递增必须完成递增才能使用这个值，会引起<strong>流水线停顿</strong></p><p>在for循环里面前置和后置没有区别，<strong>当用到值的时候建议使用后置递增</strong></p><p>在使用类类型的时候，由于前置和后置可能是自定义的运算符重载</p><p>而后置递增需要对对象进行拷贝，会造成性能消耗，因此<strong>在类类型尽量使用前置递增</strong></p><hr><h3 id="5-3-3-算法复杂度"><a href="#5-3-3-算法复杂度" class="headerlink" title="5.3.3 算法复杂度"></a>5.3.3 算法复杂度</h3><p>这个大家面试的时候应该都刷烂了，但是书里边对于复杂度的常见解释</p><p>写的不错所以还是可以记一下的：</p><p>若算法的运行时间和容器中的元素数目无关的话，称算法为O（1）；</p><p>若算法循环访问容器里面的元素，每个元素当访问一次，则算法为O（n）；</p><p>若算法有两层循环，每层循环访问每个元素一次，则算法为O（n2）（自动联想上标）；</p><p>若算法使用分治法（二分查找），每次都能消去余下元素的一半，则算法为O（logn）；</p><p>若算法执行一个子算法n次，且子算法为O（logn），则整个算法为O（nlogn）</p><p>最长预见的数量级O（1），O（logn）,O（n）,O（nlogn）,O（n2）</p><p>同时也应该考虑容器的内存布局和使用特性</p><p>数组的内存连续，更加缓存友好，且除了元素不需要额外的内存开销（对比链表需要存指向下一元素的指针）</p><p>若插入以及移除元素的速度很重要，则应该使用链表</p><hr><h3 id="5-3-4-自建容器"><a href="#5-3-4-自建容器" class="headerlink" title="5.3.4 自建容器"></a>5.3.4 自建容器</h3><p>这里对于是否使用自建的数据结构提供了讨论，使用自建容器有以下好处：</p><ul><li>可以自己控制如何分配内存，自由的进行优化</li><li>可自行提供第三方库没有的功能（stl中只能搜索单个最有关元素，而不能搜索n个）</li><li>不需要第三方库支持则可以消除第三方团队的外部依赖</li><li>可全权控制多线程或多核系统的保护机制</li></ul><hr><p>常见第三方：</p><p><strong>STL：</strong></p><p>优势：功能丰富，多平台的壮健表现，几乎所有c++编译器自带stl</p><p>缺点：难学，对于特定问题速度不如自建容器快，对比自建容器会占用更多内存</p><p>会进行许多动态分配，要控制stl的内存占用量</p><p>STL适合pc游戏引擎，因为对比游戏主机内存受限，缺乏高级CPU和虚拟内存</p><p>现代pc拥有高级虚拟内存系统，通常也能忽略物理内存不足的可能性</p><p><strong>Boost：</strong></p><p>优势：文档写得好，功能比stl更多，能有效处理智能指针</p><p>缺点：核心类是模板，可能会生成较大的lib，不适合小项目</p><p>不保证向后兼容，Boost团队也不提供保障。</p><hr><p>数组和动态数组不加赘述，没什么好说的</p><hr><p>链表这块讲的很不错：</p><p>外露式链表：</p><pre><code>template&lt;typename ELEMENT&gt;struct Link&#123;   Link&lt;ELEMENT&gt;* Prev;   Link&lt;ELEMENT&gt;* Next;   ELEMENT* Elem;&#125;</code></pre><p>节点数据结构和元素数据结构完全分离，每个节点含指针指向元素。</p><p>外露式链表的特点在于，一个元素可以置于多个链表中，只需要节点指向该元素</p><p>但分配节点时必须进行动态分配，许多时候会使用池分配器。</p><hr><p>侵入式链表：</p><pre><code>template&lt;typename ELEMENT&gt;struct Link&#123;   Link&lt;ELEMENT&gt;* Prev;   Link&lt;ELEMENT&gt;* Next;&#125;class SomeElement:public Link&lt;SomeElement&gt;&#123;   //其他成员&#125;</code></pre><p>使用侵入式链表的好处是，分配元素时无须再动态分配节点（已经获得了节点）</p><p>但每个元素不能置于多个列表中，（元素只有一个节点数据），因此侵入式链表不如外露式有弹性</p><hr><p>循环链表的结构一般会包含头尾指针：</p><pre><code>template&lt;typename ELEMENT&gt;struct Link&#123;   Link&lt;ELEMENT&gt;* Tail;   Link&lt;ELEMENT&gt;* Head;      //相关操作成员函数&#125;</code></pre><p>用Link类来管理头尾指针有些好处:</p><pre><code>template&lt;typename ELEMENT&gt;struct Link&#123;   Link&lt;ELEMENT&gt; Root; //包含了头尾指针         //相关操作成员函数&#125;</code></pre><p>这样一来最后节点的next和第一个节点的pre都是指向root的</p><p>这样设计能简化插入和移除的逻辑，我们先看看独立头尾指针移除元素的代码：</p><pre><code>void LinkList::remove(Link&lt;ELEMENT&gt;&amp; link)&#123;  if(link.next)link.next.pre=link.pre;  else this.Tail=link.pre  //移除链表末元素    if(link.pre)link.pre.pre=link.next;  else this.Head=link.next//移除链表首元素    link.pre=link.next=nullptr;&#125;</code></pre><p>在这个设计中首节点的pre和末节点的next必为空指针，若列表只有一个节点，则两个指针都会是空指针</p><p>不能单凭一个指针得知他是否属于一个链表</p><p>若使用root的设计：</p><pre><code>void LinkList::remove(Link&lt;ELEMENT&gt;&amp; link)&#123;  ASSERT(link.next);  ASSERT(link.pre);    link.next.pre=link.pre;  link.pre.pre=link.next;    link.pre=link.next=nullptr;&#125;</code></pre><p>最后节点的next和第一个节点的pre都是指向root的</p><p>因此若首节点的pre和末节点的next为空指针，则他不属于这个链表</p><hr><p>字典，散列表（哈希表）</p><p>笔者不可能去手写哈希函数所以感觉没什么好说的哈哈哈</p><p>感觉还是乖乖std::吧</p><hr><h2 id="5-4-字符串"><a href="#5-4-字符串" class="headerlink" title="5.4 字符串"></a>5.4 字符串</h2><p>问了问魔方的引擎前辈</p><p>那边好像基本上都是在改ue的，说在游戏引擎里面处理这个不多</p><p>而且ue内部的字符串管理也还行</p><p>那我就选择性忽略这章吧</p><hr><h2 id="5-5-引擎配置"><a href="#5-5-引擎配置" class="headerlink" title="5.5 引擎配置"></a>5.5 引擎配置</h2><p>5.5这章感觉也没有提供什么对我比较有启发的东西</p><p>讲到ini，xml还有注册表什么的感觉算是短期之内比较接触不到的东西</p><p>如果具体想做的话应该很快能找到不错的解决方案</p><hr><p>今天就到这吧 赶紧shadowmapping去了</p><p>2022.3.9 17:35</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;《Game Engine Architecture》是一直以来我很有兴趣也很想阅读的书，书的译者是我很敬重的milo叶劲峰前辈（魔方引擎中心的大大）。&lt;/p&gt;
&lt;p&gt;但是由于自己基础不牢，再加上这本厚厚的大书所带来的畏难情绪，同时自己过于功利总是把时间抽去做容易提升的事情，&lt;/p&gt;
&lt;p&gt;以及n个自己给自己找的理由，让这个阅读计划一直搁置。&lt;/p&gt;
&lt;p&gt;但这学期拿到了暑期实习的offer，刚巧也在魔方，对于就业的压力就减小了很多&lt;/p&gt;
&lt;p&gt;再加上自己有意往引擎方向发展，阅读这本书就提上了日程。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>第三周学习日志</title>
    <link href="https://aprilnavi.github.io/2022/03/07/2022-03-07-%E7%AC%AC%E4%B8%89%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/"/>
    <id>https://aprilnavi.github.io/2022/03/07/2022-03-07-%E7%AC%AC%E4%B8%89%E5%91%A8%E5%AD%A6%E4%B9%A0%E6%97%A5%E5%BF%97/</id>
    <published>2022-03-07T10:31:58.000Z</published>
    <updated>2022-03-11T18:25:28.859Z</updated>
    
    <content type="html"><![CDATA[<p>第三周的学习日志哒</p><span id="more"></span><h1 id="Monday"><a href="#Monday" class="headerlink" title="Monday"></a>Monday</h1><p>上午的状态很不错，整个人都神采奕奕的</p><p>把光照改进成了bling phong，加了gamma校正和点光源的衰减</p><p>做起来的效果不错，而且一整个上午的效率也很高，明天可以开始做Shadow mapping</p><p>上午上课发生了一点小插曲，我在上PS课的时候用着自己电脑在写shader</p><p>老师过来问我在干什么我说在写着色器，老师说我是毕业想去做游戏吗</p><p>我说已经进tx了（实则转正没一撇），然后老师就以整层楼都听得见的声音直接大喊了一声</p><p>（说起来这个offer真的给了我很多，信心，实力，虚荣，人脉，好的坏的都有）</p><p>然后老师坏笑的说：如果我挂掉你会怎么样呢，我：球球放过</p><p>然后老师就推了一个后辈的v给我，叫我好好带带，带不动就挂我（晕）</p><p>然后稍微看了下大二上在跟着unity教程做demo，看着是还不错，但是不知道基础怎么样</p><p>稍微了解了下挺多行情也术语也不了解（还好不算太离谱的卷王）</p><p>其实挺好的，游戏有在做，后端也有在搞，不需要版号掐死就死路一条</p><hr><p>下午补考完以后基本上是做大牢</p><p>补考本身是并不能算顺利但也并不是完全寄，只能说期望能过吧</p><p>四点就来图书馆想着写一两个小时博客，结果摸鱼边码字字码了不少但是还没写完</p><p>最后因为版号的事情人也焦虑的不行，只能说游戏行业真的太难了</p><p>之后的日子会很难熬吧，但我早已经斩断后路了，毕竟重现前辈所期望的世界是我的U咩呢</p><hr><p>希望七点二十之前可以把UE打开吧，博客写到这样就算了</p><hr><h1 id="Tuesday"><a href="#Tuesday" class="headerlink" title="Tuesday"></a>Tuesday</h1><p>昨天晚上因为一些琐事没有睡好，大概是三点多才睡着</p><p>早上一下睡到了五十分才醒，一醒来就往教室跑，除开很困之外人的精神面貌还不错（好像也不好）</p><p>但起码好在我是个精神独立的人，不会因为失去什么就停止前进</p><p>身体感觉到了明显的劳累感，不过我知道这是因为我把作息调成了不熬夜的作息导致的（好事）</p><p>早上做shadowmapping只做了一半，感觉好难，最后还是跟着源码粘上去才出了效果</p><p>希望明天花多点时间能够把shadowmapping搞明白。</p><hr><p>中午下课把电脑开开心心放图书馆</p><p>然后下午下课过来发现电脑给人挪走了，一天的好心情直接急急急</p><p>希望晚上抽雷神的时候运气可以好点吧</p><hr><p>九条五命，西风长枪两把，和璞鸢一把，毕业心海一只</p><p>水群时间一大把，博客都没有肝完呜呜呜呜</p><p>晚上看了一小时光追课全程发呆，什么都听不懂属实小emo</p><p>好在心情还是不错的，但不得不说萌萌真的很厉害我真的很敬佩她</p><p>我还零基础的时候她就在拿MiniGame打比赛，gameplay做的很好</p><p>我们现在联系的少了，我记得拿到了魔方的oc告诉她的时候她反应不大</p><p>（看来是不稀罕了呜呜呜）她确实没有让我失望，</p><p>晚上直接列式问光追里面的积分和采样算的结果如何（tql）而且她真的是很谦虚的人</p><p>如果我的成长速度是5那她估计是15，但我也会好好加油的</p><hr><h1 id="Wednesday"><a href="#Wednesday" class="headerlink" title="Wednesday"></a>Wednesday</h1><hr><p>早上睡到了八九点，一早上都没怎么肝，就想着东奔西跑给图书馆占位置了</p><p>os课下半节直接逃了，回宿舍打原神去了笑死</p><p>一中午没睡下午精神也不是很好</p><hr><p>说是学习日志到现在根本也还没进状态吧</p><p>不过倒是和鸡哥聊了很多转正的事情，对转正更有信心了</p><p>在居居的群了钓了一下午鱼心情蛮好的还</p><p>虽然最后也是什么都没做哈哈哈哈</p><hr><p>今天的任务定个小目标吧</p><ol><li><p>补完昨天的博客</p></li><li><p>搞完昨天没搞完的shadowmapping（这也算是早上没搞完的）</p></li><li><p>gameplay做完一个模块吧</p></li></ol><p>今日事今日毕冲冲冲！ </p><hr><h1 id="Thursday"><a href="#Thursday" class="headerlink" title="Thursday"></a>Thursday</h1><p>搞了一整个晚上的shadow map</p><p>rtr到了但是翻了几页就劝退了</p><h1 id="Friday"><a href="#Friday" class="headerlink" title="Friday"></a>Friday</h1><p>单单是重新把框架搞好</p><p>调试shadowmap什么的就做了一早上</p><p>回来一边摸鱼一边学习把202第一章关于shadow的整理归纳好了</p><p>写完博客已经是2点钟了</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;第三周的学习日志哒&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>年糕老师的ue4小课堂（第二期）</title>
    <link href="https://aprilnavi.github.io/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/"/>
    <id>https://aprilnavi.github.io/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/</id>
    <published>2022-03-07T10:31:58.000Z</published>
    <updated>2022-03-07T10:59:08.634Z</updated>
    
    <content type="html"><![CDATA[<p>在ue方面笔者完全是个萌新，糕糕前辈在我进入某大佬群时主动加了我的好友（现在想来感动的能哭出声）</p><p>在我学习ue时不吝赐教，为我提供了许多资料，语气也十分的和蔼温柔</p><p>每次遇到什么问题发消息几乎都是秒回，解答了我的许多疑惑（我哭死）</p><p>这篇博客会做成一个对话的专栏形式，会记录一些前期学习遇到的疑问</p><p>不会有固定的大纲，记录的风格是诙谐轻松的（顺利的话会一直写下去？）</p><p>最重要的是这些遇到并得到解答的问题我不希望今天获取然后明天就失忆了</p><p>这些知识对初学者应该是很有帮助的（确信），所以我很乐意记录这样一个快乐的过程</p><span id="more"></span><hr><p>这次笔者会记录在学校学习的第二周和糕糕前辈发生的有趣的对话</p><hr><h2 id="第一幕-3-1"><a href="#第一幕-3-1" class="headerlink" title="第一幕 3.1"></a>第一幕 3.1</h2><p>四月：糕糕你之前发我的那个有关assert的文章还在吗，哦对了说起来断言算是c++的机制还是算是ue的机制呢</p><p>糕糕：是ue的机制，你也可以自己写，不过就不叫断言了。你知道断言为什么叫断言吗。</p><p>四月：会引发一个中断！（确信）</p><p>糕糕：没错，断言的意思差不多就类似中断的文字版。</p><hr><h2 id="第二幕-3-2"><a href="#第二幕-3-2" class="headerlink" title="第二幕 3.2"></a>第二幕 3.2</h2><p>四月：糕糕，元数据metadata是什么</p><p>糕糕：元数据是用来描述数据的数据，<a href="https://www.ruanyifeng.com/blog/2007/03/metadata.html">https://www.ruanyifeng.com/blog/2007/03/metadata.html</a></p><p>四月：这样，那ue的元数据是什么，文件大小时间那些的吗</p><p>糕糕：UE的UProperty有Meta标签，不过可以自己加，只能editor识别。或者说这个所谓的描述其实没有固定添加的地方</p><p>只是看你的程序对他处不处理。</p><p>四月：噢噢正是这样所以UE editor能把这些当成资产来使用，这就是元数据</p><hr><h2 id="第三幕-3-2"><a href="#第三幕-3-2" class="headerlink" title="第三幕 3.2"></a>第三幕 3.2</h2><p><strong>四月：</strong>自带的FPS模板写了一堆前向声明诶</p><p><img src="/images/loading.jpg" data-original="/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/_4VZ%25%5D%25DHR%5B7%60RTAIZ79GOR.png" alt="img"></p><p><strong>糕糕：</strong>C++ 必须写这个，必须能不用#include就不用</p><p><strong>四月：</strong>噢噢原来是这样，我之前都是都是#include</p><p><strong>糕糕：</strong>#include的话 其中某个头文件改了，链式增加编译数量，而且会有重叠引用的问题</p><p><strong>四月：</strong>之前demo就遇到过，就武器类引用了我的角色，角色类也引用我的武器，然后乱糟糟的，可能哪边不小心改错了就过不去编译。</p><p><strong>糕糕：</strong>还有这个前置声明，我推荐在头文件里写在要用的地方，而不是写在最上面，方便复制片段代码</p><p>还有个事，struct不能前置声明</p><p><strong>四月：</strong>所以class和struct的区别又多了一个，那我怎么天天看到它们只有一个public一个private的区别</p><p>糕糕：其实是UE里不能这样</p><p><strong>四月：</strong>可恶啊</p><p><strong>糕糕：</strong>因为UE的struct只能放到栈里构造，而class只能在堆里构造，UE的uclass 创建变量的时候只能用 指针，ustruct只识别非指针</p><p>所以ustruct，在头文件里构造这个类的时候就要明确要多少内存，所以就得在这里include进来了。</p><p>而class在构造这个类的时候是用的指针，固定大小的，所以可以前置声明。</p><p><strong>四月：</strong>呜呜呜糕糕真是好老师</p><p><strong>糕糕：</strong>所以可恶的C++，现在我学ts就完全好多了</p><hr><h2 id="第四幕-3-2"><a href="#第四幕-3-2" class="headerlink" title="第四幕 3.2"></a>第四幕 3.2</h2><p>四月：UgameplayStatic::里面有什么常用的api吗</p><p>糕糕：看源码，基本上都是常用Api吧。但实际项目中，最好自己写个类似的库</p><p>四月：我自己实现一遍吗</p><p>糕糕：嗯嗯，因为他get出来的是UE原来的类型，要cast一下</p><p><img src="/images/loading.jpg" data-original="/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/T39@HAUYOY4%7BNE%7D(QPL)RKU.png" alt="img"></p><p>比如最常用的这个，正经项目你肯定会自己写个Gamemode吧，你每次都要cast一下</p><p>直接对自己的gamemode写个static get自己的实例算了 反正是单例。</p><p>四月：避免cast是为什么呢，性能开销太大了吗</p><p>糕糕：嗯，损耗很大。</p><p><img src="/images/loading.jpg" data-original="/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/%E5%8D%95%E4%BE%8B.png" alt="img"></p><p>写个单例大概像这样的</p><p>四月：单例不是考虑到线程安全会有什么懒汉式还有其他的吗</p><p>糕糕：Gamemode的生命周期不用自己管理，所以我们只用存他的指针返回他的指针就是了</p><p>四月：所以引擎会帮我们解决对吗</p><p>糕糕：嗯嗯对的，这样只有第一次有cast损耗，后面放tick里也没啥问题了</p><hr><h2 id="小插曲"><a href="#小插曲" class="headerlink" title="小插曲"></a>小插曲</h2><p>四月：我想玩那个车车游戏</p><p>糕糕：base.apk</p><p>四月：这车真的很难开，为什么你漂移还能炸对手</p><p>糕糕：游戏开发者一般是技术最好的吧，其实一般来说是策划，但这移动算法都是我写的</p><p>四月：里面的按钮居然都点不了！只有广告是可以点的，老板估计很开心</p><p>糕糕：说起来 你想去大厂的话，一定要想办法转正或者毕业就直接去大厂，不然工作几年之后很难的</p><p>我这边的tx基本上只招资深的<img src="/images/loading.jpg" data-original="/2022/03/07/%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%BA%8C%E6%9C%9F%EF%BC%89/2FFS%7B6G@M3$ZUWUK%25SWE0H.gif" alt="img">普通的和高级的基本上都是从实习生就在Tx的</p><p>四月：我当然知道啦，所以转正我特别重视，毕竟现在版号不发了，是游戏圈的紧要关头，可能没转正成功我就回家了。</p><p>我打算死磕tx了，毕业拿转正offer之前都不算高枕无忧。</p><hr><p>笔者写这些的时候，又听到了一些所谓“小道消息”，说春招的hc被卡了很多，即使自己不需要春招已经上岸</p><p>但还是感觉到了不小的压力，也为整个中国游戏行业的未来狠狠的捏了一把汗。</p><p>再说下去要emo了，这样可不行，人还是得开开心心的，毕竟我又是月亮又是太阳！</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在ue方面笔者完全是个萌新，糕糕前辈在我进入某大佬群时主动加了我的好友（现在想来感动的能哭出声）&lt;/p&gt;
&lt;p&gt;在我学习ue时不吝赐教，为我提供了许多资料，语气也十分的和蔼温柔&lt;/p&gt;
&lt;p&gt;每次遇到什么问题发消息几乎都是秒回，解答了我的许多疑惑（我哭死）&lt;/p&gt;
&lt;p&gt;这篇博客会做成一个对话的专栏形式，会记录一些前期学习遇到的疑问&lt;/p&gt;
&lt;p&gt;不会有固定的大纲，记录的风格是诙谐轻松的（顺利的话会一直写下去？）&lt;/p&gt;
&lt;p&gt;最重要的是这些遇到并得到解答的问题我不希望今天获取然后明天就失忆了&lt;/p&gt;
&lt;p&gt;这些知识对初学者应该是很有帮助的（确信），所以我很乐意记录这样一个快乐的过程&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>年糕老师的ue4小课堂（第一期）</title>
    <link href="https://aprilnavi.github.io/2022/03/07/2022-03-04-%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%B8%80%E6%9C%9F%EF%BC%89/"/>
    <id>https://aprilnavi.github.io/2022/03/07/2022-03-04-%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%B8%80%E6%9C%9F%EF%BC%89/</id>
    <published>2022-03-07T09:31:58.000Z</published>
    <updated>2022-03-07T09:02:02.104Z</updated>
    
    <content type="html"><![CDATA[<p>在ue方面笔者完全是个萌新，糕糕前辈在我进入某大佬群时主动加了我的好友（现在想来感动的能哭出声）</p><p>在我学习ue时不吝赐教，为我提供了许多资料，语气也十分的和蔼温柔</p><p>每次遇到什么问题发消息几乎都是秒回，解答了我的许多疑惑（我哭死）</p><p>这篇博客会做成一个对话的专栏形式，会记录一些前期学习遇到的疑问</p><p>不会有固定的大纲，记录的风格是诙谐轻松的（顺利的话会一直写下去？）</p><p>最重要的是这些遇到并得到解答的问题我不希望今天获取然后明天就失忆了</p><p>这些知识对初学者应该是很有帮助的（确信），所以我很乐意记录这样一个快乐的过程</p><span id="more"></span><hr><p>让我们有请今天的嘉宾，糕糕老师！</p><p><strong>糕糕：</strong>大家好，我是一个工作不到两年的菜鸡（看来糕糕老师确实很谦虚呢）</p><hr><h2 id="第一幕-2-23"><a href="#第一幕-2-23" class="headerlink" title="第一幕 2.23"></a>第一幕 2.23</h2><p>某天晚上我新建了个了第三人称模板，想找个项目做做重温一下act的感觉，在搞动画蓝图的时候有了以下一幕：</p><p><strong>四月：</strong>那个人向哪里走就向哪里转向的，是在哪里设置的？</p><p><strong>糕糕 ：</strong>MovementComponent 还是 Character的默认属性那里忘记了</p><p><strong>四月：</strong>我还是开中文吧，感觉用英文很多东西反应不过来</p><p><strong>糕糕：</strong>建议是开中文语言，节点的名字和变量的名字英文</p><p><img src="/images/loading.jpg" data-original="/2022/03/07/2022-03-04-%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%B8%80%E6%9C%9F%EF%BC%89/(S9NBOMCU)3C7$7ZNKGC%7D5O-16463936762971.png" alt="img"></p><p><img src="/images/loading.jpg" data-original="/2022/03/07/2022-03-04-%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%B8%80%E6%9C%9F%EF%BC%89/QQ%E5%9B%BE%E7%89%8720220304193559.png" alt="img"></p><p><strong>糕糕：</strong>嗯对是这样</p><p><strong>四月：</strong>奇怪了，我在blendspace里面看都是正常的，有很多个方向的移动，连上去之后，怎么跑怎么动都是一个样子</p><p><img src="/images/loading.jpg" data-original="/2022/03/07/2022-03-04-%E5%B9%B4%E7%B3%95%E8%80%81%E5%B8%88%E7%9A%84ue4%E5%B0%8F%E8%AF%BE%E5%A0%82%EF%BC%88%E7%AC%AC%E4%B8%80%E6%9C%9F%EF%BC%89/image-20220304194659446.png" alt="image-20220304194659446"></p><p><strong>糕糕：</strong>白色那里选场景里的Character，这可是蓝图调试基础</p><p><strong>四月：</strong>呜呜呜基础</p><p><strong>糕糕：</strong>没事，我也是自学才看到这个功能的</p><p><strong>四月：</strong>算了我把速度打印到屏幕吧，这样方便一点</p><p><strong>四月：</strong>我草，破案了，他的速度只有正值，我是傻逼啊</p><p><strong>糕糕：</strong>哈哈哈哈哈哈哈，这个就是做项目的好处了，能学到解决问题的思路，所以即使之后做的不是这个类型的游戏之类的也能做</p><p><strong>四月：</strong>他这个自带模板有大病啊，怪不得要设置成自动旋转，速度怎么可能会没有负值啊，然后blendspace只做了前进的</p><p><strong>糕糕：</strong>速度一般都是0～动画的实际速度，看设计的。</p><hr><p>次日：</p><p><strong>四月：</strong>完了，我是怎么说出昨天晚上那些话的，正常来说速度怎么可能有负值呢</p><p><strong>糕糕：</strong>所以我没多想</p><p>![image-20220304200942589]image-20220304200942589.png)</p><p><strong>四月：</strong>这样，感觉好缺编程经验，断言，调试，句柄，宏这些我都没学过，怎么恶补</p><p><strong>糕糕：</strong>你是想刚毕业就有10年经验吗</p><p><strong>四月：</strong>啊可是这个难道不是毕业生标配吗，我怎么感觉别人都会（事实上这个傻逼在过度焦虑）</p><p><strong>四月：</strong>哈哈哈哈哈哈哈哈哈，你这一说我就放心了</p><p><strong>糕糕：</strong>嗯 我的意思就是，这些其实都是在做项目过程中学的，所以没有恶补的方法</p><p><strong>四月 ：</strong>噢噢这样，之前精力基本上都在看理论，怪不得都不知道这些，实操少了</p><hr><p>由此可见，gameplay的实操本身就是最好的学习资料</p><hr><h2 id="第二幕-2-25"><a href="#第二幕-2-25" class="headerlink" title="第二幕 2.25"></a>第二幕 2.25</h2><p>这篇特别长但我觉得特别有营养，是经典</p><p>有天下午在图书馆看大象无形（确实是真的看不懂），看到一半回忆起当时面试被问到的问题</p><p><strong>四月：</strong>gamemode和gamestate的区别是什么，关卡蓝图又是什么</p><p><strong>糕糕：</strong>终于到这里了</p><p><strong>四月：</strong>没有，还没到这里，是我在读书的时候想起了面试官问我的问题。</p><p><strong>糕糕：</strong>这些东西都是属于Gameplay框架里的一部分，Gameplay框架的定义，它是一个“房间制多人联机回合计分对战游戏框架”，所以你做单机游戏的时候，实际上是用不到的。</p><p><strong>四月：</strong>所以做单机游戏的时候 ，是不是我把规则写gamemode和gamestate都可以</p><p><strong>糕糕：</strong>是这样，但是你一旦做多人游戏，这俩的网络同步状态，以目前游戏用得比较多的UE联机方式，DS服务器架构下，<br>一个游戏房间里拥有一个中央服务端只处理服务器逻辑不处理渲染，而所有玩家都是客户端。在这种架构下，服务端跑了一个UWorld，客户端也跑了一个UWorld，但是只有服务端的UWorld是真实的，其他所有的都是复制品。</p><p><strong>四月：</strong>所以说客户端是对服务端的拙劣模仿，有看到这样的形容</p><p><strong>糕糕：</strong>对的，然后 Gamemode Gamestate都是继承actor的，Gamemode仅在服务端上生成，不复制到客户端，Gamestate在所有端均生成，以服务端为准，其他为复制品</p><p><strong>四月：</strong>噢噢原来是这样，那关卡蓝图呢</p><p><strong>糕糕：</strong>关卡蓝图纯本地，一般不使用关卡蓝图，关卡蓝图不是Actor哦</p><p><strong>四月：</strong>原来是这样</p><p><strong>糕糕：</strong>Gamemode是UE的Gameplay框架的一部分，所以 Gamemode 的设置里的这些东西也是</p><p><strong>糕糕：</strong>先不看Pawn，先看PlayerController，只在拥有的客户端上生成，服务端拥有所有客户端的 PlayerController，所以，玩家在自己的PlayerController，修改了值啊，执行了什么事件啊之类的，只有服务器知道，其他客户端是不知道的，所以又来了个PlayerState</p><p><strong>四月：</strong>啊这</p><p><strong>糕糕：</strong><a href="https://docs.unrealengine.com/4.27/zh-CN/InteractiveExperiences/Framework/">https://docs.unrealengine.com/4.27/zh-CN/InteractiveExperiences/Framework/</a></p><p>你的问题文档都有，只是“计分多人游戏框架”这件事是我自己总结的，网上没有的，你先理解了这个定义，用这个定义去理解他的框架应该会更容易些，不然容易误解某些功能233。</p><p><strong>四月：</strong>虚幻引擎真的好难学啊</p><p><strong>糕糕：</strong>成也Gameplay框架败也Gameplay框架，成在，你作为没有经验的，不是架构师，理解它用它，就能出游戏了；</p><p>成在，你作为没有经验的，不是架构师，理解它用它，就能出游戏了。</p><p><strong>四月：</strong>我该怎么做呜呜呜呜</p><p><strong>糕糕：</strong>开整！现在就用它整个多人联机fps</p><p><strong>糕糕：</strong>Gamemode用来写当前游戏模式的服务器要执行的事件，比如LOL，假如在10分钟出大龙，这件事就是写Gamemode里的。</p><p>而游戏已经进行了10分钟，大龙已经被击杀了多少次，是在Gamestate里面。</p><p><strong>四月：</strong>gamemode是写事件，state是记录信息条件，这样吗</p><p><strong>糕糕：</strong>这样，大龙例子不是很好，那就红buff吧。红BUFF有个特点，你没视野的时候被打死，你不知道红BUFF没了。没错，他的生成和存在状态就是存Gamemode里的。</p><p><strong>四月：</strong>所有野怪都这样</p><p><strong>糕糕：</strong>因为Gamemode不在客户端同步，你可以设置只在客户端有视野的时候，Gamemode才把对应状态通过RPC发过去</p><p><strong>四月：</strong>那gamestate还是记信息嘛，每个客户端一份，然后服务端的是真的，其他都是复制品</p><p><strong>糕糕：</strong>嗯，gamestate记全场客户端人尽皆知的事，游戏持续时间……大逃杀的话，剩余人数。但如果是LOL的话，</p><p>玩家杀人数可以记到gamestate，但是补刀数 装备在 playerstate，可以理解吗</p><p><strong>四月：</strong>不太理解诶，补刀数不是和杀人数战绩按理说不是一样的吗</p><p><strong>糕糕：</strong>不一样的哦，你观察下打野英雄，不露脸不显示补刀数的，防止你知道打野英雄的发育情况了</p><p><strong>四月：</strong>噢噢，所以补刀并不是全场客户端人尽皆知的事情，所以就并不是记录在Gametate而是在Playerstate里面。这样我就明白了</p><hr><p>这个专栏感觉还是很生动的，打算以一星期一次的频率更新一次（前提是有提问）</p><p>这一期太长了剩下就放到下一期来吧！2022.3.7</p><hr>]]></content>
    
    
    <summary type="html">&lt;p&gt;在ue方面笔者完全是个萌新，糕糕前辈在我进入某大佬群时主动加了我的好友（现在想来感动的能哭出声）&lt;/p&gt;
&lt;p&gt;在我学习ue时不吝赐教，为我提供了许多资料，语气也十分的和蔼温柔&lt;/p&gt;
&lt;p&gt;每次遇到什么问题发消息几乎都是秒回，解答了我的许多疑惑（我哭死）&lt;/p&gt;
&lt;p&gt;这篇博客会做成一个对话的专栏形式，会记录一些前期学习遇到的疑问&lt;/p&gt;
&lt;p&gt;不会有固定的大纲，记录的风格是诙谐轻松的（顺利的话会一直写下去？）&lt;/p&gt;
&lt;p&gt;最重要的是这些遇到并得到解答的问题我不希望今天获取然后明天就失忆了&lt;/p&gt;
&lt;p&gt;这些知识对初学者应该是很有帮助的（确信），所以我很乐意记录这样一个快乐的过程&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>主流抗锯齿方案对比</title>
    <link href="https://aprilnavi.github.io/2022/03/04/%E4%B8%BB%E6%B5%81%E6%8A%97%E9%94%AF%E9%BD%BF%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94/"/>
    <id>https://aprilnavi.github.io/2022/03/04/%E4%B8%BB%E6%B5%81%E6%8A%97%E9%94%AF%E9%BD%BF%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94/</id>
    <published>2022-03-04T11:00:58.000Z</published>
    <updated>2022-03-04T11:01:59.010Z</updated>
    
    <content type="html"><![CDATA[<p>感觉这个坑对于经常玩游戏的玩家应该还算有一点吸引力</p><p>因为笔者最近在研究opengl的时候做到了离屏msaa的部分</p><p>觉得如果能自己好好学习一下抗锯齿的几种类型并简要的介绍一下</p><p>想必对自己学习历程一定会有很大的帮助</p><span id="more"></span><p>我们不会在这里阐述锯齿产生的原因，详见games101 P6的那节，同时我们假设读者都了解熟悉光栅化的过程</p><p>我们也不会拿源码出来讲解抗锯齿的实际使用</p><p>（PS：确实除了msaa其他都没做过，可能会把opengl做离屏msaa那一章拿出来讲解一下）</p><p>本篇内容当然还是以网上的内容摘要总结为主（其实就是写给自己复习用的）</p><p>我们会尽量从原理和优缺点分析这些抗锯齿方案。</p><h1 id="MSAA，SSAA"><a href="#MSAA，SSAA" class="headerlink" title="MSAA，SSAA"></a>MSAA，SSAA</h1><p><strong>MSAA（MultiSampling Anti-Aliasing）（多重采样反走样）</strong></p><p><strong>SSAA（Super-Sampling Anti-Aliasing）（超级采样反走样）</strong></p><p>从名字我们就能很容易看出两种抗锯齿采取的办法是在增加了采样的次数</p><p>msaa和ssaa我认为是相似的，虽然他们只在对子像素点处理方式上有着细微区别</p><p>但所耗费的开销差别的巨大的，这也因此让ssaa直接就退出了历史舞台，因此我们会细嗦MSAA</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>他们的具体做法都是在一个像素内增加子像素点，ssaa会对每个子像素点都进行一次单独的着色计算</p><p>在最后将子像素点的颜色合并到对应的像素点。SSAA是最直接也是效果最好的抗锯齿方法。</p><p>像素本身就是计算机图像的最小不可分最小的单位，所以会将整个纹理拉大到更高倍数的缓存上进行采样</p><p>以常见的SSAAx4为例，在面对一张需要以1920x1080（1080P）像素渲染的画面时</p><p>SSAA会首先渲染一张尺寸为3840x2160（4K）像素的缓存，再在这种长宽都乘以2的画面上进行采样</p><p>采样的精度和效果当然是最理想的，但是也可以想象，这种对于硬件资源的消耗非常大，成本也非常高。</p><hr><p>MSAA出于性能考虑，同一个像素上的多个子像素点，不会每个都进行一次像素着色计算</p><p>而是共享像素中心点的像素计算结果。</p><p>对于每个像素点，如果上面对应的子像素点至少有一个通过了覆盖测试，就会进行<strong>一次</strong>采样</p><p>计算的插值采样位置是像素的中心位置。一次采样的结果，会用于多个次像素采样点中。</p><p>计算完成后，每个通过覆盖测试的次像素点还需要进行 <strong>depth-stencil test/深度-模板测试</strong></p><p>这个测试和普通的单个像素的深度-模板测试是一样的，只是现在发生在次像素点而已。</p><p>当深度-模板测试通过后，在像素中心位置采样的结果值就会写入到对应的次像素点。</p><hr><p>使用MSAA是比较简单的，重要工作都是 GPU 来自动完成的，我们只需要使用即可。</p><p>在 OpengGL 中，使用 MSAA 只需要将 FrameBuffer 的格式设置成相应的 NxMSAA 格式</p><p>将 FrameBuffer 作为渲染输出，就是 MSAA的效果。</p><p>将 MSAA 格式贴图 Blit 到普通的格式，OpenGL 会自动完成 resolve 的工作。</p><p>我们使用 MSAA 时也要注意，要尽量避免过多地进行 resolve 操作</p><p>比如经常将 MSAA 格式贴图作为贴图输入，又作为 RenderTarget 来输出。这样会不断进行 resovle 操作，造成额外的性能消耗。</p><p>（草这说的好像就是我）</p><p>如果是使用现代的图形 API，则一般需要显式地调用 resolve，整个过程也更加可控。</p><p>（懂了opengl不算现代图形api）</p><hr><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：使用简单方便，效果好。</p><p>缺点：因为是在光栅化阶段做的抗锯齿，抗锯齿这部分是由硬件完成的，会额外消耗大量内存和带宽</p><p>对于延迟渲染来说，GBuffer 本身就已经很大了，如果再使用 MSAA，额外的带宽消耗极大。</p><p>因此延迟渲染一般不会使用 MSAA来作为实现抗锯齿手段。</p><p>而目前大部分 PC 端游戏都是基于延迟渲染管线的，包括Unity 的 HDRP ，所以 PC 游戏一般不会使用 MSAA。</p><p>（因为自己没做过延迟渲染，所以关于延迟渲染的部分是抄的网上的233333）</p><hr><h1 id="FXAA"><a href="#FXAA" class="headerlink" title="FXAA"></a>FXAA</h1><p><strong>FXAA（Fast Approximate Anti-Aliasing）（快速近似抗锯齿）</strong></p><p>它是传统MSAA（多重采样抗锯齿）效果的一种高性能近似值。运行于目标游戏渲染管线的后期处理阶段</p><p>它只是单纯的后期处理着色器，不依赖于任何GPU计算API。</p><p>正因为如此，FXAA技术对显卡没有特殊要求，完全兼容NVIDIA、AMD的不同显卡(MLAA仅支持A卡)和DX9、DX10、DX11。</p><h2 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h2><p>除了增加每个像素点的采样数，我们实现抗锯齿的另一种方式就是后处理。</p><p>考虑到大部分情况下，我们想要抗锯齿的部分，其实都只是在物体边缘或者高光变化的部分</p><p>我们通过后处理的方式，找出图像块之间的边缘，然后根据边缘信息对边缘两侧的图像进行混合处理，达到抗锯齿的效果。</p><p>这类基于后处理的抗锯齿方式也叫做<strong>形变抗锯齿/Morphological antialiasing</strong></p><p>但是任何事物都是辩证的，正如同其名，FXAA毕竟是一种“比较廉价”的抗锯齿技术</p><p>在大多数的游戏应用中，效果终究不及传统的MSAA，适用于性能不高的电脑配置。</p><p>具体的FXAA算法可以看这篇优质博客：</p><p><a href="https://zhuanlan.zhihu.com/p/431384101">主流抗锯齿方案详解（三）FXAA - 知乎 (zhihu.com)</a></p><p>（其实很多观点也是扒的人家和百度百科的，这位作者的文真的给了我很大的启发，有机会的话建议都好好读一遍）</p><h2 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点：FXAA 的优点就是集成比较方便，只需要一个 Pass 来实现抗锯齿，</p><p>同时提供了quality和console两个版本，是目前手机上的最常用的抗锯齿方式。</p><p>缺点：FXAA在带来超快速运算的同时，也带来了精度和质量上的损失。</p><p>而且由于FXAA是基于后处理判断边界来实现的，因此没有次像素特性，在光照高频(颜色变化很快)的地方会不稳定。</p><p>单独看静态的场景没有问题，但是移动摄影机时，就会导致一些闪烁。</p><hr><h1 id="TAA"><a href="#TAA" class="headerlink" title="TAA"></a>TAA</h1><hr><h1 id="SMAA"><a href="#SMAA" class="headerlink" title="SMAA"></a>SMAA</h1><hr><h1 id="DLSS"><a href="#DLSS" class="headerlink" title="DLSS"></a>DLSS</h1><hr><p>很多很多内容都来自，谢谢这位作者，仅做自己学习记录之用，若有雷同，无意冒犯</p><p><a href="https://www.zhihu.com/column/c_1210266723531976704">实时渲染学习笔记 - 知乎 (zhihu.com)</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;感觉这个坑对于经常玩游戏的玩家应该还算有一点吸引力&lt;/p&gt;
&lt;p&gt;因为笔者最近在研究opengl的时候做到了离屏msaa的部分&lt;/p&gt;
&lt;p&gt;觉得如果能自己好好学习一下抗锯齿的几种类型并简要的介绍一下&lt;/p&gt;
&lt;p&gt;想必对自己学习历程一定会有很大的帮助&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
</feed>
